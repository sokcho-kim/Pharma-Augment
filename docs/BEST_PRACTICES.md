# Pharma-Augment ë² ìŠ¤íŠ¸ í”„ë™í‹°ìŠ¤

## ğŸ“‹ ê°œìš”

Pharma-Augment í”„ë¡œì íŠ¸ë¥¼ íš¨ê³¼ì ìœ¼ë¡œ ì‚¬ìš©í•˜ê³  ìœ ì§€ë³´ìˆ˜í•˜ê¸° ìœ„í•œ ë² ìŠ¤íŠ¸ í”„ë™í‹°ìŠ¤ì™€ ê¶Œì¥ì‚¬í•­ì„ ì •ë¦¬í•œ ë¬¸ì„œì…ë‹ˆë‹¤.

## ğŸ¯ ë²„ì „ ì„ íƒ ê°€ì´ë“œ

### ëª©ì ë³„ ê¶Œì¥ ë²„ì „

| ì‚¬ìš© ëª©ì  | ê¶Œì¥ ë²„ì „ | ì´ìœ  |
|----------|-----------|------|
| **ì„ë² ë”© ëª¨ë¸ í•™ìŠµ** | **V5** | êµ¬ì²´ì ì´ê³  ë‹¤ì–‘í•œ ê³ í’ˆì§ˆ ì§ˆë¬¸ |
| **100% ë°ì´í„° ì»¤ë²„ë¦¬ì§€** | V4 | ëª¨ë“  í–‰ì—ì„œ ë°˜ë“œì‹œ ì§ˆë¬¸ ìƒì„± |
| **ë¹ ë¥¸ í”„ë¡œí† íƒ€ì´í•‘** | V1 | ë‹¨ìˆœí•˜ê³  ë¹ ë¥¸ ê¸°ë³¸ ìƒì„± |
| **ë ˆê±°ì‹œ í˜¸í™˜ì„±** | V2 | ê¸°ì¡´ ì„ë² ë”© ëª¨ë¸ê³¼ í˜¸í™˜ |

### í’ˆì§ˆ vs ì»¤ë²„ë¦¬ì§€ íŠ¸ë ˆì´ë“œì˜¤í”„

```
ë†’ì€ í’ˆì§ˆ ì›í•  ë•Œ: V5 â†’ V2 â†’ V3 â†’ V4 â†’ V1
ë†’ì€ ì»¤ë²„ë¦¬ì§€ ì›í•  ë•Œ: V4 â†’ V5 â†’ V1 â†’ V2 â†’ V3
```

## ğŸ”§ ì‹¤í–‰ ì „ ì²´í¬ë¦¬ìŠ¤íŠ¸

### 1. í™˜ê²½ ì¤€ë¹„
- [ ] Python 3.8+ ì„¤ì¹˜ í™•ì¸
- [ ] í•„ìš”í•œ íŒ¨í‚¤ì§€ ì„¤ì¹˜: `pip install -r requirements.txt`
- [ ] API í‚¤ ì„¤ì •: `.env` íŒŒì¼ì— `OPENAI_API_KEY` ì¶”ê°€
- [ ] ì…ë ¥ ë°ì´í„° ì¤€ë¹„: ì—‘ì…€ íŒŒì¼ ê²½ë¡œ í™•ì¸

### 2. ë°ì´í„° ê²€ì¦
- [ ] í•„ìˆ˜ ì»¬ëŸ¼ ì¡´ì¬ í™•ì¸: `êµ¬ë¶„`, `ì„¸ë¶€ì¸ì •ê¸°ì¤€ ë° ë°©ë²•`
- [ ] í•œê¸€ ì¸ì½”ë”© ë¬¸ì œ ì—†ëŠ”ì§€ í™•ì¸
- [ ] ê´„í˜¸ íŒ¨í„´ ì •ë¦¬ ì—¬ë¶€ í™•ì¸: `[ì¼ë°˜ì›ì¹™]` ë“±

### 3. ë¦¬ì†ŒìŠ¤ ê³„íš
- [ ] API ì‚¬ìš©ëŸ‰ í•œë„ í™•ì¸
- [ ] ë™ì‹œì„± ìˆ˜ì¤€ ì„¤ì •: `--concurrency` (ê¶Œì¥: 4-6)
- [ ] ë””ìŠ¤í¬ ìš©ëŸ‰ í™•ì¸: ê²°ê³¼ íŒŒì¼ ì €ì¥ ê³µê°„

## ğŸ’¡ ìµœì  ì‹¤í–‰ ë°©ë²•

### V5 ì‹¤í–‰ (ê¶Œì¥)

```bash
# ê¸°ë³¸ ì‹¤í–‰
python versions/v5/drug_generator_v5.py \
  --excel "data/cleaned_data.xlsx" \
  --out "results/v5_questions.xlsx"

# ìµœì í™”ëœ ì‹¤í–‰ (ì¶”ì²œ ì„¤ì •)
python versions/v5/drug_generator_v5.py \
  --excel "data/cleaned_data.xlsx" \
  --out "results/v5_questions.xlsx" \
  --provider openai \
  --model gpt-4o-mini \
  --concurrency 4 \
  --seed 20250903
```

### ëŒ€ìš©ëŸ‰ ë°ì´í„° ì²˜ë¦¬

```bash
# ë‹¨ê³„ë³„ ì²˜ë¦¬ (1000í–‰ì”©)
python utils/batch_processor.py \
  --input "large_data.xlsx" \
  --batch_size 1000 \
  --version v5

# ë³‘ë ¬ ì²˜ë¦¬ (ì—¬ëŸ¬ í”„ë¡œì„¸ìŠ¤)
python utils/parallel_runner.py \
  --input "large_data.xlsx" \
  --workers 4 \
  --version v5
```

## ğŸ“Š í’ˆì§ˆ ê´€ë¦¬ ê°€ì´ë“œ

### 1. ìƒì„± ì „ ë°ì´í„° í’ˆì§ˆ ì²´í¬

```python
# ë°ì´í„° í’ˆì§ˆ ê²€ì¦ ìŠ¤í¬ë¦½íŠ¸ ì˜ˆì‹œ
def validate_input_data(df):
    """ì…ë ¥ ë°ì´í„° í’ˆì§ˆ ê²€ì¦"""
    issues = []
    
    # 1. í•„ìˆ˜ ì»¬ëŸ¼ í™•ì¸
    required_cols = ['êµ¬ë¶„', 'ì„¸ë¶€ì¸ì •ê¸°ì¤€ ë° ë°©ë²•']
    for col in required_cols:
        if col not in df.columns:
            issues.append(f"í•„ìˆ˜ ì»¬ëŸ¼ ëˆ„ë½: {col}")
    
    # 2. ë¹ˆ ê°’ ë¹„ìœ¨ í™•ì¸
    for col in required_cols:
        if col in df.columns:
            empty_rate = df[col].isna().sum() / len(df)
            if empty_rate > 0.1:  # 10% ì´ìƒ
                issues.append(f"{col} ë¹ˆ ê°’ ë¹„ìœ¨ ë†’ìŒ: {empty_rate:.1%}")
    
    # 3. ê´„í˜¸ íŒ¨í„´ í™•ì¸
    if 'êµ¬ë¶„' in df.columns:
        bracket_count = df['êµ¬ë¶„'].str.contains(r'\[.*?\]', na=False).sum()
        if bracket_count > 0:
            issues.append(f"ê´„í˜¸ íŒ¨í„´ ë°œê²¬: {bracket_count}ê°œ - ì‚¬ì „ ì •ë¦¬ í•„ìš”")
    
    return issues

# ì‚¬ìš©ë²•
issues = validate_input_data(df)
if issues:
    print("âš ï¸  ë°ì´í„° í’ˆì§ˆ ì´ìŠˆ:")
    for issue in issues:
        print(f"  - {issue}")
    print("âœ… í•´ê²° í›„ ë‹¤ì‹œ ì‹¤í–‰í•˜ì„¸ìš”.")
```

### 2. ìƒì„± í›„ í’ˆì§ˆ í‰ê°€

```python
def evaluate_generated_questions(questions):
    """ìƒì„±ëœ ì§ˆë¬¸ í’ˆì§ˆ í‰ê°€"""
    metrics = {}
    
    # ê¸°ë³¸ í†µê³„
    metrics['total_count'] = len(questions)
    metrics['avg_length'] = np.mean([len(q['question']) for q in questions])
    
    # ëŒ€ëª…ì‚¬ ì‚¬ìš©ë¥  (0%ê°€ ëª©í‘œ)
    pronoun_pattern = re.compile(r"(ì´|ê·¸|í•´ë‹¹|ë³¸|ë™)\s?(ì•½|ì•½ì œ|ì œì œ|ì œí’ˆ)|ì´ê²ƒ|ê·¸ê²ƒ")
    pronoun_count = sum(1 for q in questions if pronoun_pattern.search(q['question']))
    metrics['pronoun_rate'] = pronoun_count / len(questions)
    
    # êµ¬ì²´ì„± ë¹„ìœ¨
    concrete_patterns = [r'\d+', r'(ê°œì›”|ì¼|íšŒ|mg)', r'(í™˜ì|ì²˜ë°©|íˆ¬ì—¬)']
    concrete_count = sum(1 for q in questions 
                        if any(re.search(p, q['question']) for p in concrete_patterns))
    metrics['concrete_rate'] = concrete_count / len(questions)
    
    # WH ì§ˆë¬¸ ë¹„ìœ¨
    wh_count = sum(1 for q in questions 
                  if re.search(r'(ë¬´ì—‡|ì–´ë–¤|ì–¸ì œ|ì–´ë–»ê²Œ|ì™œ)', q['question']))
    metrics['wh_rate'] = wh_count / len(questions)
    
    return metrics

# í’ˆì§ˆ ê¸°ì¤€
QUALITY_THRESHOLDS = {
    'avg_length': (30, 60),     # 30-60ì
    'pronoun_rate': (0, 0.01),  # 1% ë¯¸ë§Œ
    'concrete_rate': (0.7, 1),  # 70% ì´ìƒ
    'wh_rate': (0.8, 1)         # 80% ì´ìƒ
}

def check_quality_standards(metrics):
    """í’ˆì§ˆ ê¸°ì¤€ ë‹¬ì„± ì—¬ë¶€ í™•ì¸"""
    results = {}
    
    for metric, (min_val, max_val) in QUALITY_THRESHOLDS.items():
        value = metrics[metric]
        passed = min_val <= value <= max_val
        results[metric] = {
            'value': value,
            'target': f"{min_val}-{max_val}",
            'passed': passed
        }
    
    return results
```

### 3. í’ˆì§ˆ ê°œì„  ê°€ì´ë“œ

**í’ˆì§ˆì´ ë‚®ì„ ë•Œ ê°œì„  ë°©ë²•**:

1. **í‰ê·  ê¸¸ì´ê°€ ì§§ì„ ë•Œ** (< 30ì)
   ```python
   # í”„ë¡¬í”„íŠ¸ì— ê¸¸ì´ ì œì•½ ê°•í™”
   "ë°˜ë“œì‹œ 30ì ì´ìƒì˜ êµ¬ì²´ì ì´ê³  ìƒì„¸í•œ ì§ˆë¬¸ì„ ìƒì„±í•˜ë¼"
   
   # ì˜¨ë„ ì¡°ì •
   payload["temperature"] = 0.8  # ë” ì°½ì˜ì ìœ¼ë¡œ
   ```

2. **êµ¬ì²´ì„±ì´ ë¶€ì¡±í•  ë•Œ** (< 70%)
   ```python
   # í”„ë¡¬í”„íŠ¸ì— êµ¬ì²´ì„± ìš”êµ¬ì‚¬í•­ ì¶”ê°€
   "ë°˜ë“œì‹œ ë‹¤ìŒ ì¤‘ í•˜ë‚˜ ì´ìƒ í¬í•¨: êµ¬ì²´ì  ìˆ˜ì¹˜, ì˜ë£Œìš©ì–´, í™˜ìêµ°, ì ˆì°¨"
   ```

3. **ëŒ€ëª…ì‚¬ ì‚¬ìš©ë¥ ì´ ë†’ì„ ë•Œ** (> 1%)
   ```python
   # í›„ì²˜ë¦¬ì—ì„œ ë” ì—„ê²©í•˜ê²Œ í•„í„°ë§
   if pronoun_pattern.search(question_text):
       logger.warning(f"ëŒ€ëª…ì‚¬ ê²€ì¶œ: {question_text}")
       continue  # ì§ˆë¬¸ ì œê±°
   ```

## ğŸš¨ ë¬¸ì œ í•´ê²° ê°€ì´ë“œ

### ìì£¼ ë°œìƒí•˜ëŠ” ì˜¤ë¥˜ì™€ í•´ê²°ì±…

#### 1. API ê´€ë ¨ ì˜¤ë¥˜

**ì—ëŸ¬**: `OpenAI API key not found`
```bash
# í•´ê²°ì±…
echo "OPENAI_API_KEY=your_actual_key_here" >> .env
```

**ì—ëŸ¬**: `Rate limit exceeded`
```bash
# í•´ê²°ì±…: ë™ì‹œì„± ë‚®ì¶”ê¸°
python generate.py --concurrency 2  # ê¸°ë³¸ 6 â†’ 2ë¡œ ë‚®ì¶¤
```

#### 2. ë°ì´í„° ê´€ë ¨ ì˜¤ë¥˜

**ì—ëŸ¬**: `KeyError: 'êµ¬ë¶„'`
```python
# í•´ê²°ì±…: ì»¬ëŸ¼ëª… í™•ì¸ ë° ë§¤í•‘
print("ì‹¤ì œ ì»¬ëŸ¼ëª…:", df.columns.tolist())
# í•„ìš”ì‹œ ìˆ˜ë™ ë§¤í•‘
df = df.rename(columns={'ì‹¤ì œì»¬ëŸ¼ëª…': 'êµ¬ë¶„'})
```

**ì—ëŸ¬**: `UnicodeDecodeError`
```python
# í•´ê²°ì±…: ì¸ì½”ë”© ëª…ì‹œ
df = pd.read_excel(file_path, encoding='utf-8-sig')
```

#### 3. ë©”ëª¨ë¦¬ ê´€ë ¨ ì˜¤ë¥˜

**ì—ëŸ¬**: `MemoryError`
```python
# í•´ê²°ì±…: ë°°ì¹˜ ì²˜ë¦¬
def process_in_batches(df, batch_size=100):
    for i in range(0, len(df), batch_size):
        batch = df[i:i+batch_size]
        yield batch
        
# ì‚¬ìš©ë²•
for batch in process_in_batches(large_df):
    results = generator.process(batch)
```

### ì„±ëŠ¥ ìµœì í™” íŒ

#### 1. API í˜¸ì¶œ ìµœì í™”

```python
# ì¢‹ì€ ì˜ˆ: ë¹„ë™ê¸° ë°°ì¹˜ ì²˜ë¦¬
tasks = [process_item(item) for item in data[:100]]  # 100ê°œì”©
results = await asyncio.gather(*tasks)

# ë‚˜ìœ ì˜ˆ: ìˆœì°¨ ì²˜ë¦¬
for item in data:
    result = await process_item(item)  # ë„ˆë¬´ ëŠë¦¼
```

#### 2. ë©”ëª¨ë¦¬ ì‚¬ìš© ìµœì í™”

```python
# ì¢‹ì€ ì˜ˆ: ì œë„ˆë ˆì´í„° ì‚¬ìš©
def load_data_lazy(file_path):
    for chunk in pd.read_excel(file_path, chunksize=1000):
        yield chunk

# ë‚˜ìœ ì˜ˆ: ì „ì²´ ë¡œë“œ
df = pd.read_excel(huge_file)  # ë©”ëª¨ë¦¬ ë¶€ì¡± ìœ„í—˜
```

#### 3. ë””ìŠ¤í¬ I/O ìµœì í™”

```python
# ì¢‹ì€ ì˜ˆ: ìŠ¤íŠ¸ë¦¼ ì“°ê¸°
with open('results.jsonl', 'w') as f:
    for result in results:
        f.write(json.dumps(result) + '\n')

# ë‚˜ìœ ì˜ˆ: ë©”ëª¨ë¦¬ì— ëª¨ë“  ê²°ê³¼ ì €ì¥ í›„ í•œë²ˆì— ì“°ê¸°
all_results = []  # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¦ê°€
```

## ğŸ“ˆ ëª¨ë‹ˆí„°ë§ê³¼ ë¶„ì„

### 1. ì‹¤í–‰ ì¤‘ ëª¨ë‹ˆí„°ë§

```python
# ì§„í–‰ë¥  ì¶”ì 
from tqdm import tqdm

with tqdm(total=len(data), desc="ì§„í–‰ë¥ ") as pbar:
    for item in data:
        result = process_item(item)
        pbar.update(1)
        pbar.set_postfix({
            'success_rate': f"{success_count/processed_count:.1%}",
            'avg_length': f"{avg_length:.1f}"
        })
```

### 2. ê²°ê³¼ ë¶„ì„

```python
# ê²°ê³¼ í†µê³„ ëŒ€ì‹œë³´ë“œ
def create_analysis_report(results_file):
    df = pd.read_excel(results_file)
    
    report = {
        'summary': {
            'total_questions': len(df),
            'avg_length': df['question'].str.len().mean(),
            'unique_drugs': df['êµ¬ë¶„'].nunique()
        },
        'quality_metrics': {
            'pronoun_rate': check_pronoun_usage(df),
            'concrete_rate': check_concreteness(df),
            'label_distribution': df['ë¼ë²¨'].value_counts().to_dict()
        },
        'recommendations': generate_recommendations(df)
    }
    
    return report
```

## ğŸ”„ ì§€ì†ì  ê°œì„  ë°©ë²•

### 1. A/B í…ŒìŠ¤íŠ¸

```python
# í”„ë¡¬í”„íŠ¸ ë²„ì „ í…ŒìŠ¤íŠ¸
def test_prompts(data_sample, prompt_a, prompt_b):
    results_a = generate_with_prompt(data_sample, prompt_a)
    results_b = generate_with_prompt(data_sample, prompt_b)
    
    metrics_a = evaluate_quality(results_a)
    metrics_b = evaluate_quality(results_b)
    
    winner = 'A' if metrics_a['overall_score'] > metrics_b['overall_score'] else 'B'
    return winner, metrics_a, metrics_b
```

### 2. í”¼ë“œë°± ë£¨í”„

```python
# ì‚¬ìš©ì í”¼ë“œë°± ìˆ˜ì§‘
def collect_feedback(questions):
    feedback = {}
    for q in questions:
        rating = input(f"ì§ˆë¬¸: {q}\ní‰ê°€ (1-5): ")
        feedback[q] = int(rating)
    return feedback

# í”¼ë“œë°± ê¸°ë°˜ ê°œì„ 
def improve_based_on_feedback(feedback):
    low_quality = [q for q, rating in feedback.items() if rating <= 2]
    analyze_failure_patterns(low_quality)
```

### 3. ë²„ì „ ê´€ë¦¬

```bash
# Gitìœ¼ë¡œ í”„ë¡¬í”„íŠ¸ ë²„ì „ ê´€ë¦¬
git tag v5.1 -m "êµ¬ì²´ì„± ê°œì„ ëœ í”„ë¡¬í”„íŠ¸"
git push origin v5.1

# ì‹¤í—˜ ë¸Œëœì¹˜
git checkout -b experiment/longer-questions
# ì‹¤í—˜ í›„
git checkout main
git merge experiment/longer-questions
```

## ğŸ“š ì¶”ê°€ ë¦¬ì†ŒìŠ¤

### ìœ ìš©í•œ ìŠ¤í¬ë¦½íŠ¸

1. **`utils/data_validator.py`**: ì…ë ¥ ë°ì´í„° ê²€ì¦
2. **`utils/quality_checker.py`**: ê²°ê³¼ í’ˆì§ˆ í‰ê°€
3. **`utils/batch_processor.py`**: ëŒ€ìš©ëŸ‰ ë°ì´í„° ë°°ì¹˜ ì²˜ë¦¬
4. **`utils/result_analyzer.py`**: ê²°ê³¼ ë¶„ì„ ë° ì‹œê°í™”

### ì°¸ê³  ë¬¸í—Œ

- [OpenAI API ë¬¸ì„œ](https://platform.openai.com/docs)
- [Pandas ìµœì í™” ê°€ì´ë“œ](https://pandas.pydata.org/docs/user_guide/enhancingperf.html)
- [ë¹„ë™ê¸° í”„ë¡œê·¸ë˜ë° ë² ìŠ¤íŠ¸ í”„ë™í‹°ìŠ¤](https://docs.python.org/3/library/asyncio.html)

### ì»¤ë®¤ë‹ˆí‹°

- **ì´ìŠˆ ë¦¬í¬íŒ…**: GitHub Issues
- **ê¸°ëŠ¥ ìš”ì²­**: GitHub Discussions
- **ê¸°ìˆ  ì§ˆë¬¸**: Stack Overflow (íƒœê·¸: pharma-augment)

---

*ìµœì¢… ì—…ë°ì´íŠ¸: 2025-09-03*  
*ì‘ì„±ì: Claude Code Assistant*