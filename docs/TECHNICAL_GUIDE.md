# Pharma-Augment ê¸°ìˆ  ê°€ì´ë“œ

## ğŸ“‹ ê°œìš”

Pharma-Augment í”„ë¡œì íŠ¸ì˜ ê¸°ìˆ ì  êµ¬í˜„ ì„¸ë¶€ì‚¬í•­, ì•„í‚¤í…ì²˜, ê·¸ë¦¬ê³  ê°œë°œ ê³¼ì •ì—ì„œ ë°œê²¬í•œ í•µì‹¬ ì´ìŠˆì™€ í•´ê²°ì±…ì„ ì •ë¦¬í•œ ê¸°ìˆ  ë¬¸ì„œì…ë‹ˆë‹¤.

## ğŸ—ï¸ í”„ë¡œì íŠ¸ ì•„í‚¤í…ì²˜

### ë””ë ‰í† ë¦¬ êµ¬ì¡°
```
Pharma-Augment/
â”œâ”€â”€ versions/              # ë²„ì „ë³„ êµ¬í˜„ì²´
â”‚   â”œâ”€â”€ v1/               # ê¸°ë³¸ ì§ˆë¬¸ ìƒì„±
â”‚   â”œâ”€â”€ v2/               # ì„ë² ë”© ìµœì í™”  
â”‚   â”œâ”€â”€ v3/               # ëŒ€ëª…ì‚¬ ì°¨ë‹¨ + ì´ë¦„ë¹„ìœ¨
â”‚   â”œâ”€â”€ v4/               # 100% ì»¤ë²„ë¦¬ì§€ ë³´ì¥
â”‚   â””â”€â”€ v5/               # í’ˆì§ˆ + ì»¤ë²„ë¦¬ì§€ ê· í˜•
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ inputs/           # ì›ë³¸ ì—‘ì…€ íŒŒì¼
â”‚   â””â”€â”€ outputs/          # ìƒì„± ê²°ê³¼ íŒŒì¼
â”œâ”€â”€ utils/                # ìœ í‹¸ë¦¬í‹° ìŠ¤í¬ë¦½íŠ¸  
â””â”€â”€ docs/                 # ë¬¸ì„œ ë° í”„ë¡¬í”„íŠ¸
```

### í•µì‹¬ ì»´í¬ë„ŒíŠ¸

1. **ë°ì´í„° ë¡œë”** (`load_excel_data`)
   - ì—‘ì…€ íŒŒì¼ ì½ê¸° ë° ì»¬ëŸ¼ ë§¤í•‘
   - UTF-8 ì¸ì½”ë”© ë¬¸ì œ í•´ê²°
   - í•„ìˆ˜ í•„ë“œ ê²€ì¦

2. **ì „ì²˜ë¦¬ê¸°** (`preprocess_data`)
   - NaN ê°’ ì²˜ë¦¬
   - í…ìŠ¤íŠ¸ ì •ê·œí™”
   - clause_id ìƒì„±

3. **í”„ë¡¬í”„íŠ¸ ì—”ì§„** (`create_prompt`)
   - ë²„ì „ë³„ ë§ì¶¤ í”„ë¡¬í”„íŠ¸ ìƒì„±
   - ë™ì  íŒŒë¼ë¯¸í„° ì‚½ì…
   - í’ˆì§ˆ ê¸°ì¤€ ì •ì˜

4. **API í´ë¼ì´ì–¸íŠ¸** (`call_api`)
   - ë¹„ë™ê¸° HTTP ìš”ì²­
   - Rate limit ì²˜ë¦¬
   - ì¬ì‹œë„ ë¡œì§

5. **í›„ì²˜ë¦¬ê¸°** (`post_process`)
   - ì •ê·œì‹ ê¸°ë°˜ ê²€ì¦
   - í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°
   - í•„í„°ë§ ë° ì •ì œ

## ğŸ”§ í•µì‹¬ ê¸°ìˆ  êµ¬í˜„

### 1. ëŒ€ëª…ì‚¬ ì°¨ë‹¨ ì‹œìŠ¤í…œ

**ì •ê·œì‹ íŒ¨í„´**:
```python
PRONOUN_RE = re.compile(r"(ì´|ê·¸|í•´ë‹¹|ë³¸|ë™)\s?(ì•½|ì•½ì œ|ì œì œ|ì œí’ˆ)|ì´ê²ƒ|ê·¸ê²ƒ")
```

**ê²€ì¦ ë¡œì§**:
```python
def validate_pronoun(text: str) -> bool:
    """ëŒ€ëª…ì‚¬ ê²€ì¦"""
    return not self.PRONOUN_RE.search(text)

# ì‚¬ìš© ì˜ˆì‹œ
for question in questions:
    if not validate_pronoun(question['text']):
        logger.warning(f"ëŒ€ëª…ì‚¬ ê²€ì¶œ: {question['text']}")
        continue  # í•´ë‹¹ ì§ˆë¬¸ ì œê±°
```

**ê²€ì¶œ ì˜ˆì‹œ**:
```
âŒ "ì´ ì•½ì œì˜ ì‚¬ìš©ë²•ì€?" â†’ ëŒ€ëª…ì‚¬ ê²€ì¶œ
âŒ "í•´ë‹¹ ì œì œì˜ ê¸°ì¤€ì€?" â†’ ëŒ€ëª…ì‚¬ ê²€ì¶œ  
âœ… "Tacrolimusì˜ ì‚¬ìš©ë²•ì€?" â†’ í†µê³¼
```

### 2. ì´ë¦„ ì‚¬ìš© ë¹„ìœ¨ ì‹œìŠ¤í…œ

**ì¶”ì¶œ ë¡œì§**:
```python
def extract_name_slots(gubun: str) -> Tuple[str, List[str]]:
    """êµ¬ë¶„ í•„ë“œì—ì„œ ì•½ì œëª… ì¶”ì¶œ"""
    # [ì¼ë°˜ì›ì¹™] ì œê±°
    clean_gubun = re.sub(r'\[.*?\]\s*', '', gubun)
    
    # ì£¼ ì•½ì œëª… ì¶”ì¶œ (ê´„í˜¸ ì•)
    main_match = re.search(r'^([^(]+)', clean_gubun)
    main_name = main_match.group(1).strip() if main_match else ""
    
    # í’ˆëª… ì¶”ì¶œ (í’ˆëª…: ë’¤)
    brand_match = re.search(r'í’ˆ\s*ëª…\s*[:ï¼š]\s*([^)]+)', clean_gubun)
    brand_names = []
    if brand_match:
        brand_text = brand_match.group(1).strip()
        brand_names = re.split(r'[Â·/]+', brand_text)
        brand_names = [name.strip() for name in brand_names if name.strip()]
    
    return main_name, brand_names
```

**ë¹„ìœ¨ ê³„ì‚°**:
```python
def calculate_ratios(brand_names: List[str]) -> Dict[str, Tuple[float, float]]:
    """ë¸Œëœë“œëª… ê°œìˆ˜ë³„ ë¹„ìœ¨ ê³„ì‚°"""
    num_brands = len(brand_names)
    
    if num_brands == 0:
        return {"MAIN": (0.70, 0.80), "BRAND": (0.0, 0.0), "BOTH": (0.20, 0.30)}
    elif num_brands == 1:  
        return {"MAIN": (0.35, 0.45), "BRAND": (0.30, 0.40), "BOTH": (0.20, 0.30)}
    else:
        return {"MAIN": (0.30, 0.40), "BRAND": (0.30, 0.40), "BOTH": (0.20, 0.30)}
```

### 3. í’ˆì§ˆ ì ìˆ˜ ì‹œìŠ¤í…œ (V4)

**S_q ì ìˆ˜ ê³„ì‚°**:
```python
def calculate_question_score(text: str, content: str) -> float:
    """ë¬¸í•­ ì ìˆ˜ S_q ê³„ì‚° (0~1)"""
    
    # 1. ê¸¸ì´ ì ìˆ˜ (45ì ìµœì )
    length = len(text)
    length_score = max(0, min(1, 1 - abs(length - 45) / 30))
    
    # 2. WH ì ìˆ˜
    wh_patterns = r'(ë¬´ì—‡|ì–´ë–¤|ì–¸ì œ|ì–´ë–»ê²Œ|ì™œ|ëˆ„ê°€|ì–´ë””|ëª‡)'
    if re.search(f'^{wh_patterns}', text):
        wh_score = 1.0
    elif re.search(wh_patterns, text):
        wh_score = 0.6
    else:
        wh_score = 0.2
    
    # 3. ë‹¨ì¼ ë…¼ì  ì ìˆ˜
    multi_issue_count = text.count(',') + text.count('ë°') + text.count('/')
    single_issue = 1.0 if multi_issue_count <= 1 else 0.3
    
    # 4. ëŒ€ëª…ì‚¬ íŒ¨ë„í‹°
    pronoun_penalty = -1.0 if self.PRONOUN_RE.search(text) else 0.0
    
    # 5. ì›ë¬¸ ì¤‘ì²© ì ìˆ˜
    text_tokens = set(re.findall(r'\w+', text))
    content_tokens = set(re.findall(r'\w+', content))
    overlap = len(text_tokens & content_tokens) / len(text_tokens) if text_tokens else 0.0
    
    # ìµœì¢… ì ìˆ˜
    s_q = (0.25 * length_score + 0.25 * wh_score + 
           0.25 * single_issue + 0.25 * overlap + pronoun_penalty)
    
    return max(0.0, min(1.0, s_q))
```

### 4. Fallback ì‹œìŠ¤í…œ (V4)

**3ë‹¨ê³„ ì¬ì‹œë„ ë¡œì§**:
```python
async def generate_questions_for_drug(self, session, row_data, row_idx):
    """3ë‹¨ê³„ fallbackìœ¼ë¡œ 100% ì„±ê³µ ë³´ì¥"""
    
    validated_questions = []
    
    # 1ì°¨: ì—„ê²©í•œ ê¸°ì¤€
    try:
        prompt = self.create_strict_prompt(row_data)
        questions = await self.call_api(session, prompt)
        validated_questions = self.strict_post_process(questions)
        if len(validated_questions) >= 5:
            return validated_questions
    except Exception as e:
        logger.warning(f"1ì°¨ ì‹œë„ ì‹¤íŒ¨: {e}")
    
    # 2ì°¨: ì™„í™”ëœ ê¸°ì¤€
    try:
        prompt = self.create_relaxed_prompt(row_data)
        questions = await self.call_api(session, prompt)
        validated_questions = self.relaxed_post_process(questions)
        if len(validated_questions) >= 5:
            return validated_questions  
    except Exception as e:
        logger.warning(f"2ì°¨ ì‹œë„ ì‹¤íŒ¨: {e}")
    
    # 3ì°¨: ê¸°ë³¸ ì§ˆë¬¸ ìƒì„± (100% ë³´ì¥)
    return self.create_basic_questions(row_data)
```

### 5. V5 êµ¬ì²´ì„± ê²€ì¦ ì‹œìŠ¤í…œ

**êµ¬ì²´ì„± íŒ¨í„´ ë§¤ì¹­**:
```python
def validate_concreteness(text: str) -> bool:
    """V5 êµ¬ì²´ì„± ê²€ì¦"""
    concrete_patterns = [
        r'\d+',                           # ìˆ«ì í¬í•¨
        r'(ê°œì›”|ì¼|íšŒ|mg|mL|U/L)',        # ì˜ë£Œ ë‹¨ìœ„
        r'(í™˜ì|ì²˜ë°©|íˆ¬ì—¬|ì‚¬ìš©|ì ìš©)',      # ì˜ë£Œ ìš©ì–´
        r'(ê¸°ì¤€|ì¡°ê±´|ì ˆì°¨|ë°©ë²•|ì‚¬í•­)',      # êµ¬ì²´ì  ëª…ì‚¬
    ]
    
    return any(re.search(pattern, text) for pattern in concrete_patterns)

# V5ì—ì„œ ì‚¬ìš©
if not validate_concreteness(question_text):
    logger.warning(f"V5 êµ¬ì²´ì„± ë¶€ì¡±: {question_text}")
    continue
```

## ğŸ” ì£¼ìš” ì´ìŠˆì™€ í•´ê²°ì±…

### 1. ì¸ì½”ë”© ë¬¸ì œ

**ë¬¸ì œ**: Windows í™˜ê²½ì—ì„œ UTF-8 í•œê¸€ ì²˜ë¦¬ ì˜¤ë¥˜
```
UnicodeEncodeError: 'cp949' codec can't encode character
```

**í•´ê²°ì±…**:
```python
# ë¡œê¹… í•¸ë“¤ëŸ¬ì—ì„œ UTF-8 ëª…ì‹œ
logging.FileHandler('log.log', encoding='utf-8')

# íŒŒì¼ ì €ì¥ ì‹œ ì¸ì½”ë”© ì§€ì •
df.to_csv(path, encoding='utf-8-sig')  # BOM í¬í•¨
df.to_excel(path, engine='openpyxl')   # ì—‘ì…€ì€ openpyxl ì‚¬ìš©
```

### 2. [ê´„í˜¸] íŒ¨í„´ ì˜¤ì—¼

**ë¬¸ì œ**: ì›ë³¸ ë°ì´í„°ì˜ [ì¼ë°˜ì›ì¹™] ë“±ì´ ì§ˆë¬¸ì— í¬í•¨ë¨

**í•´ê²° ê³¼ì •**:
1. **ë¬¸ì œ ë°œê²¬**: ìƒì„±ëœ ì§ˆë¬¸ì— "[ì¼ë°˜ì›ì¹™] ê°„ì¥ì œì œì˜..." í˜•íƒœ
2. **ì›ì¸ ë¶„ì„**: ì›ë³¸ ë°ì´í„°ì˜ êµ¬ë¶„ í•„ë“œì— ê´„í˜¸ íŒ¨í„´ ì¡´ì¬
3. **í•´ê²°ì±… êµ¬í˜„**: 
   - `data_cleaner.py`: ì›ë³¸ ë°ì´í„° ì •ë¦¬
   - `question_only_cleaner.py`: ì§ˆë¬¸ í•„ë“œë§Œ ì •ë¦¬

**ì •ë¦¬ ìŠ¤í¬ë¦½íŠ¸**:
```python
def clean_bracket_patterns(text):
    """ê´„í˜¸ íŒ¨í„´ ì œê±°"""
    text = re.sub(r'\[.*?\]\s*', '', text)  # [íŒ¨í„´] ì œê±°
    return text.strip()

# ì›ë³¸ ë°ì´í„° ì •ë¦¬
df['êµ¬ë¶„'] = df['êµ¬ë¶„'].apply(clean_bracket_patterns)

# ìƒì„±ëœ ì§ˆë¬¸ë§Œ ì •ë¦¬ (êµ¬ë¶„ í•„ë“œëŠ” ìœ ì§€)
df['question'] = df['question'].apply(clean_bracket_patterns)
```

### 3. API Rate Limit ì²˜ë¦¬

**ë¬¸ì œ**: OpenAI API 429 ì—ëŸ¬ë¡œ ì¸í•œ ìƒì„± ì¤‘ë‹¨

**í•´ê²°ì±…**:
```python
@backoff.on_exception(
    backoff.expo, 
    (aiohttp.ClientError, asyncio.TimeoutError), 
    max_tries=3
)
async def call_api(self, session, prompt):
    """ë°±ì˜¤í”„ ì¬ì‹œë„ ë¡œì§"""
    
    async with session.post(url, json=payload) as response:
        if response.status == 429:
            logger.warning("Rate limit, retrying...")
            await asyncio.sleep(3)  # ì ì‹œ ëŒ€ê¸°
            raise aiohttp.ClientError("Rate limit")
        
        response.raise_for_status()
        return await response.json()
```

### 4. ë™ì‹œì„± ì œì–´

**ë¬¸ì œ**: ë„ˆë¬´ ë§ì€ ë™ì‹œ ìš”ì²­ìœ¼ë¡œ ì¸í•œ ì‹œìŠ¤í…œ ë¶€í•˜

**í•´ê²°ì±…**:
```python
# ì„¸ë§ˆí¬ì–´ë¡œ ë™ì‹œì„± ì œì–´
self.semaphore = asyncio.Semaphore(concurrency)

async def generate_questions(self, session, data):
    async with self.semaphore:  # ìµœëŒ€ concurrencyê°œë§Œ ë™ì‹œ ì‹¤í–‰
        # API í˜¸ì¶œ ë¡œì§
        pass
```

### 5. ì§„í–‰ìƒí™© ì‹œê°í™”

**ë¬¸ì œ**: ëŒ€ìš©ëŸ‰ ë°ì´í„° ì²˜ë¦¬ ì‹œ ì§„í–‰ìƒí™© íŒŒì•… ì–´ë ¤ì›€

**í•´ê²°ì±…**:
```python
from tqdm.asyncio import tqdm

# ë¹„ë™ê¸° ì§„í–‰ë°”
self.progress_bar = tqdm(total=len(data), desc="ì§ˆë¬¸ ìƒì„± ì¤‘", unit="ì•½ì œ")

async def process_item(self, item):
    # ì‘ì—… ì²˜ë¦¬
    result = await self.generate_questions(item)
    
    # ì§„í–‰ìƒí™© ì—…ë°ì´íŠ¸
    if self.progress_bar:
        self.progress_bar.update(1)
    
    return result
```

## ğŸ“Š ì„±ëŠ¥ ìµœì í™”

### 1. ë°°ì¹˜ ì²˜ë¦¬ ìµœì í™”

```python
# ë¹„íš¨ìœ¨ì : ìˆœì°¨ ì²˜ë¦¬
for item in data:
    result = await process_item(item)

# íš¨ìœ¨ì : ë¹„ë™ê¸° ë°°ì¹˜ ì²˜ë¦¬  
tasks = [process_item(item) for item in data]
results = await asyncio.gather(*tasks, return_exceptions=True)
```

### 2. ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ìµœì í™”

```python
# ëŒ€ìš©ëŸ‰ ë°ì´í„° ìŠ¤íŠ¸ë¦¼ ì²˜ë¦¬
def process_large_file(file_path):
    chunk_size = 1000
    
    for chunk in pd.read_excel(file_path, chunksize=chunk_size):
        yield chunk  # ì œë„ˆë ˆì´í„°ë¡œ ë©”ëª¨ë¦¬ ì ˆì•½
```

### 3. ìºì‹± ì‹œìŠ¤í…œ

```python
from functools import lru_cache

@lru_cache(maxsize=1000)
def extract_drug_info(gubun: str):
    """ìì£¼ ì‚¬ìš©ë˜ëŠ” ì•½ì œ ì •ë³´ ìºì‹±"""
    # íŒŒì‹± ë¡œì§
    return main_name, brand_names
```

## ğŸ§ª í…ŒìŠ¤íŠ¸ ì „ëµ

### 1. ë‹¨ìœ„ í…ŒìŠ¤íŠ¸
```python
def test_pronoun_detection():
    """ëŒ€ëª…ì‚¬ ê²€ì¶œ í…ŒìŠ¤íŠ¸"""
    assert not validate_pronoun("ì´ ì•½ì œì˜ ì‚¬ìš©ë²•")  # ê²€ì¶œë˜ì–´ì•¼ í•¨
    assert validate_pronoun("Tacrolimusì˜ ì‚¬ìš©ë²•")   # í†µê³¼ë˜ì–´ì•¼ í•¨

def test_name_extraction():
    """ì•½ì œëª… ì¶”ì¶œ í…ŒìŠ¤íŠ¸"""  
    gubun = "Tacrolimus ì œì œ (í’ˆëª…: í”„ë¡œê·¸ëìº…ì…€Â·ì£¼ì‚¬)"
    main_name, brand_names = extract_name_slots(gubun)
    assert main_name == "Tacrolimus ì œì œ"
    assert brand_names == ["í”„ë¡œê·¸ëìº…ì…€", "ì£¼ì‚¬"]
```

### 2. í†µí•© í…ŒìŠ¤íŠ¸
```python
def test_end_to_end_generation():
    """ì „ì²´ í”„ë¡œì„¸ìŠ¤ í…ŒìŠ¤íŠ¸"""
    sample_data = load_sample_data()
    generator = DrugGeneratorV5()
    
    results = asyncio.run(generator.generate_all_questions(sample_data))
    
    assert len(results) > 0
    assert all(validate_pronoun(r['question']) for r in results)
    assert all(25 <= len(r['question']) <= 80 for r in results)
```

## ğŸ“ˆ ëª¨ë‹ˆí„°ë§ê³¼ ë¡œê¹…

### 1. ê°ì‚¬ ë¡œê·¸ ì‹œìŠ¤í…œ
```python
self.audit_log.append({
    'row_id': row_id,
    'questions_generated': len(questions),
    'avg_length': avg_length,
    'elapsed_ms': elapsed_time,
    'success': is_success,
    'provider': self.provider,
    'model': self.model,
    'version': 'v5'
})

# CSVë¡œ ì €ì¥í•˜ì—¬ ë¶„ì„ ìš©ì´
df_audit = pd.DataFrame(self.audit_log)
df_audit.to_csv('audit_log.csv')
```

### 2. í’ˆì§ˆ ë©”íŠ¸ë¦­ ìˆ˜ì§‘
```python
def calculate_quality_metrics(questions):
    """í’ˆì§ˆ ë©”íŠ¸ë¦­ ê³„ì‚°"""
    return {
        'avg_length': np.mean([len(q) for q in questions]),
        'pronoun_rate': sum(1 for q in questions if PRONOUN_RE.search(q)) / len(questions),
        'concrete_rate': sum(1 for q in questions if validate_concreteness(q)) / len(questions),
        'wh_rate': sum(1 for q in questions if re.search(r'^(ë¬´ì—‡|ì–´ë–¤)', q)) / len(questions)
    }
```

## ğŸš€ ë°°í¬ ë° ìš´ì˜

### 1. í™˜ê²½ ì„¤ì •
```bash
# requirements.txt
pandas>=2.0.0
aiohttp>=3.8.0  
backoff>=2.2.0
rapidfuzz>=3.0.0
python-dotenv>=1.0.0
tiktoken>=0.5.0
tqdm>=4.65.0
openpyxl>=3.1.0

# .env íŒŒì¼
OPENAI_API_KEY=your_api_key_here
ANTHROPIC_API_KEY=your_claude_key_here
```

### 2. ë„ì»¤í™”
```dockerfile
FROM python:3.11-slim

WORKDIR /app
COPY requirements.txt .
RUN pip install -r requirements.txt

COPY . .
CMD ["python", "drug_generator_v5.py", "--excel", "data.xlsx"]
```

### 3. ë°°ì¹˜ ìŠ¤í¬ë¦½íŠ¸
```bash
#!/bin/bash
# run_v5.sh

echo "V5 ì§ˆë¬¸ ìƒì„± ì‹œì‘..."
python versions/v5/drug_generator_v5.py \
  --excel "data/cleaned_drug_data.xlsx" \
  --out "results/drug_questions_v5.xlsx" \
  --concurrency 4

echo "ì™„ë£Œ: results/drug_questions_v5.xlsx"
```

---

*ìµœì¢… ì—…ë°ì´íŠ¸: 2025-09-03*  
*ì‘ì„±ì: Claude Code Assistant*