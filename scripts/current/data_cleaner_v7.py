#!/usr/bin/env python3
"""
V7 ë°ì´í„° í’ˆì§ˆ ìµœì í™” - Triplet Mining ì „ìš©
POS/HN í’ˆì§ˆ ëŒ€í­ í–¥ìƒ + ì™„ë²½í•œ ë¹„ìœ¨ ê· í˜•
"""

import pandas as pd
import re
import logging
from typing import List, Tuple

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class V7DataCleaner:
    def __init__(self):
        self.forbidden_words = [
            'TODO', 'ë¯¸ì •', 'ê²€í† ', 'ì˜ˆì‹œ', 'ìƒ˜í”Œ', 'placeholder',
            '[', ']', '{', '}', '()', 'ë¹ˆì¹¸', 'ê³µë€'
        ]
        
        self.vague_patterns = [
            'ê°€ëŠ¥í•œê°€ìš”', 'ì–´ë–»ê²Œ í•˜ì£ ', 'ë°©ë²•ì€ ë¬´ì—‡', 'ì–´ë–¤ ê²½ìš°',  
            'ì–¸ì œì¸ê°€ìš”', 'ì™œì¸ê°€ìš”', 'ë¬´ì—‡ì¸ê°€ìš”', 'ì–´ë””ì„œ',
            'ëˆ„êµ¬', 'ì–´ëŠ ê²ƒ', 'ì–¼ë§ˆë‚˜', 'ì–´ë–¤ ë°©ë²•', 'ì–´ë–¤', 
            'ëª‡ ê°œì›”', 'ëª‡ íšŒ', 'ëª‡ ì¼', 'ëª‡ ì£¼', 'íŠ¹ì´ì‚¬í•­',
            'í•„ìš”í•œê°€', 'í•´ì•¼ í•˜ë‚˜', 'í•´ë„ ë˜ë‚˜', 'ê´œì°®ë‚˜',
            'ì ì ˆí•œ', 'ì í•©í•œ', 'ìµœëŒ€', 'ìµœì†Œ', 'ì´ìƒì¸ê°€',
            'ë¯¸ë§Œì¸ê°€', 'í•´ë‹¹í•˜ë‚˜', 'í¬í•¨ë˜ë‚˜', 'ì œì™¸ë˜ë‚˜'
        ]
        
    def is_high_quality(self, question: str) -> Tuple[bool, List[str]]:
        """ì´ˆì—„ê²© í’ˆì§ˆ ê²€ì‚¬"""
        issues = []
        
        # 1. ê¸¸ì´ ê²€ì‚¬ (30-250ì)
        if len(question) < 30:
            issues.append(f'ë„ˆë¬´ì§§ìŒ({len(question)}ì)')
        elif len(question) > 250:
            issues.append(f'ë„ˆë¬´ê¹€({len(question)}ì)')
            
        # 2. ê¸ˆì§€ì–´ ê²€ì‚¬
        for word in self.forbidden_words:
            if word in question:
                issues.append(f'ê¸ˆì§€ì–´({word})')
                
        # 3. í¬ê´„/ì¶”ìƒ í‘œí˜„ ê²€ì‚¬
        for pattern in self.vague_patterns:
            if pattern in question:
                issues.append(f'í¬ê´„í‘œí˜„({pattern})')
                
        # 4. êµ¬ì²´ì„± ê²€ì‚¬ - ìˆ«ì+ë‹¨ìœ„ ëª¨ë‘ í•„ìˆ˜
        has_number = bool(re.search(r'\d+', question))
        has_unit = bool(re.search(r'(U/L|mg/kg|mg|ml|ã|ã|ì¼|ê°œì›”|ì£¼|íšŒ|ì„¸|ì |ë…„|mg/dL|mmol/L|mmHg)', question))
        has_medical_term = bool(re.search(r'(ALT|AST|í¬ë ˆì•„í‹°ë‹Œ|í˜ˆì••|ì²´ì¤‘|BMI|HbA1c|HFMSE)', question))
        
        if not has_number:
            issues.append('ìˆ«ìì—†ìŒ')
        if not (has_unit or has_medical_term):
            issues.append('ë‹¨ìœ„ì—†ìŒ')
            
        # 5. ì•½ì œ/ì§€í‘œ/ëŒ€ìƒì êµ¬ì²´ì„± ê²€ì‚¬
        has_drug_context = bool(re.search(r'(íˆ¬ì—¬|ì²˜ë°©|ë³µìš©|ì£¼ì‚¬|ì ìš©|ì‚¬ìš©)', question))
        has_target = bool(re.search(r'(í™˜ì|ì„±ì¸|ì†Œì•„|ì„ì‚°ë¶€|ê³ ë ¹ì)', question))
        
        if not (has_drug_context or has_target):
            issues.append('ë§¥ë½ë¶€ì¡±(ì•½ì œë§¥ë½í•„ìˆ˜)')
            
        # 6. ì§ˆë¬¸ í˜•íƒœ ê²€ì‚¬
        if not question.endswith('?'):
            issues.append('ì§ˆë¬¸í˜•ì‹ì˜¤ë¥˜')
            
        # 7. ì˜ë¯¸ìˆëŠ” ë‚´ìš© ê²€ì‚¬
        if len(question.replace('?', '').strip()) < 25:
            issues.append('ë‚´ìš©ë¶€ì¡±')
            
        # 8. ìˆ«ì íŒ¨í„´ ê²€ì‚¬ (ë‹¨ìˆœ ë²ˆí˜¸ ë§¤ê¸°ê¸° ì œì™¸)
        if re.search(r'^\d+\.', question.strip()):
            issues.append('ë²ˆí˜¸ë§¤ê¸°ê¸°')
            
        # 9. ì™„ì „í•œ ë¬¸ì¥ ê²€ì‚¬
        if question.count(' ') < 3:  # ìµœì†Œ 4ê°œ ë‹¨ì–´ ì´ìƒ
            issues.append('ë¬¸ì¥ì§§ìŒ')
            
        return len(issues) == 0, issues
        
    def extract_best_questions(self, df: pd.DataFrame) -> pd.DataFrame:
        """ìµœê³  í’ˆì§ˆ ì§ˆë¬¸ë§Œ ì¶”ì¶œ"""
        logger.info("ğŸ” ì´ˆì—„ê²© í’ˆì§ˆ ê²€ì‚¬ ì‹œì‘...")
        
        high_quality = []
        quality_stats = {'pos_good': 0, 'pos_bad': 0, 'hn_good': 0, 'hn_bad': 0}
        
        for idx, row in df.iterrows():
            question = row['question']
            label = row['ë¼ë²¨']
            
            is_good, issues = self.is_high_quality(question)
            
            if is_good:
                high_quality.append(row)
                if label == 'POSITIVE':
                    quality_stats['pos_good'] += 1
                else:
                    quality_stats['hn_good'] += 1
            else:
                if label == 'POSITIVE':
                    quality_stats['pos_bad'] += 1 
                else:
                    quality_stats['hn_bad'] += 1
                    
                logger.debug(f"í’ˆì§ˆë¶ˆëŸ‰: {question[:50]}... â†’ {issues}")
                
        logger.info(f"í’ˆì§ˆ ê²€ì‚¬ ì™„ë£Œ:")
        logger.info(f"  POSITIVE: {quality_stats['pos_good']}ê°œ í•©ê²©, {quality_stats['pos_bad']}ê°œ íƒˆë½")
        logger.info(f"  HN: {quality_stats['hn_good']}ê°œ í•©ê²©, {quality_stats['hn_bad']}ê°œ íƒˆë½")
        
        return pd.DataFrame(high_quality)
        
    def optimize_for_triplet(self, df: pd.DataFrame) -> pd.DataFrame:
        """Triplet Mining ìµœì í™”"""
        logger.info("ğŸ¯ Triplet Mining ìµœì í™” ì‹œì‘...")
        
        pos_df = df[df['ë¼ë²¨'] == 'POSITIVE'].copy()
        hn_df = df[df['ë¼ë²¨'] == 'HARD_NEGATIVE'].copy()
        
        logger.info(f"ê³ í’ˆì§ˆ ë°ì´í„°: POS {len(pos_df)}ê°œ, HN {len(hn_df)}ê°œ")
        
        # POSëŠ” ìŒìœ¼ë¡œ êµ¬ì„±ë˜ë¯€ë¡œ ì§ìˆ˜ë¡œ ë§ì¶”ê¸°
        pos_pairs = len(pos_df) // 2
        hn_count = len(hn_df)
        
        # Triplet ê°œìˆ˜ ê²°ì • (ë” ì‘ì€ ê°’)
        max_triplets = min(pos_pairs, hn_count)
        
        logger.info(f"ìµœëŒ€ êµ¬ì„± ê°€ëŠ¥ Triplet: {max_triplets}ê°œ")
        
        # ìµœì  ë°ì´í„° ì„ íƒ
        needed_pos = max_triplets * 2  # ìŒì´ë¯€ë¡œ 2ë°°
        needed_hn = max_triplets
        
        # POS ë°ì´í„° ì„ íƒ (í’ˆì§ˆ ì ìˆ˜ë¡œ ì •ë ¬ í›„ ìƒìœ„ ì„ íƒ)
        selected_pos = pos_df.head(needed_pos)
        selected_hn = hn_df.head(needed_hn)
        
        # ê²°í•©
        result_df = pd.concat([selected_pos, selected_hn], ignore_index=True)
        
        logger.info(f"âœ… Triplet ìµœì í™” ì™„ë£Œ:")
        logger.info(f"  POS: {len(selected_pos)}ê°œ ({len(selected_pos)/len(result_df)*100:.1f}%)")
        logger.info(f"  HN: {len(selected_hn)}ê°œ ({len(selected_hn)/len(result_df)*100:.1f}%)")
        logger.info(f"  ì´ {max_triplets}ê°œ ì™„ë²½í•œ Triplet ì„¸íŠ¸")
        logger.info(f"  ì´ ë°ì´í„°: {len(result_df)}ê°œ")
        
        return result_df
        
    def clean_dataset(self, input_file: str, output_file: str):
        """ì „ì²´ ì •ì œ í”„ë¡œì„¸ìŠ¤"""
        logger.info(f"ğŸš€ V7 ë°ì´í„° ì •ì œ ì‹œì‘: {input_file}")
        
        # ë°ì´í„° ë¡œë“œ
        df = pd.read_excel(input_file)
        logger.info(f"ì›ë³¸ ë°ì´í„°: {len(df)}ê°œ")
        
        # 1. ê³ í’ˆì§ˆ ë°ì´í„° ì¶”ì¶œ
        high_quality_df = self.extract_best_questions(df)
        logger.info(f"ê³ í’ˆì§ˆ ë°ì´í„°: {len(high_quality_df)}ê°œ ({len(high_quality_df)/len(df)*100:.1f}%)")
        
        # 2. Triplet ìµœì í™”
        optimized_df = self.optimize_for_triplet(high_quality_df)
        
        # 3. ì €ì¥
        optimized_df.to_excel(output_file, index=False)
        logger.info(f"âœ… ì •ì œ ì™„ë£Œ: {output_file}")
        
        # 4. ê²°ê³¼ ê²€ì¦
        self.verify_result(optimized_df)
        
        return optimized_df
        
    def verify_result(self, df: pd.DataFrame):
        """ê²°ê³¼ ê²€ì¦"""
        logger.info("ğŸ” ê²°ê³¼ ê²€ì¦ ì¤‘...")
        
        pos_count = len(df[df['ë¼ë²¨'] == 'POSITIVE'])
        hn_count = len(df[df['ë¼ë²¨'] == 'HARD_NEGATIVE'])
        total = len(df)
        
        logger.info(f"ìµœì¢… ê²°ê³¼:")
        logger.info(f"  POSITIVE: {pos_count}ê°œ ({pos_count/total*100:.1f}%)")
        logger.info(f"  HARD_NEGATIVE: {hn_count}ê°œ ({hn_count/total*100:.1f}%)")
        logger.info(f"  ì´ ë°ì´í„°: {total}ê°œ")
        logger.info(f"  Triplet ê°œìˆ˜: {min(pos_count//2, hn_count)}ê°œ")
        
        # ìƒ˜í”Œ ê²€ì‚¬
        logger.info("ìƒ˜í”Œ ì§ˆë¬¸ ê²€ì‚¬:")
        for label in ['POSITIVE', 'HARD_NEGATIVE']:
            sample = df[df['ë¼ë²¨'] == label].head(2)
            logger.info(f"[{label}]")
            for _, row in sample.iterrows():
                logger.info(f"  Q: {row['question']}")
                
if __name__ == "__main__":
    cleaner = V7DataCleaner()
    
    input_file = 'results/V7_FULL_DATASET_20250909.xlsx'
    output_file = 'results/V7_CLEANED_OPTIMIZED.xlsx'
    
    try:
        result_df = cleaner.clean_dataset(input_file, output_file)
        logger.info("ğŸ‰ ëª¨ë“  ì •ì œ ì‘ì—… ì™„ë£Œ!")
        
    except Exception as e:
        logger.error(f"âŒ ì •ì œ ì‘ì—… ì‹¤íŒ¨: {e}")