#!/usr/bin/env python3
"""
Pharma-Augment V4 - ì•½ì œ(DRUG) ì „ìš© ì§ˆë¬¸ ìƒì„±ê¸°
prompt_v4.md ìŠ¤í™ ê¸°ë°˜ ì—„ê²©í•œ ë¼ë²¨ë§ ë° ì¶œë ¥ í˜•ì‹ êµ¬í˜„
"""

import argparse
import asyncio
import json
import logging
import os
import re
import sys
import random
import math
from typing import Dict, List, Optional, Tuple, Any
import pandas as pd
import aiohttp
import backoff
from rapidfuzz import fuzz
from dotenv import load_dotenv
import tiktoken
from tqdm.asyncio import tqdm
import time

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('drug_generation_v4.log', encoding='utf-8'),
        logging.StreamHandler(sys.stdout)
    ]
)
logger = logging.getLogger(__name__)

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

class DrugGeneratorV4:
    def __init__(self, provider: str = "openai", model: str = "gpt-4o-mini", 
                 concurrency: int = 6, seed: int = 20250903):
        self.provider = provider
        self.model = model
        self.concurrency = concurrency
        self.seed = seed
        random.seed(seed)
        
        # API í‚¤ ì„¤ì •
        if provider == "openai":
            self.api_key = os.getenv("OPENAI_API_KEY")
            if not self.api_key:
                raise ValueError("OPENAI_API_KEYê°€ í™˜ê²½ë³€ìˆ˜ì— ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        elif provider == "claude":
            self.api_key = os.getenv("ANTHROPIC_API_KEY")
            if not self.api_key:
                raise ValueError("ANTHROPIC_API_KEYê°€ í™˜ê²½ë³€ìˆ˜ì— ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        # ì„¸ë§ˆí¬ì–´ë¡œ ë™ì‹œì„± ì œì–´
        self.semaphore = asyncio.Semaphore(concurrency)
        
        # ëŒ€ëª…ì‚¬ ì°¨ë‹¨ ì •ê·œì‹
        self.PRONOUN_RE = re.compile(r"(ì´|ê·¸|í•´ë‹¹|ë³¸|ë™)\s?(ì•½|ì•½ì œ|ì œì œ|ì œí’ˆ)|ì´ê²ƒ|ê·¸ê²ƒ")
        
        # V4 ì¹´í…Œê³ ë¦¬ (9ê°œ)
        self.CATEGORIES = [
            "ë²”ìœ„", "ìš”ê±´/ê¸°ì¤€", "ì˜¤í”„ë¼ë²¨/í—ˆê°€ë²”ìœ„", "ê¸°ê°„/ì‹œì ", "ì „í™˜", 
            "ì¦ë¹™/ì„œë¥˜", "ë³¸ì¸ë¶€ë‹´/ê¸‰ì—¬êµ¬ë¶„", "ëŒ€ìƒêµ°", "ì ˆì°¨/í”„ë¡œì„¸ìŠ¤"
        ]
        
        # ë¼ë²¨ íƒ€ì…
        self.LABELS = ["POSITIVE", "NEGATIVE", "HARD_NEGATIVE"]
        
        # ê°ì‚¬ ë¡œê·¸
        self.audit_log = []
        self.progress_bar = None
    
    def load_excel_data(self, excel_path: str, sheet_name: str = "Sheet1") -> pd.DataFrame:
        """ì—‘ì…€ íŒŒì¼ ë¡œë“œ"""
        try:
            df = pd.read_excel(excel_path, sheet_name=sheet_name)
            logger.info(f"ì—‘ì…€ íŒŒì¼ ë¡œë“œ ì™„ë£Œ: {df.shape[0]}í–‰ {df.shape[1]}ì—´")
            
            # UTF-8 ë””ì½”ë”© ë¬¸ì œ í•´ê²° ì‹œë„
            for col in df.columns:
                if df[col].dtype == 'object':
                    df[col] = df[col].astype(str)
            
            # ì»¬ëŸ¼ëª… í™•ì¸ ë° ë§¤í•‘
            expected_cols = ['ì•½ì œë¶„ë¥˜ë²ˆí˜¸', 'ì•½ì œ ë¶„ë¥˜ëª…', 'êµ¬ë¶„', 'ì„¸ë¶€ì¸ì •ê¸°ì¤€ ë° ë°©ë²•']
            actual_cols = list(df.columns)
            
            logger.info(f"ì‹¤ì œ ì»¬ëŸ¼: {actual_cols}")
            
            # ì»¬ëŸ¼ ìˆœì„œëŒ€ë¡œ ë§¤í•‘ (ìˆœì„œ ê¸°ë°˜)
            if len(actual_cols) >= 4:
                column_mapping = dict(zip(actual_cols[:4], expected_cols))
                df = df.rename(columns=column_mapping)
                logger.info(f"ì»¬ëŸ¼ ë§¤í•‘ ì™„ë£Œ: {column_mapping}")
            
            return df
            
        except Exception as e:
            logger.error(f"ì—‘ì…€ íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}")
            raise
    
    def extract_name_slots(self, gubun: str) -> Tuple[str, List[str]]:
        """êµ¬ë¶„ í•„ë“œì—ì„œ main_nameê³¼ brand_names ì¶”ì¶œ"""
        # main_name = ê´„í˜¸ ì•ì˜ ì£¼ ì•½ì œëª…
        main_name = ""
        brand_names = []
        
        # ê´„í˜¸ ì• ë¶€ë¶„ì„ main_nameìœ¼ë¡œ
        paren_match = re.search(r'^([^(]+)', gubun)
        if paren_match:
            main_name = paren_match.group(1).strip()
        
        # "í’ˆëª…:" ë’¤ì˜ í’ˆëª…ë“¤ì„ ì¶”ì¶œ
        brand_match = re.search(r'í’ˆ\s*ëª…\s*[:ï¼š]\s*([^)]+)', gubun)
        if brand_match:
            brand_text = brand_match.group(1).strip()
            # 'Â·' ë˜ëŠ” '/' ê¸°ì¤€ìœ¼ë¡œ ë¶„ë¦¬
            brand_names = re.split(r'[Â·/]+', brand_text)
            brand_names = [name.strip() for name in brand_names if name.strip()]
        
        return main_name, brand_names
    
    def calculate_name_ratios(self, brand_names: List[str]) -> Dict[str, Tuple[float, float]]:
        """ë¸Œëœë“œëª… ê°œìˆ˜ì— ë”°ë¥¸ ì´ë¦„ ì‚¬ìš© ë¹„ìœ¨ ë²”ìœ„ ê³„ì‚°"""
        num_brands = len(brand_names)
        
        if num_brands == 0:
            # ë¸Œëœë“œ 0ê°œ: MAIN 70-80%, BOTH 20-30%
            return {
                "MAIN": (0.70, 0.80),
                "BRAND": (0.0, 0.0),
                "BOTH": (0.20, 0.30)
            }
        elif num_brands == 1:
            # ë¸Œëœë“œ 1ê°œ: MAIN 35-45%, BRAND 30-40%, BOTH 20-30%
            return {
                "MAIN": (0.35, 0.45),
                "BRAND": (0.30, 0.40),
                "BOTH": (0.20, 0.30)
            }
        else:
            # ë¸Œëœë“œ 2ê°œ ì´ìƒ: MAIN 30-40%, BRAND 30-40%, BOTH 20-30%
            return {
                "MAIN": (0.30, 0.40),
                "BRAND": (0.30, 0.40),
                "BOTH": (0.20, 0.30)
            }
    
    def create_drug_prompt_v4(self, row_data: Dict) -> str:
        """V4 ì•½ì œ í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        drug_code = row_data.get('ì•½ì œë¶„ë¥˜ë²ˆí˜¸', '')
        drug_name = row_data.get('ì•½ì œ ë¶„ë¥˜ëª…', '')
        gubun = row_data.get('êµ¬ë¶„', '')
        content = row_data.get('ì„¸ë¶€ì¸ì •ê¸°ì¤€ ë° ë°©ë²•', '')
        
        main_name, brand_names = self.extract_name_slots(gubun)
        brand_names_json = json.dumps(brand_names, ensure_ascii=False)
        
        return f"""[ROLE]
ë„ˆëŠ” ì˜ë£Œ ë³´í—˜ ì‹¬ì‚¬Â·ìˆ˜ê°€ ì•½ì œ ë°ì´í„°ë¥¼ ì„ë² ë”© í•™ìŠµìš© ì§ˆë¬¸ ì„¸íŠ¸ë¡œ ë³€í™˜í•˜ëŠ” ì—ì´ì „íŠ¸ë‹¤.
ì…ë ¥ 1í–‰(ì•½ì œ ë‹¨ìœ„)ì„ ë°›ì•„ ì§ˆë¬¸ì„ ìµœì†Œ 5ê°œ~ìµœëŒ€ 20ê°œ ìƒì„±í•˜ê³ , ê° ì§ˆë¬¸ì— ë¼ë²¨ì„ ë¶€ì—¬í•œë‹¤.
ìµœì¢… ì œì¶œ í˜•ì‹ì€ ë°˜ë“œì‹œ ì•„ë˜ 6ê°œ í•„ë“œë§Œì„ ê°€ì§€ëŠ” JSON ë°°ì—´ì´ë‹¤.

[INPUT]
- ì•½ì œë¶„ë¥˜ë²ˆí˜¸: {drug_code}
- ì•½ì œ ë¶„ë¥˜ëª…: {drug_name}
- êµ¬ë¶„: {gubun}
- ì„¸ë¶€ì¸ì •ê¸°ì¤€ ë° ë°©ë²•: \"\"\"
{content}
\"\"\"

[NAME SLOTS] (í”„ë¡¬í”„íŠ¸ ë‚´ë¶€ ì¶”ì¶œ ê·œì¹™)
- main_name = "{main_name}"
- brand_names = {brand_names_json}

[GENERATION RULES]
1) ì§ˆë¬¸ ìˆ˜: 5~20ê°œ. ìƒì„± ê°€ëŠ¥í•œ ë§Œí¼ ë§Œë“¤ë˜ í’ˆì§ˆ í•„í„° í†µê³¼ë¶„ë§Œ ì±„íƒ.
2) ë¬¸í˜•: WH ê°œë°©í˜•(ë¬´ì—‡/ì–´ë–¤/ì–¸ì œ/ì–´ë–»ê²Œ/ì™œ), 1ë¬¸ì¥ 1ë…¼ì , ì™¸ë¶€ ì§€ì‹/ì¶”ì • ê¸ˆì§€.
3) ê¸¸ì´: 15~70ì(í›ˆë ¨ ê¸°ì¤€). 12~50ìëŠ” ê²€ì¦ì…‹ ì¶”ì¶œ ì‹œ ê°€ì .
4) ëŒ€ëª…ì‚¬ ê¸ˆì§€: "(ì´|ê·¸|í•´ë‹¹|ë³¸|ë™) (ì•½|ì•½ì œ|ì œì œ|ì œí’ˆ)|ì´ê²ƒ|ê·¸ê²ƒ" í¬í•¨ ì‹œ íê¸°Â·ì¬ìƒì„±.
5) ì´ë¦„ ì‚¬ìš© ë¹„ìœ¨(ì„¸íŠ¸ ìˆ˜ì¤€ ê°•ì œ):
   - MAIN(ì£¼ ì•½ì œëª…ë§Œ í¬í•¨) 30â€“40%
   - BRAND(í’ˆëª…ë§Œ í¬í•¨)     30â€“40%  
   - BOTH(ë‘˜ ë‹¤ í¬í•¨)        20â€“30%
   - brand_names == [] ì´ë©´: MAIN 70â€“80%, BOTH 20â€“30%
   - brand_names ê¸¸ì´ == 1 ì´ë©´: MAIN 35â€“45%, BRAND 30â€“40%, BOTH 20â€“30%
   - ê²€ì¦: MAINì´ë©´ brand ë¯¸í¬í•¨, BRANDë©´ main ë¯¸í¬í•¨, BOTHë©´ ë‘˜ ë‹¤ í¬í•¨.
6) ì¹´í…Œê³ ë¦¬(ì§ˆë¬¸ë§ˆë‹¤ ì •í™•íˆ 1ê°œ ë¶€ì—¬, ì„¸íŠ¸ ë‚´ ìµœì†Œ 4ì¢… ì´ìƒ ë“±ì¥, ë‹¨ì¼ ì¹´í…Œê³ ë¦¬ â‰¤ 40%)
   {{ë²”ìœ„, ìš”ê±´/ê¸°ì¤€, ì˜¤í”„ë¼ë²¨/í—ˆê°€ë²”ìœ„, ê¸°ê°„/ì‹œì , ì „í™˜(ê²½êµ¬â†”ì£¼ì‚¬),
    ì¦ë¹™/ì„œë¥˜, ë³¸ì¸ë¶€ë‹´/ê¸‰ì—¬êµ¬ë¶„, ëŒ€ìƒêµ°, ì ˆì°¨/í”„ë¡œì„¸ìŠ¤}}
7) DRUG ì„¸íŠ¸ì—ì„œ íŠ¹íˆ í¬í•¨ ê¶Œì¥: ê¸°ê°„/ì‹œì , ì „í™˜(ê²½êµ¬â†”ì£¼ì‚¬), ë³¸ì¸ë¶€ë‹´, ëŒ€ìƒêµ° íŠ¹ë¡€.

[LABELING]
- POSITIVE: ë³¸ ì…ë ¥(êµ¬ë¶„/ì„¸ë¶€ì¸ì •ê¸°ì¤€)ì— ì§ì ‘ ë¶€í•©í•˜ëŠ” ì§ˆë¬¸.
- NEGATIVE: ì „í˜€ ë‹¤ë¥¸ ì•½ì œÂ·ì¡°í•­ì„ ì „ì œë¡œ í•œ ëª…ë°±íˆ ë¬´ê´€í•œ ì§ˆë¬¸.
- HARD_NEGATIVE: í‘œë©´ í† í°ì€ ìœ ì‚¬í•˜ë‚˜ í•µì‹¬ ì°¨ì›ì´ ì–´ê¸‹ë‚˜ëŠ” near-miss
  (ì˜ˆ: ê°™ì€ ì•½ì œì§€ë§Œ 'ì¡°í˜ˆëª¨ì„¸í¬ì´ì‹'â†”'ì‹ ì¥ì´ì‹', 'ì„±ì¸'â†”'ì†Œì•„', 'ì´ˆê¸°'â†”'ì¬ë°œ',
   'ê²½êµ¬'â†”'ì£¼ì‚¬', 'ê¸‰ì—¬'â†”'ì „ì•¡ ë³¸ì¸ë¶€ë‹´', 'ê¸°ê°„ A'â†”'ê¸°ê°„ B' ë“±).

[SELF-CHECK & SCORING]
ë¬¸í•­ ì ìˆ˜ S_q (0~1):
- length_score = clip(1 - |len-45|/30, 0, 1)
- wh_score     = 1 if ë¬¸ë‘ WH, 0.6 if WH í¬í•¨, else 0.2
- single_issue = 1 if (','+'ë°'+'/' í•©ê³„) â‰¤ 1 else 0.3
- pronoun_penalty = -1 if ëŒ€ëª…ì‚¬ íŒ¨í„´ ì¡´ì¬ else 0
- overlap = ì›ë¬¸ í•µì‹¬í† í°ê³¼ì˜ êµì§‘í•© ë¹„ìœ¨(0~1)  # 0.4~0.9ê°€ ì´ìƒì 
- S_q = 0.25*length + 0.25*wh + 0.25*single_issue + 0.25*overlap + pronoun_penalty
ê¸°ì¤€: S_q â‰¥ 0.75ë§Œ ì±„íƒ. ë¯¸ë‹¬ 1íšŒ ì¬ì‘ì„±, ê·¸ë˜ë„ ë¯¸ë‹¬ì´ë©´ íê¸°.

ì„¸íŠ¸ ì ìˆ˜ S_set (0~1):
- name_ratio_dev = Î£_k max(0, |obs_k - target_k| - 0.05)  # kâˆˆ{{MAIN,BRAND,BOTH}}
- cat_coverage   = unique_categories / max(4, min(9, N))
- max_cat_ratio  = ì„¸íŠ¸ì—ì„œ ìµœë¹ˆ ì¹´í…Œê³ ë¦¬ ë¹„ì¤‘
- S_set = 0.5*cat_coverage + 0.5*(1 - min(1, 2*name_ratio_dev)) - max(0, max_cat_ratio-0.4)
ê¸°ì¤€: S_set â‰¥ 0.7. ë¯¸ë‹¬ ì‹œ ë¶€ì¡± ì¹´í…Œê³ ë¦¬/ì´ë¦„ì‚¬ìš©ìœ¼ë¡œ ì¶”ê°€ ìƒì„±Â·ì¹˜í™˜ í›„ ì¬ê³„ì‚°.

[LABEL ë¶„í¬ ê²Œì´íŠ¸(ê¶Œì¥)]
- ì„¸íŠ¸ ë‚´ POSITIVE â‰¥ 60%, HARD_NEGATIVE 10~25%, NEGATIVE 10~25%.
- N<5ì´ë©´ ì¶”ê°€ ìƒì„±, N>20ì´ë©´ S_q ë‚®ì€ ìˆœìœ¼ë¡œ 20ê°œë§Œ ë‚¨ê¹€.

[OUTPUT â€” ì œì¶œìš© ê³ ì • ìŠ¤í‚¤ë§ˆ(JSON ë°°ì—´ë§Œ ì¶œë ¥)]
[
  {{"ì•½ì œë¶„ë¥˜ë²ˆí˜¸":"{drug_code}","ì•½ì œ ë¶„ë¥˜ëª…":"{drug_name}","êµ¬ë¶„":"{gubun}","ì„¸ë¶€ì¸ì •ê¸°ì¤€ ë° ë°©ë²•":"{content[:100]}...","question":"...","ë¼ë²¨":"POSITIVE|NEGATIVE|HARD_NEGATIVE"}},
  ...
]"""

    def calculate_question_score(self, text: str, content: str) -> float:
        """ë¬¸í•­ ì ìˆ˜ S_q ê³„ì‚°"""
        # ê¸¸ì´ ì ìˆ˜ (15-70ì ê¸°ì¤€, 45ìê°€ ìµœì )
        length = len(text)
        length_score = max(0, min(1, 1 - abs(length - 45) / 30))
        
        # WH ì ìˆ˜
        wh_patterns = r'(ë¬´ì—‡|ì–´ë–¤|ì–¸ì œ|ì–´ë–»ê²Œ|ì™œ|ëˆ„ê°€|ì–´ë””|ëª‡)'
        if re.search(f'^{wh_patterns}', text):
            wh_score = 1.0
        elif re.search(wh_patterns, text):
            wh_score = 0.6
        else:
            wh_score = 0.2
        
        # ë‹¨ì¼ ë…¼ì  ì ìˆ˜
        multi_issue_count = text.count(',') + text.count('ë°') + text.count('/')
        single_issue = 1.0 if multi_issue_count <= 1 else 0.3
        
        # ëŒ€ëª…ì‚¬ íŒ¨ë„í‹°
        pronoun_penalty = -1.0 if self.PRONOUN_RE.search(text) else 0.0
        
        # ì›ë¬¸ ì¤‘ì²© ì ìˆ˜ (ê°„ë‹¨í•œ í† í° êµì§‘í•©)
        text_tokens = set(re.findall(r'\w+', text))
        content_tokens = set(re.findall(r'\w+', content))
        if len(text_tokens) > 0:
            overlap = len(text_tokens & content_tokens) / len(text_tokens)
        else:
            overlap = 0.0
        
        # ìµœì¢… ì ìˆ˜ ê³„ì‚°
        s_q = (0.25 * length_score + 0.25 * wh_score + 
               0.25 * single_issue + 0.25 * overlap + pronoun_penalty)
        
        return max(0.0, min(1.0, s_q))
    
    def validate_name_usage(self, text: str, name_usage: str, main_name: str, brand_names: List[str]) -> bool:
        """ì´ë¦„ ì‚¬ìš© ê²€ì¦"""
        main_in_text = main_name in text if main_name else False
        brand_in_text = any(brand in text for brand in brand_names)
        
        if name_usage == "MAIN":
            return main_in_text and not brand_in_text
        elif name_usage == "BRAND":
            return brand_in_text and not main_in_text
        elif name_usage == "BOTH":
            return main_in_text and brand_in_text
        
        return False
    
    def post_process_questions(self, questions: List[Dict], main_name: str, brand_names: List[str], content: str) -> List[Dict]:
        """ì§ˆë¬¸ í›„ì²˜ë¦¬ ë° ê²€ì¦"""
        if not questions:
            return []
        
        processed = []
        
        for q in questions:
            text = q.get("question", "")
            name_usage = q.get("name_usage", "")
            category = q.get("category", "")
            label = q.get("ë¼ë²¨", "")
            
            # 1. ëŒ€ëª…ì‚¬ ê²€ì¦
            if self.PRONOUN_RE.search(text):
                logger.warning(f"ëŒ€ëª…ì‚¬ ê²€ì¶œë¡œ ì œê±°: {text}")
                continue
            
            # 2. ê¸¸ì´ ê²€ì¦ (15-70ì)
            if not (15 <= len(text) <= 70):
                logger.warning(f"ê¸¸ì´ ì œí•œ ìœ„ë°˜: {text} ({len(text)}ì)")
                continue
            
            # 3. ì´ë¦„ ì‚¬ìš© ê²€ì¦
            if not self.validate_name_usage(text, name_usage, main_name, brand_names):
                logger.warning(f"ì´ë¦„ ì‚¬ìš© ê²€ì¦ ì‹¤íŒ¨: {text} ({name_usage})")
                continue
            
            # 4. ì¹´í…Œê³ ë¦¬ ê²€ì¦
            if category not in self.CATEGORIES:
                logger.warning(f"ì˜ëª»ëœ ì¹´í…Œê³ ë¦¬: {category}")
                continue
            
            # 5. ë¼ë²¨ ê²€ì¦
            if label not in self.LABELS:
                logger.warning(f"ì˜ëª»ëœ ë¼ë²¨: {label}")
                continue
            
            # 6. ë¬¸í•­ ì ìˆ˜ ê³„ì‚°
            s_q = self.calculate_question_score(text, content)
            if s_q < 0.75:
                logger.warning(f"í’ˆì§ˆ ì ìˆ˜ ë¯¸ë‹¬: {text} ({s_q:.2f})")
                continue
            
            processed.append(q)
        
        return processed
    
    @backoff.on_exception(backoff.expo, (aiohttp.ClientError, asyncio.TimeoutError), max_tries=3)
    async def call_api_v4(self, session: aiohttp.ClientSession, prompt: str, row_id: str) -> List[Dict]:
        """V4 API í˜¸ì¶œ"""
        if self.provider == "openai":
            headers = {
                "Authorization": f"Bearer {self.api_key}",
                "Content-Type": "application/json"
            }
            
            payload = {
                "model": self.model,
                "messages": [{"role": "user", "content": prompt}],
                "temperature": 0.7,
                "top_p": 0.9,
                "max_tokens": 3000,
                "response_format": {"type": "json_object"},
                "seed": self.seed
            }
            
            async with session.post(
                "https://api.openai.com/v1/chat/completions",
                headers=headers,
                json=payload,
                timeout=aiohttp.ClientTimeout(total=120)
            ) as response:
                if response.status == 429:
                    logger.warning(f"Rate limit for {row_id}, retrying...")
                    await asyncio.sleep(3)
                    raise aiohttp.ClientError("Rate limit")
                
                response.raise_for_status()
                result = await response.json()
                
                try:
                    content = result['choices'][0]['message']['content']
                    # JSON íŒŒì‹± ì‹œë„
                    if content.startswith('['):
                        return json.loads(content)
                    else:
                        # JSON ê°ì²´ê°€ ì˜¨ ê²½ìš° ë°°ì—´ë¡œ ê°ì‹¸ì„œ ë°˜í™˜
                        parsed = json.loads(content)
                        if isinstance(parsed, dict):
                            return [parsed]
                        return parsed
                except (json.JSONDecodeError, KeyError) as e:
                    logger.error(f"JSON íŒŒì‹± ì‹¤íŒ¨ for {row_id}: {e}")
                    logger.error(f"Response content: {content[:200]}...")
                    return []
        
        # Claude êµ¬í˜„ì€ ìƒëµ (OpenAI ìš°ì„ )
        return []
    
    async def generate_questions_for_drug(self, session: aiohttp.ClientSession, row_data: Dict, row_idx: int) -> List[Dict]:
        """ë‹¨ì¼ ì•½ì œì— ëŒ€í•œ ì§ˆë¬¸ ìƒì„±"""
        async with self.semaphore:
            start_time = time.time()
            row_id = f"row_{row_idx}"
            
            try:
                # NAME SLOTS ì¶”ì¶œ
                gubun = str(row_data.get('êµ¬ë¶„', ''))
                main_name, brand_names = self.extract_name_slots(gubun)
                content = str(row_data.get('ì„¸ë¶€ì¸ì •ê¸°ì¤€ ë° ë°©ë²•', ''))
                
                # í”„ë¡¬í”„íŠ¸ ìƒì„±
                prompt = self.create_drug_prompt_v4(row_data)
                
                # API í˜¸ì¶œ
                raw_questions = await self.call_api_v4(session, prompt, row_id)
                
                # í›„ì²˜ë¦¬
                validated_questions = self.post_process_questions(raw_questions, main_name, brand_names, content)
                
                # ê²°ê³¼ ê²€ì¦ (5~20ê°œ)
                if len(validated_questions) < 5:
                    logger.warning(f"{row_id}: ì§ˆë¬¸ ë¶€ì¡± ({len(validated_questions)}ê°œ)")
                elif len(validated_questions) > 20:
                    # S_q ì ìˆ˜ ê¸°ì¤€ìœ¼ë¡œ ìƒìœ„ 20ê°œë§Œ ì„ íƒ
                    scored = [(q, self.calculate_question_score(q.get("question", ""), content)) 
                             for q in validated_questions]
                    scored.sort(key=lambda x: x[1], reverse=True)
                    validated_questions = [q for q, _ in scored[:20]]
                
                # ê°ì‚¬ ë¡œê·¸
                elapsed_ms = int((time.time() - start_time) * 1000)
                self.audit_log.append({
                    'row_id': row_id,
                    'row_idx': row_idx,
                    'main_name': main_name,
                    'brand_count': len(brand_names),
                    'questions_generated': len(validated_questions),
                    'elapsed_ms': elapsed_ms,
                    'provider': self.provider,
                    'model': self.model
                })
                
                # ì§„í–‰ìƒí™© ì—…ë°ì´íŠ¸
                if self.progress_bar:
                    self.progress_bar.update(1)
                
                logger.info(f"ì™„ë£Œ: {row_id} - {len(validated_questions)}ê°œ ì§ˆë¬¸")
                return validated_questions
                
            except Exception as e:
                logger.error(f"ì§ˆë¬¸ ìƒì„± ì‹¤íŒ¨ {row_id}: {e}")
                if self.progress_bar:
                    self.progress_bar.update(1)
                return []
    
    def preprocess_data(self, df: pd.DataFrame) -> List[Dict]:
        """ë°ì´í„° ì „ì²˜ë¦¬"""
        processed_data = []
        
        for idx, row in df.iterrows():
            try:
                # NaN ê°’ ì²˜ë¦¬
                row_dict = {}
                for col in ['ì•½ì œë¶„ë¥˜ë²ˆí˜¸', 'ì•½ì œ ë¶„ë¥˜ëª…', 'êµ¬ë¶„', 'ì„¸ë¶€ì¸ì •ê¸°ì¤€ ë° ë°©ë²•']:
                    if col in row:
                        val = row[col]
                        if pd.isna(val):
                            row_dict[col] = ""
                        else:
                            row_dict[col] = str(val).strip()
                    else:
                        row_dict[col] = ""
                
                # í•„ìˆ˜ í•„ë“œ ê²€ì¦
                if not row_dict.get('êµ¬ë¶„') or not row_dict.get('ì„¸ë¶€ì¸ì •ê¸°ì¤€ ë° ë°©ë²•'):
                    logger.warning(f"í–‰ {idx}: í•„ìˆ˜ í•„ë“œ ëˆ„ë½")
                    continue
                
                processed_data.append(row_dict)
                
            except Exception as e:
                logger.warning(f"í–‰ {idx} ì „ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
                continue
        
        logger.info(f"ì „ì²˜ë¦¬ ì™„ë£Œ: {len(processed_data)}ê°œ í•­ëª©")
        return processed_data
    
    async def generate_all_questions(self, processed_data: List[Dict]) -> List[Dict]:
        """ëª¨ë“  ì•½ì œì— ëŒ€í•œ ì§ˆë¬¸ ìƒì„±"""
        # ì§„í–‰ìƒí™© ë°” ì´ˆê¸°í™”
        self.progress_bar = tqdm(total=len(processed_data), desc="ì§ˆë¬¸ ìƒì„± ì¤‘", unit="ì•½ì œ")
        
        async with aiohttp.ClientSession() as session:
            tasks = [
                self.generate_questions_for_drug(session, item, idx)
                for idx, item in enumerate(processed_data)
            ]
            
            results = await asyncio.gather(*tasks, return_exceptions=True)
            
            # ì§„í–‰ìƒí™© ë°” ì¢…ë£Œ
            if self.progress_bar:
                self.progress_bar.close()
                self.progress_bar = None
            
            # ê²°ê³¼ ì •ë¦¬
            all_questions = []
            for idx, result in enumerate(results):
                if isinstance(result, Exception):
                    logger.error(f"í–‰ {idx} ì‹¤íŒ¨: {result}")
                elif isinstance(result, list):
                    all_questions.extend(result)
            
            return all_questions
    
    def save_final_results(self, questions: List[Dict], output_path: str):
        """ìµœì¢… í˜•ì‹ìœ¼ë¡œ ê²°ê³¼ ì €ì¥"""
        try:
            # ì—‘ì…€ í˜•ì‹ìœ¼ë¡œ ì €ì¥ (ê³ ì • ì»¬ëŸ¼)
            df = pd.DataFrame(questions)
            
            # ì»¬ëŸ¼ ìˆœì„œ ê³ ì •
            final_columns = ['ì•½ì œë¶„ë¥˜ë²ˆí˜¸', 'ì•½ì œ ë¶„ë¥˜ëª…', 'êµ¬ë¶„', 'ì„¸ë¶€ì¸ì •ê¸°ì¤€ ë° ë°©ë²•', 'question', 'ë¼ë²¨']
            for col in final_columns:
                if col not in df.columns:
                    df[col] = ""
            
            df = df[final_columns]
            df.to_excel(output_path, index=False, engine='openpyxl')
            
            logger.info(f"ìµœì¢… ê²°ê³¼ ì €ì¥: {output_path} ({len(questions)}ê°œ ì§ˆë¬¸)")
            
        except Exception as e:
            logger.error(f"ê²°ê³¼ ì €ì¥ ì‹¤íŒ¨: {e}")
            raise
    
    def save_audit_log(self, output_dir: str = "."):
        """ê°ì‚¬ ë¡œê·¸ ì €ì¥"""
        try:
            audit_path = os.path.join(output_dir, "audit_log_drug_v4.csv")
            df = pd.DataFrame(self.audit_log)
            df.to_csv(audit_path, index=False, encoding='utf-8-sig')
            logger.info(f"ê°ì‚¬ ë¡œê·¸ ì €ì¥: {audit_path}")
        except Exception as e:
            logger.error(f"ê°ì‚¬ ë¡œê·¸ ì €ì¥ ì‹¤íŒ¨: {e}")
    
    def print_statistics(self, questions: List[Dict]):
        """í†µê³„ ì¶œë ¥"""
        if not questions:
            print("ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        total_questions = len(questions)
        
        # ë¼ë²¨ ë¶„í¬
        label_counts = {}
        for q in questions:
            label = q.get('ë¼ë²¨', 'UNKNOWN')
            label_counts[label] = label_counts.get(label, 0) + 1
        
        # í†µê³„ ì¶œë ¥
        print(f"\n=== V4 ì•½ì œ ì§ˆë¬¸ ìƒì„± í†µê³„ ===")
        print(f"ì´ ì§ˆë¬¸ ìˆ˜: {total_questions}")
        
        print(f"\n=== ë¼ë²¨ ë¶„í¬ ===")
        for label, count in label_counts.items():
            ratio = count / total_questions * 100 if total_questions > 0 else 0
            print(f"{label}: {count}ê°œ ({ratio:.1f}%)")


def main():
    parser = argparse.ArgumentParser(description="Pharma-Augment V4 ì•½ì œ ì§ˆë¬¸ ìƒì„±ê¸°")
    
    # í•„ìˆ˜ ì¸ì
    parser.add_argument("--excel", required=True, help="ì•½ì œ ì—‘ì…€ íŒŒì¼ ê²½ë¡œ")
    
    # ì„ íƒì  ì¸ì
    parser.add_argument("--sheet", default="Sheet1", help="ì‹œíŠ¸ëª…")
    parser.add_argument("--out", default="drug_questions_v4.xlsx", help="ìµœì¢… ì¶œë ¥ íŒŒì¼")
    parser.add_argument("--provider", choices=["openai", "claude"], default="openai", help="LLM ì œê³µì")
    parser.add_argument("--model", default="gpt-4o-mini", help="ëª¨ë¸ëª…")
    parser.add_argument("--concurrency", type=int, default=6, help="ë™ì‹œ ì‹¤í–‰ ìˆ˜")
    parser.add_argument("--seed", type=int, default=20250903, help="ëœë¤ ì‹œë“œ")
    
    args = parser.parse_args()
    
    try:
        # ì§ˆë¬¸ ìƒì„±ê¸° ì´ˆê¸°í™”
        generator = DrugGeneratorV4(
            provider=args.provider,
            model=args.model,
            concurrency=args.concurrency,
            seed=args.seed
        )
        
        print("ğŸ“‹ ì•½ì œ ë°ì´í„° ë¡œë“œ ì¤‘...")
        # ì—‘ì…€ ë°ì´í„° ë¡œë“œ
        df = generator.load_excel_data(args.excel, args.sheet)
        
        print("ğŸ”„ ë°ì´í„° ì „ì²˜ë¦¬ ì¤‘...")
        # ì „ì²˜ë¦¬
        processed_data = generator.preprocess_data(df)
        
        if not processed_data:
            logger.error("ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            sys.exit(1)
        
        print(f"ğŸ¤– V4 ì•½ì œ ì§ˆë¬¸ ìƒì„± ì‹œì‘: {len(processed_data)}ê°œ í–‰")
        # ì§ˆë¬¸ ìƒì„±
        results = asyncio.run(generator.generate_all_questions(processed_data))
        
        print("ğŸ’¾ ê²°ê³¼ ì €ì¥ ì¤‘...")
        # ê²°ê³¼ ì €ì¥
        generator.save_final_results(results, args.out)
        generator.save_audit_log()
        
        # í†µê³„ ì¶œë ¥
        generator.print_statistics(results)
        
        print("âœ… V4 ì•½ì œ ì§ˆë¬¸ ìƒì„± ì™„ë£Œ!")
        
    except KeyboardInterrupt:
        logger.info("ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë¨")
        sys.exit(1)
    except Exception as e:
        logger.error(f"ì‹¤í–‰ ì‹¤íŒ¨: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()