#!/usr/bin/env python3
"""
Pharma-Augment V4 - ì•½ì œ(DRUG) ê°•í™”ëœ ìƒì„±ê¸°
100% í–‰ ì»¤ë²„ë¦¬ì§€ë¥¼ ë³´ì¥í•˜ëŠ” fallback ë©”ì»¤ë‹ˆì¦˜ í¬í•¨
"""

import argparse
import asyncio
import json
import logging
import os
import re
import sys
import random
import math
from typing import Dict, List, Optional, Tuple, Any
import pandas as pd
import aiohttp
import backoff
from rapidfuzz import fuzz
from dotenv import load_dotenv
import tiktoken
from tqdm.asyncio import tqdm
import time

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('drug_generation_v4_robust.log', encoding='utf-8'),
        logging.StreamHandler(sys.stdout)
    ]
)
logger = logging.getLogger(__name__)

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

class DrugGeneratorV4Robust:
    def __init__(self, provider: str = "openai", model: str = "gpt-4o-mini", 
                 concurrency: int = 6, seed: int = 20250903):
        self.provider = provider
        self.model = model
        self.concurrency = concurrency
        self.seed = seed
        random.seed(seed)
        
        # API í‚¤ ì„¤ì •
        if provider == "openai":
            self.api_key = os.getenv("OPENAI_API_KEY")
            if not self.api_key:
                raise ValueError("OPENAI_API_KEYê°€ í™˜ê²½ë³€ìˆ˜ì— ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        elif provider == "claude":
            self.api_key = os.getenv("ANTHROPIC_API_KEY")
            if not self.api_key:
                raise ValueError("ANTHROPIC_API_KEYê°€ í™˜ê²½ë³€ìˆ˜ì— ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        # ì„¸ë§ˆí¬ì–´ë¡œ ë™ì‹œì„± ì œì–´
        self.semaphore = asyncio.Semaphore(concurrency)
        
        # ëŒ€ëª…ì‚¬ ì°¨ë‹¨ ì •ê·œì‹
        self.PRONOUN_RE = re.compile(r"(ì´|ê·¸|í•´ë‹¹|ë³¸|ë™)\s?(ì•½|ì•½ì œ|ì œì œ|ì œí’ˆ)|ì´ê²ƒ|ê·¸ê²ƒ")
        
        # V4 ì¹´í…Œê³ ë¦¬ (9ê°œ)
        self.CATEGORIES = [
            "ë²”ìœ„", "ìš”ê±´/ê¸°ì¤€", "ì˜¤í”„ë¼ë²¨/í—ˆê°€ë²”ìœ„", "ê¸°ê°„/ì‹œì ", "ì „í™˜", 
            "ì¦ë¹™/ì„œë¥˜", "ë³¸ì¸ë¶€ë‹´/ê¸‰ì—¬êµ¬ë¶„", "ëŒ€ìƒêµ°", "ì ˆì°¨/í”„ë¡œì„¸ìŠ¤"
        ]
        
        # ë¼ë²¨ íƒ€ì…
        self.LABELS = ["POSITIVE", "NEGATIVE", "HARD_NEGATIVE"]
        
        # ê°ì‚¬ ë¡œê·¸
        self.audit_log = []
        self.progress_bar = None
        self.failed_rows = []  # ì‹¤íŒ¨í•œ í–‰ ì¶”ì 
    
    def load_excel_data(self, excel_path: str, sheet_name: str = "Sheet1") -> pd.DataFrame:
        """ì—‘ì…€ íŒŒì¼ ë¡œë“œ"""
        try:
            df = pd.read_excel(excel_path, sheet_name=sheet_name)
            logger.info(f"ì—‘ì…€ íŒŒì¼ ë¡œë“œ ì™„ë£Œ: {df.shape[0]}í–‰ {df.shape[1]}ì—´")
            
            # UTF-8 ë””ì½”ë”© ë¬¸ì œ í•´ê²° ì‹œë„
            for col in df.columns:
                if df[col].dtype == 'object':
                    df[col] = df[col].astype(str)
            
            # ì»¬ëŸ¼ëª… í™•ì¸ ë° ë§¤í•‘
            expected_cols = ['ì•½ì œë¶„ë¥˜ë²ˆí˜¸', 'ì•½ì œ ë¶„ë¥˜ëª…', 'êµ¬ë¶„', 'ì„¸ë¶€ì¸ì •ê¸°ì¤€ ë° ë°©ë²•']
            actual_cols = list(df.columns)
            
            logger.info(f"ì‹¤ì œ ì»¬ëŸ¼: {actual_cols}")
            
            # ì»¬ëŸ¼ ìˆœì„œëŒ€ë¡œ ë§¤í•‘ (ìˆœì„œ ê¸°ë°˜)
            if len(actual_cols) >= 4:
                column_mapping = dict(zip(actual_cols[:4], expected_cols))
                df = df.rename(columns=column_mapping)
                logger.info(f"ì»¬ëŸ¼ ë§¤í•‘ ì™„ë£Œ: {column_mapping}")
            
            return df
            
        except Exception as e:
            logger.error(f"ì—‘ì…€ íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}")
            raise
    
    def extract_name_slots(self, gubun: str) -> Tuple[str, List[str]]:
        """êµ¬ë¶„ í•„ë“œì—ì„œ main_nameê³¼ brand_names ì¶”ì¶œ"""
        # main_name = ê´„í˜¸ ì•ì˜ ì£¼ ì•½ì œëª…
        main_name = ""
        brand_names = []
        
        # ê´„í˜¸ ì• ë¶€ë¶„ì„ main_nameìœ¼ë¡œ
        paren_match = re.search(r'^([^(]+)', gubun)
        if paren_match:
            main_name = paren_match.group(1).strip()
        
        # "í’ˆëª…:" ë’¤ì˜ í’ˆëª…ë“¤ì„ ì¶”ì¶œ
        brand_match = re.search(r'í’ˆ\s*ëª…\s*[:ï¼š]\s*([^)]+)', gubun)
        if brand_match:
            brand_text = brand_match.group(1).strip()
            # 'Â·' ë˜ëŠ” '/' ê¸°ì¤€ìœ¼ë¡œ ë¶„ë¦¬
            brand_names = re.split(r'[Â·/]+', brand_text)
            brand_names = [name.strip() for name in brand_names if name.strip()]
        
        return main_name, brand_names
    
    def create_basic_questions(self, row_data: Dict) -> List[Dict]:
        """ê¸°ë³¸ ì§ˆë¬¸ ìƒì„± (fallbackìš©)"""
        drug_code = row_data.get('ì•½ì œë¶„ë¥˜ë²ˆí˜¸', '')
        drug_name = row_data.get('ì•½ì œ ë¶„ë¥˜ëª…', '')
        gubun = row_data.get('êµ¬ë¶„', '')
        content = row_data.get('ì„¸ë¶€ì¸ì •ê¸°ì¤€ ë° ë°©ë²•', '')
        
        main_name, brand_names = self.extract_name_slots(gubun)
        
        # ì•ˆì „í•œ ê¸°ë³¸ ì§ˆë¬¸ë“¤ (ëŒ€ëª…ì‚¬ ì—†ìŒ, ì ì ˆí•œ ê¸¸ì´)
        basic_questions = []
        
        if main_name:
            basic_questions.extend([
                {"question": f"{main_name}ì˜ ê¸‰ì—¬ ì¸ì • ê¸°ì¤€ì€ ë¬´ì—‡ì¸ê°€ìš”?", "ë¼ë²¨": "POSITIVE", "name_usage": "MAIN", "category": "ìš”ê±´/ê¸°ì¤€"},
                {"question": f"{main_name} ì‚¬ìš© ì‹œ í•„ìš”í•œ ì¦ë¹™ì„œë¥˜ëŠ”?", "ë¼ë²¨": "POSITIVE", "name_usage": "MAIN", "category": "ì¦ë¹™/ì„œë¥˜"},
                {"question": f"{main_name}ì˜ ë³´í—˜ê¸‰ì—¬ ì ìš© ë²”ìœ„ëŠ”?", "ë¼ë²¨": "POSITIVE", "name_usage": "MAIN", "category": "ë²”ìœ„"},
                {"question": f"{main_name} ì²˜ë°© ì‹œ ì£¼ì˜ì‚¬í•­ì€ ë¬´ì—‡ì¸ê°€ìš”?", "ë¼ë²¨": "POSITIVE", "name_usage": "MAIN", "category": "ì ˆì°¨/í”„ë¡œì„¸ìŠ¤"},
                {"question": f"{main_name}ì˜ íˆ¬ì—¬ ê¸°ê°„ ì œí•œì€?", "ë¼ë²¨": "POSITIVE", "name_usage": "MAIN", "category": "ê¸°ê°„/ì‹œì "}
            ])
        
        if brand_names:
            for brand in brand_names[:2]:  # ìµœëŒ€ 2ê°œ ë¸Œëœë“œë§Œ
                basic_questions.extend([
                    {"question": f"{brand}ì˜ ê¸‰ì—¬ ì¸ì • ìš”ê±´ì€?", "ë¼ë²¨": "POSITIVE", "name_usage": "BRAND", "category": "ìš”ê±´/ê¸°ì¤€"},
                    {"question": f"{brand} ì‚¬ìš© ëŒ€ìƒêµ°ì€ ë¬´ì—‡ì¸ê°€ìš”?", "ë¼ë²¨": "POSITIVE", "name_usage": "BRAND", "category": "ëŒ€ìƒêµ°"}
                ])
        
        if main_name and brand_names:
            brand = brand_names[0]
            basic_questions.extend([
                {"question": f"{main_name}({brand})ì˜ ë³¸ì¸ë¶€ë‹´ ê¸°ì¤€ì€?", "ë¼ë²¨": "POSITIVE", "name_usage": "BOTH", "category": "ë³¸ì¸ë¶€ë‹´/ê¸‰ì—¬êµ¬ë¶„"},
                {"question": f"{brand}({main_name}) ì „í™˜ ì‹œ ì¡°ê±´ì€?", "ë¼ë²¨": "POSITIVE", "name_usage": "BOTH", "category": "ì „í™˜"}
            ])
        
        # NEGATIVE ì§ˆë¬¸ ì¶”ê°€
        basic_questions.extend([
            {"question": "ì†Œì•„ê³¼ í™˜ìì˜ íŠ¹ë³„ ê¸‰ì—¬ ê¸°ì¤€ì€?", "ë¼ë²¨": "NEGATIVE", "name_usage": "NONE", "category": "ëŒ€ìƒêµ°"},
            {"question": "ì™¸ë˜ ì§„ë£Œ ì‹œ ìˆ˜ê°€ ì‚°ì • ë°©ë²•ì€?", "ë¼ë²¨": "NEGATIVE", "name_usage": "NONE", "category": "ì ˆì°¨/í”„ë¡œì„¸ìŠ¤"}
        ])
        
        # ê° ì§ˆë¬¸ì— í•„ìˆ˜ í•„ë“œ ì¶”ê°€
        for q in basic_questions:
            q.update({
                "ì•½ì œë¶„ë¥˜ë²ˆí˜¸": drug_code,
                "ì•½ì œ ë¶„ë¥˜ëª…": drug_name,
                "êµ¬ë¶„": gubun,
                "ì„¸ë¶€ì¸ì •ê¸°ì¤€ ë° ë°©ë²•": content[:100] + "..." if len(content) > 100 else content
            })
        
        return basic_questions[:10]  # ìµœëŒ€ 10ê°œë¡œ ì œí•œ
    
    def create_drug_prompt_v4_relaxed(self, row_data: Dict) -> str:
        """ì™„í™”ëœ V4 ì•½ì œ í”„ë¡¬í”„íŠ¸ (fallbackìš©)"""
        drug_code = row_data.get('ì•½ì œë¶„ë¥˜ë²ˆí˜¸', '')
        drug_name = row_data.get('ì•½ì œ ë¶„ë¥˜ëª…', '')
        gubun = row_data.get('êµ¬ë¶„', '')
        content = row_data.get('ì„¸ë¶€ì¸ì •ê¸°ì¤€ ë° ë°©ë²•', '')
        
        main_name, brand_names = self.extract_name_slots(gubun)
        brand_names_json = json.dumps(brand_names, ensure_ascii=False)
        
        return f"""[ROLE]
ë„ˆëŠ” ì˜ë£Œ ë³´í—˜ ì•½ì œ ì§ˆë¬¸ ìƒì„±ê¸°ë‹¤. ë°˜ë“œì‹œ 5ê°œ ì´ìƒì˜ ì§ˆë¬¸ì„ ìƒì„±í•´ì•¼ í•œë‹¤.

[INPUT]
- ì•½ì œë¶„ë¥˜ë²ˆí˜¸: {drug_code}
- ì•½ì œ ë¶„ë¥˜ëª…: {drug_name}
- êµ¬ë¶„: {gubun}
- ì„¸ë¶€ì¸ì •ê¸°ì¤€ ë° ë°©ë²•: \"\"\"{content}\"\"\"

[RELAXED RULES - ë°˜ë“œì‹œ ì¤€ìˆ˜]
1) ìµœì†Œ 5ê°œ ì´ìƒ ì§ˆë¬¸ ìƒì„± (í•„ìˆ˜)
2) ëŒ€ëª…ì‚¬ ê¸ˆì§€: "ì´ê²ƒ", "ê·¸ê²ƒ", "í•´ë‹¹ ì•½ì œ", "ë³¸ ì œì œ" ë“± ì‚¬ìš© ê¸ˆì§€
3) ê¸¸ì´: 10~80ì (ì™„í™”ë¨)
4) ë¼ë²¨: POSITIVE(60% ì´ìƒ), NEGATIVE, HARD_NEGATIVE í¬í•¨

[OUTPUT - JSON ë°°ì—´ë§Œ ì¶œë ¥]
[
  {{"ì•½ì œë¶„ë¥˜ë²ˆí˜¸":"{drug_code}","ì•½ì œ ë¶„ë¥˜ëª…":"{drug_name}","êµ¬ë¶„":"{gubun}","ì„¸ë¶€ì¸ì •ê¸°ì¤€ ë° ë°©ë²•":"{content[:50]}...","question":"ê¸‰ì—¬ ì¸ì • ê¸°ì¤€ì€ ë¬´ì—‡ì¸ê°€ìš”?","ë¼ë²¨":"POSITIVE"}},
  {{"ì•½ì œë¶„ë¥˜ë²ˆí˜¸":"{drug_code}","ì•½ì œ ë¶„ë¥˜ëª…":"{drug_name}","êµ¬ë¶„":"{gubun}","ì„¸ë¶€ì¸ì •ê¸°ì¤€ ë° ë°©ë²•":"{content[:50]}...","question":"ì‚¬ìš© ëŒ€ìƒêµ°ì€?","ë¼ë²¨":"POSITIVE"}},
  {{"ì•½ì œë¶„ë¥˜ë²ˆí˜¸":"{drug_code}","ì•½ì œ ë¶„ë¥˜ëª…":"{drug_name}","êµ¬ë¶„":"{gubun}","ì„¸ë¶€ì¸ì •ê¸°ì¤€ ë° ë°©ë²•":"{content[:50]}...","question":"íˆ¬ì—¬ ê¸°ê°„ì€?","ë¼ë²¨":"POSITIVE"}},
  {{"ì•½ì œë¶„ë¥˜ë²ˆí˜¸":"{drug_code}","ì•½ì œ ë¶„ë¥˜ëª…":"{drug_name}","êµ¬ë¶„":"{gubun}","ì„¸ë¶€ì¸ì •ê¸°ì¤€ ë° ë°©ë²•":"{content[:50]}...","question":"í•„ìš”í•œ ê²€ì‚¬ëŠ”?","ë¼ë²¨":"POSITIVE"}},
  {{"ì•½ì œë¶„ë¥˜ë²ˆí˜¸":"{drug_code}","ì•½ì œ ë¶„ë¥˜ëª…":"{drug_name}","êµ¬ë¶„":"{gubun}","ì„¸ë¶€ì¸ì •ê¸°ì¤€ ë° ë°©ë²•":"{content[:50]}...","question":"ì²˜ë°©ì „ ì‘ì„± ë°©ë²•ì€?","ë¼ë²¨":"NEGATIVE"}}
]"""
    
    def post_process_relaxed(self, questions: List[Dict]) -> List[Dict]:
        """ì™„í™”ëœ í›„ì²˜ë¦¬ (fallbackìš©)"""
        if not questions:
            return []
        
        processed = []
        
        for q in questions:
            text = q.get("question", "")
            label = q.get("ë¼ë²¨", "")
            
            # 1. ëŒ€ëª…ì‚¬ ê²€ì¦ë§Œ (ë‹¤ë¥¸ ê¸°ì¤€ ì™„í™”)
            if self.PRONOUN_RE.search(text):
                logger.warning(f"ëŒ€ëª…ì‚¬ ê²€ì¶œë¡œ ì œê±°: {text}")
                continue
            
            # 2. ì™„í™”ëœ ê¸¸ì´ ê²€ì¦ (10-80ì)
            if not (10 <= len(text) <= 80):
                logger.warning(f"ê¸¸ì´ ì œí•œ ìœ„ë°˜: {text} ({len(text)}ì)")
                continue
            
            # 3. ë¼ë²¨ ê²€ì¦ (ì™„í™”)
            if label not in self.LABELS:
                q["ë¼ë²¨"] = "POSITIVE"  # ê¸°ë³¸ê°’ìœ¼ë¡œ ìˆ˜ì •
            
            processed.append(q)
        
        return processed
    
    def create_drug_prompt_v4(self, row_data: Dict) -> str:
        """ì›ë³¸ V4 ì•½ì œ í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        drug_code = row_data.get('ì•½ì œë¶„ë¥˜ë²ˆí˜¸', '')
        drug_name = row_data.get('ì•½ì œ ë¶„ë¥˜ëª…', '')
        gubun = row_data.get('êµ¬ë¶„', '')
        content = row_data.get('ì„¸ë¶€ì¸ì •ê¸°ì¤€ ë° ë°©ë²•', '')
        
        main_name, brand_names = self.extract_name_slots(gubun)
        brand_names_json = json.dumps(brand_names, ensure_ascii=False)
        
        return f"""[ROLE]
ë„ˆëŠ” ì˜ë£Œ ë³´í—˜ ì‹¬ì‚¬Â·ìˆ˜ê°€ ì•½ì œ ë°ì´í„°ë¥¼ ì„ë² ë”© í•™ìŠµìš© ì§ˆë¬¸ ì„¸íŠ¸ë¡œ ë³€í™˜í•˜ëŠ” ì—ì´ì „íŠ¸ë‹¤.
ì…ë ¥ 1í–‰(ì•½ì œ ë‹¨ìœ„)ì„ ë°›ì•„ ì§ˆë¬¸ì„ ìµœì†Œ 5ê°œ~ìµœëŒ€ 20ê°œ ìƒì„±í•˜ê³ , ê° ì§ˆë¬¸ì— ë¼ë²¨ì„ ë¶€ì—¬í•œë‹¤.
ìµœì¢… ì œì¶œ í˜•ì‹ì€ ë°˜ë“œì‹œ ì•„ë˜ 6ê°œ í•„ë“œë§Œì„ ê°€ì§€ëŠ” JSON ë°°ì—´ì´ë‹¤.

[INPUT]
- ì•½ì œë¶„ë¥˜ë²ˆí˜¸: {drug_code}
- ì•½ì œ ë¶„ë¥˜ëª…: {drug_name}
- êµ¬ë¶„: {gubun}
- ì„¸ë¶€ì¸ì •ê¸°ì¤€ ë° ë°©ë²•: \"\"\"
{content}
\"\"\"

[NAME SLOTS] (í”„ë¡¬í”„íŠ¸ ë‚´ë¶€ ì¶”ì¶œ ê·œì¹™)
- main_name = "{main_name}"
- brand_names = {brand_names_json}

[GENERATION RULES]
1) ì§ˆë¬¸ ìˆ˜: 5~20ê°œ. ìƒì„± ê°€ëŠ¥í•œ ë§Œí¼ ë§Œë“¤ë˜ í’ˆì§ˆ í•„í„° í†µê³¼ë¶„ë§Œ ì±„íƒ.
2) ë¬¸í˜•: WH ê°œë°©í˜•(ë¬´ì—‡/ì–´ë–¤/ì–¸ì œ/ì–´ë–»ê²Œ/ì™œ), 1ë¬¸ì¥ 1ë…¼ì , ì™¸ë¶€ ì§€ì‹/ì¶”ì • ê¸ˆì§€.
3) ê¸¸ì´: 15~70ì(í›ˆë ¨ ê¸°ì¤€). 12~50ìëŠ” ê²€ì¦ì…‹ ì¶”ì¶œ ì‹œ ê°€ì .
4) ëŒ€ëª…ì‚¬ ê¸ˆì§€: "(ì´|ê·¸|í•´ë‹¹|ë³¸|ë™) (ì•½|ì•½ì œ|ì œì œ|ì œí’ˆ)|ì´ê²ƒ|ê·¸ê²ƒ" í¬í•¨ ì‹œ íê¸°Â·ì¬ìƒì„±.
5) ì´ë¦„ ì‚¬ìš© ë¹„ìœ¨(ì„¸íŠ¸ ìˆ˜ì¤€ ê°•ì œ):
   - MAIN(ì£¼ ì•½ì œëª…ë§Œ í¬í•¨) 30â€“40%
   - BRAND(í’ˆëª…ë§Œ í¬í•¨)     30â€“40%  
   - BOTH(ë‘˜ ë‹¤ í¬í•¨)        20â€“30%
   - brand_names == [] ì´ë©´: MAIN 70â€“80%, BOTH 20â€“30%
   - brand_names ê¸¸ì´ == 1 ì´ë©´: MAIN 35â€“45%, BRAND 30â€“40%, BOTH 20â€“30%
   - ê²€ì¦: MAINì´ë©´ brand ë¯¸í¬í•¨, BRANDë©´ main ë¯¸í¬í•¨, BOTHë©´ ë‘˜ ë‹¤ í¬í•¨.
6) ì¹´í…Œê³ ë¦¬(ì§ˆë¬¸ë§ˆë‹¤ ì •í™•íˆ 1ê°œ ë¶€ì—¬, ì„¸íŠ¸ ë‚´ ìµœì†Œ 4ì¢… ì´ìƒ ë“±ì¥, ë‹¨ì¼ ì¹´í…Œê³ ë¦¬ â‰¤ 40%)
   {{ë²”ìœ„, ìš”ê±´/ê¸°ì¤€, ì˜¤í”„ë¼ë²¨/í—ˆê°€ë²”ìœ„, ê¸°ê°„/ì‹œì , ì „í™˜(ê²½êµ¬â†”ì£¼ì‚¬),
    ì¦ë¹™/ì„œë¥˜, ë³¸ì¸ë¶€ë‹´/ê¸‰ì—¬êµ¬ë¶„, ëŒ€ìƒêµ°, ì ˆì°¨/í”„ë¡œì„¸ìŠ¤}}
7) DRUG ì„¸íŠ¸ì—ì„œ íŠ¹íˆ í¬í•¨ ê¶Œì¥: ê¸°ê°„/ì‹œì , ì „í™˜(ê²½êµ¬â†”ì£¼ì‚¬), ë³¸ì¸ë¶€ë‹´, ëŒ€ìƒêµ° íŠ¹ë¡€.

[LABELING]
- POSITIVE: ë³¸ ì…ë ¥(êµ¬ë¶„/ì„¸ë¶€ì¸ì •ê¸°ì¤€)ì— ì§ì ‘ ë¶€í•©í•˜ëŠ” ì§ˆë¬¸.
- NEGATIVE: ì „í˜€ ë‹¤ë¥¸ ì•½ì œÂ·ì¡°í•­ì„ ì „ì œë¡œ í•œ ëª…ë°±íˆ ë¬´ê´€í•œ ì§ˆë¬¸.
- HARD_NEGATIVE: í‘œë©´ í† í°ì€ ìœ ì‚¬í•˜ë‚˜ í•µì‹¬ ì°¨ì›ì´ ì–´ê¸‹ë‚˜ëŠ” near-miss
  (ì˜ˆ: ê°™ì€ ì•½ì œì§€ë§Œ 'ì¡°í˜ˆëª¨ì„¸í¬ì´ì‹'â†”'ì‹ ì¥ì´ì‹', 'ì„±ì¸'â†”'ì†Œì•„', 'ì´ˆê¸°'â†”'ì¬ë°œ',
   'ê²½êµ¬'â†”'ì£¼ì‚¬', 'ê¸‰ì—¬'â†”'ì „ì•¡ ë³¸ì¸ë¶€ë‹´', 'ê¸°ê°„ A'â†”'ê¸°ê°„ B' ë“±).

[OUTPUT â€” ì œì¶œìš© ê³ ì • ìŠ¤í‚¤ë§ˆ(JSON ë°°ì—´ë§Œ ì¶œë ¥)]
[
  {{"ì•½ì œë¶„ë¥˜ë²ˆí˜¸":"{drug_code}","ì•½ì œ ë¶„ë¥˜ëª…":"{drug_name}","êµ¬ë¶„":"{gubun}","ì„¸ë¶€ì¸ì •ê¸°ì¤€ ë° ë°©ë²•":"{content[:100]}...","question":"...","ë¼ë²¨":"POSITIVE|NEGATIVE|HARD_NEGATIVE"}},
  ...
]"""

    def calculate_question_score(self, text: str, content: str) -> float:
        """ë¬¸í•­ ì ìˆ˜ S_q ê³„ì‚°"""
        # ê¸¸ì´ ì ìˆ˜ (15-70ì ê¸°ì¤€, 45ìê°€ ìµœì )
        length = len(text)
        length_score = max(0, min(1, 1 - abs(length - 45) / 30))
        
        # WH ì ìˆ˜
        wh_patterns = r'(ë¬´ì—‡|ì–´ë–¤|ì–¸ì œ|ì–´ë–»ê²Œ|ì™œ|ëˆ„ê°€|ì–´ë””|ëª‡)'
        if re.search(f'^{wh_patterns}', text):
            wh_score = 1.0
        elif re.search(wh_patterns, text):
            wh_score = 0.6
        else:
            wh_score = 0.2
        
        # ë‹¨ì¼ ë…¼ì  ì ìˆ˜
        multi_issue_count = text.count(',') + text.count('ë°') + text.count('/')
        single_issue = 1.0 if multi_issue_count <= 1 else 0.3
        
        # ëŒ€ëª…ì‚¬ íŒ¨ë„í‹°
        pronoun_penalty = -1.0 if self.PRONOUN_RE.search(text) else 0.0
        
        # ì›ë¬¸ ì¤‘ì²© ì ìˆ˜ (ê°„ë‹¨í•œ í† í° êµì§‘í•©)
        text_tokens = set(re.findall(r'\w+', text))
        content_tokens = set(re.findall(r'\w+', content))
        if len(text_tokens) > 0:
            overlap = len(text_tokens & content_tokens) / len(text_tokens)
        else:
            overlap = 0.0
        
        # ìµœì¢… ì ìˆ˜ ê³„ì‚°
        s_q = (0.25 * length_score + 0.25 * wh_score + 
               0.25 * single_issue + 0.25 * overlap + pronoun_penalty)
        
        return max(0.0, min(1.0, s_q))
    
    def validate_name_usage(self, text: str, name_usage: str, main_name: str, brand_names: List[str]) -> bool:
        """ì´ë¦„ ì‚¬ìš© ê²€ì¦"""
        main_in_text = main_name in text if main_name else False
        brand_in_text = any(brand in text for brand in brand_names)
        
        if name_usage == "MAIN":
            return main_in_text and not brand_in_text
        elif name_usage == "BRAND":
            return brand_in_text and not main_in_text
        elif name_usage == "BOTH":
            return main_in_text and brand_in_text
        
        return False
    
    def post_process_questions(self, questions: List[Dict], main_name: str, brand_names: List[str], content: str) -> List[Dict]:
        """ì§ˆë¬¸ í›„ì²˜ë¦¬ ë° ê²€ì¦"""
        if not questions:
            return []
        
        processed = []
        
        for q in questions:
            text = q.get("question", "")
            name_usage = q.get("name_usage", "")
            category = q.get("category", "")
            label = q.get("ë¼ë²¨", "")
            
            # 1. ëŒ€ëª…ì‚¬ ê²€ì¦
            if self.PRONOUN_RE.search(text):
                logger.warning(f"ëŒ€ëª…ì‚¬ ê²€ì¶œë¡œ ì œê±°: {text}")
                continue
            
            # 2. ê¸¸ì´ ê²€ì¦ (15-70ì)
            if not (15 <= len(text) <= 70):
                logger.warning(f"ê¸¸ì´ ì œí•œ ìœ„ë°˜: {text} ({len(text)}ì)")
                continue
            
            # 3. ì´ë¦„ ì‚¬ìš© ê²€ì¦ (ì™„í™”)
            if name_usage in ["MAIN", "BRAND", "BOTH"]:
                if not self.validate_name_usage(text, name_usage, main_name, brand_names):
                    logger.warning(f"ì´ë¦„ ì‚¬ìš© ê²€ì¦ ì‹¤íŒ¨: {text} ({name_usage})")
                    continue
            
            # 4. ì¹´í…Œê³ ë¦¬ ê²€ì¦ (ì™„í™”)
            if category not in self.CATEGORIES:
                q["category"] = "ìš”ê±´/ê¸°ì¤€"  # ê¸°ë³¸ê°’ìœ¼ë¡œ ìˆ˜ì •
            
            # 5. ë¼ë²¨ ê²€ì¦
            if label not in self.LABELS:
                q["ë¼ë²¨"] = "POSITIVE"  # ê¸°ë³¸ê°’ìœ¼ë¡œ ìˆ˜ì •
            
            # 6. ë¬¸í•­ ì ìˆ˜ ê³„ì‚° (ì™„í™”ëœ ê¸°ì¤€)
            s_q = self.calculate_question_score(text, content)
            if s_q < 0.6:  # ê¸°ì¤€ì„ 0.75 â†’ 0.6ìœ¼ë¡œ ì™„í™”
                logger.warning(f"í’ˆì§ˆ ì ìˆ˜ ë¯¸ë‹¬: {text} ({s_q:.2f})")
                continue
            
            processed.append(q)
        
        return processed
    
    @backoff.on_exception(backoff.expo, (aiohttp.ClientError, asyncio.TimeoutError), max_tries=3)
    async def call_api_v4(self, session: aiohttp.ClientSession, prompt: str, row_id: str) -> List[Dict]:
        """V4 API í˜¸ì¶œ"""
        if self.provider == "openai":
            headers = {
                "Authorization": f"Bearer {self.api_key}",
                "Content-Type": "application/json"
            }
            
            payload = {
                "model": self.model,
                "messages": [{"role": "user", "content": prompt}],
                "temperature": 0.7,
                "top_p": 0.9,
                "max_tokens": 3000,
                "response_format": {"type": "json_object"},
                "seed": self.seed
            }
            
            async with session.post(
                "https://api.openai.com/v1/chat/completions",
                headers=headers,
                json=payload,
                timeout=aiohttp.ClientTimeout(total=120)
            ) as response:
                if response.status == 429:
                    logger.warning(f"Rate limit for {row_id}, retrying...")
                    await asyncio.sleep(3)
                    raise aiohttp.ClientError("Rate limit")
                
                response.raise_for_status()
                result = await response.json()
                
                try:
                    content = result['choices'][0]['message']['content']
                    # JSON íŒŒì‹± ì‹œë„
                    if content.startswith('['):
                        return json.loads(content)
                    else:
                        # JSON ê°ì²´ê°€ ì˜¨ ê²½ìš° ë°°ì—´ë¡œ ê°ì‹¸ì„œ ë°˜í™˜
                        parsed = json.loads(content)
                        if isinstance(parsed, dict):
                            return [parsed]
                        return parsed
                except (json.JSONDecodeError, KeyError) as e:
                    logger.error(f"JSON íŒŒì‹± ì‹¤íŒ¨ for {row_id}: {e}")
                    logger.error(f"Response content: {content[:200]}...")
                    return []
        
        # Claude êµ¬í˜„ì€ ìƒëµ (OpenAI ìš°ì„ )
        return []
    
    async def generate_questions_for_drug(self, session: aiohttp.ClientSession, row_data: Dict, row_idx: int) -> List[Dict]:
        """ë‹¨ì¼ ì•½ì œì— ëŒ€í•œ ì§ˆë¬¸ ìƒì„± (ê°•í™”ëœ fallback í¬í•¨)"""
        async with self.semaphore:
            start_time = time.time()
            row_id = f"row_{row_idx}"
            
            try:
                # NAME SLOTS ì¶”ì¶œ
                gubun = str(row_data.get('êµ¬ë¶„', ''))
                main_name, brand_names = self.extract_name_slots(gubun)
                content = str(row_data.get('ì„¸ë¶€ì¸ì •ê¸°ì¤€ ë° ë°©ë²•', ''))
                
                validated_questions = []
                attempt_count = 0
                
                # 1ì°¨ ì‹œë„: ì›ë³¸ V4 í”„ë¡¬í”„íŠ¸
                try:
                    attempt_count += 1
                    prompt = self.create_drug_prompt_v4(row_data)
                    raw_questions = await self.call_api_v4(session, prompt, row_id)
                    validated_questions = self.post_process_questions(raw_questions, main_name, brand_names, content)
                    
                    if len(validated_questions) >= 5:
                        logger.info(f"{row_id}: 1ì°¨ ì„±ê³µ - {len(validated_questions)}ê°œ")
                    else:
                        raise ValueError(f"ì§ˆë¬¸ ë¶€ì¡±: {len(validated_questions)}ê°œ")
                        
                except Exception as e:
                    logger.warning(f"{row_id}: 1ì°¨ ì‹œë„ ì‹¤íŒ¨ - {e}")
                    
                # 2ì°¨ ì‹œë„: ì™„í™”ëœ í”„ë¡¬í”„íŠ¸
                if len(validated_questions) < 5:
                    try:
                        attempt_count += 1
                        prompt_relaxed = self.create_drug_prompt_v4_relaxed(row_data)
                        raw_questions = await self.call_api_v4(session, prompt_relaxed, row_id)
                        validated_questions = self.post_process_relaxed(raw_questions)
                        
                        if len(validated_questions) >= 5:
                            logger.info(f"{row_id}: 2ì°¨ ì„±ê³µ - {len(validated_questions)}ê°œ")
                        else:
                            raise ValueError(f"ì§ˆë¬¸ ë¶€ì¡±: {len(validated_questions)}ê°œ")
                            
                    except Exception as e:
                        logger.warning(f"{row_id}: 2ì°¨ ì‹œë„ ì‹¤íŒ¨ - {e}")
                
                # 3ì°¨ ì‹œë„: ê¸°ë³¸ ì§ˆë¬¸ ìƒì„± (fallback)
                if len(validated_questions) < 5:
                    attempt_count += 1
                    logger.warning(f"{row_id}: fallbackìœ¼ë¡œ ê¸°ë³¸ ì§ˆë¬¸ ìƒì„±")
                    validated_questions = self.create_basic_questions(row_data)
                
                # ìµœì¢… ê²€ì¦ (20ê°œ ì´ˆê³¼ ì‹œ ìƒìœ„ 20ê°œë§Œ)
                if len(validated_questions) > 20:
                    # S_q ì ìˆ˜ ê¸°ì¤€ìœ¼ë¡œ ìƒìœ„ 20ê°œë§Œ ì„ íƒ
                    scored = [(q, self.calculate_question_score(q.get("question", ""), content)) 
                             for q in validated_questions]
                    scored.sort(key=lambda x: x[1], reverse=True)
                    validated_questions = [q for q, _ in scored[:20]]
                
                # ê°ì‚¬ ë¡œê·¸
                elapsed_ms = int((time.time() - start_time) * 1000)
                self.audit_log.append({
                    'row_id': row_id,
                    'row_idx': row_idx,
                    'main_name': main_name,
                    'brand_count': len(brand_names),
                    'questions_generated': len(validated_questions),
                    'attempt_count': attempt_count,
                    'elapsed_ms': elapsed_ms,
                    'provider': self.provider,
                    'model': self.model,
                    'success': len(validated_questions) >= 5
                })
                
                # ì‹¤íŒ¨í•œ í–‰ ì¶”ì 
                if len(validated_questions) < 5:
                    self.failed_rows.append({
                        'row_idx': row_idx,
                        'row_data': row_data,
                        'question_count': len(validated_questions)
                    })
                
                # ì§„í–‰ìƒí™© ì—…ë°ì´íŠ¸
                if self.progress_bar:
                    self.progress_bar.update(1)
                
                status = "ì„±ê³µ" if len(validated_questions) >= 5 else "ì‹¤íŒ¨"
                logger.info(f"ì™„ë£Œ: {row_id} - {len(validated_questions)}ê°œ ì§ˆë¬¸ ({status})")
                return validated_questions
                
            except Exception as e:
                logger.error(f"ì§ˆë¬¸ ìƒì„± ì™„ì „ ì‹¤íŒ¨ {row_id}: {e}")
                
                # ì™„ì „ ì‹¤íŒ¨ ì‹œì—ë„ ê¸°ë³¸ ì§ˆë¬¸ ìƒì„± ì‹œë„
                try:
                    fallback_questions = self.create_basic_questions(row_data)
                    logger.info(f"{row_id}: ì™„ì „ fallback - {len(fallback_questions)}ê°œ ì§ˆë¬¸")
                    
                    self.audit_log.append({
                        'row_id': row_id,
                        'row_idx': row_idx,
                        'questions_generated': len(fallback_questions),
                        'attempt_count': 999,
                        'error': str(e),
                        'success': False
                    })
                    
                    if self.progress_bar:
                        self.progress_bar.update(1)
                    
                    return fallback_questions
                    
                except Exception as fallback_error:
                    logger.error(f"{row_id}: fallbackë„ ì‹¤íŒ¨ - {fallback_error}")
                    
                    if self.progress_bar:
                        self.progress_bar.update(1)
                    
                    return []
    
    def preprocess_data(self, df: pd.DataFrame) -> List[Dict]:
        """ë°ì´í„° ì „ì²˜ë¦¬"""
        processed_data = []
        
        for idx, row in df.iterrows():
            try:
                # NaN ê°’ ì²˜ë¦¬
                row_dict = {}
                for col in ['ì•½ì œë¶„ë¥˜ë²ˆí˜¸', 'ì•½ì œ ë¶„ë¥˜ëª…', 'êµ¬ë¶„', 'ì„¸ë¶€ì¸ì •ê¸°ì¤€ ë° ë°©ë²•']:
                    if col in row:
                        val = row[col]
                        if pd.isna(val):
                            row_dict[col] = ""
                        else:
                            row_dict[col] = str(val).strip()
                    else:
                        row_dict[col] = ""
                
                # í•„ìˆ˜ í•„ë“œ ê²€ì¦ (ì™„í™”)
                if not row_dict.get('êµ¬ë¶„') and not row_dict.get('ì„¸ë¶€ì¸ì •ê¸°ì¤€ ë° ë°©ë²•'):
                    logger.warning(f"í–‰ {idx}: êµ¬ë¶„ê³¼ ì„¸ë¶€ì¸ì •ê¸°ì¤€ ëª¨ë‘ ëˆ„ë½")
                    continue
                
                processed_data.append(row_dict)
                
            except Exception as e:
                logger.warning(f"í–‰ {idx} ì „ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
                continue
        
        logger.info(f"ì „ì²˜ë¦¬ ì™„ë£Œ: {len(processed_data)}ê°œ í•­ëª©")
        return processed_data
    
    async def generate_all_questions(self, processed_data: List[Dict]) -> List[Dict]:
        """ëª¨ë“  ì•½ì œì— ëŒ€í•œ ì§ˆë¬¸ ìƒì„±"""
        # ì§„í–‰ìƒí™© ë°” ì´ˆê¸°í™”
        self.progress_bar = tqdm(total=len(processed_data), desc="ì§ˆë¬¸ ìƒì„± ì¤‘", unit="ì•½ì œ")
        
        async with aiohttp.ClientSession() as session:
            tasks = [
                self.generate_questions_for_drug(session, item, idx)
                for idx, item in enumerate(processed_data)
            ]
            
            results = await asyncio.gather(*tasks, return_exceptions=True)
            
            # ì§„í–‰ìƒí™© ë°” ì¢…ë£Œ
            if self.progress_bar:
                self.progress_bar.close()
                self.progress_bar = None
            
            # ê²°ê³¼ ì •ë¦¬
            all_questions = []
            for idx, result in enumerate(results):
                if isinstance(result, Exception):
                    logger.error(f"í–‰ {idx} ì‹¤íŒ¨: {result}")
                elif isinstance(result, list):
                    all_questions.extend(result)
            
            return all_questions
    
    def save_final_results(self, questions: List[Dict], output_path: str):
        """ìµœì¢… í˜•ì‹ìœ¼ë¡œ ê²°ê³¼ ì €ì¥"""
        try:
            # ì—‘ì…€ í˜•ì‹ìœ¼ë¡œ ì €ì¥ (ê³ ì • ì»¬ëŸ¼)
            df = pd.DataFrame(questions)
            
            # ì»¬ëŸ¼ ìˆœì„œ ê³ ì •
            final_columns = ['ì•½ì œë¶„ë¥˜ë²ˆí˜¸', 'ì•½ì œ ë¶„ë¥˜ëª…', 'êµ¬ë¶„', 'ì„¸ë¶€ì¸ì •ê¸°ì¤€ ë° ë°©ë²•', 'question', 'ë¼ë²¨']
            for col in final_columns:
                if col not in df.columns:
                    df[col] = ""
            
            df = df[final_columns]
            df.to_excel(output_path, index=False, engine='openpyxl')
            
            logger.info(f"ìµœì¢… ê²°ê³¼ ì €ì¥: {output_path} ({len(questions)}ê°œ ì§ˆë¬¸)")
            
        except Exception as e:
            logger.error(f"ê²°ê³¼ ì €ì¥ ì‹¤íŒ¨: {e}")
            raise
    
    def save_audit_log(self, output_dir: str = "."):
        """ê°ì‚¬ ë¡œê·¸ ì €ì¥"""
        try:
            audit_path = os.path.join(output_dir, "audit_log_drug_v4_robust.csv")
            df = pd.DataFrame(self.audit_log)
            df.to_csv(audit_path, index=False, encoding='utf-8-sig')
            logger.info(f"ê°ì‚¬ ë¡œê·¸ ì €ì¥: {audit_path}")
        except Exception as e:
            logger.error(f"ê°ì‚¬ ë¡œê·¸ ì €ì¥ ì‹¤íŒ¨: {e}")
    
    def print_statistics(self, questions: List[Dict]):
        """í†µê³„ ì¶œë ¥"""
        if not questions:
            print("ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        total_questions = len(questions)
        
        # ë¼ë²¨ ë¶„í¬
        label_counts = {}
        for q in questions:
            label = q.get('ë¼ë²¨', 'UNKNOWN')
            label_counts[label] = label_counts.get(label, 0) + 1
        
        # ì„±ê³µ/ì‹¤íŒ¨ ë¶„ì„
        success_count = len([log for log in self.audit_log if log.get('success', True)])
        total_rows = len(self.audit_log)
        
        # í†µê³„ ì¶œë ¥
        print(f"\n=== V4 ì•½ì œ ì§ˆë¬¸ ìƒì„± í†µê³„ (Robust) ===")
        print(f"ì´ ì²˜ë¦¬ í–‰ ìˆ˜: {total_rows}")
        print(f"ì„±ê³µ í–‰ ìˆ˜: {success_count}")
        print(f"ì‹¤íŒ¨ í–‰ ìˆ˜: {total_rows - success_count}")
        print(f"ì„±ê³µë¥ : {success_count/total_rows*100:.1f}%" if total_rows > 0 else "N/A")
        print(f"ì´ ì§ˆë¬¸ ìˆ˜: {total_questions}")
        
        print(f"\n=== ë¼ë²¨ ë¶„í¬ ===")
        for label, count in label_counts.items():
            ratio = count / total_questions * 100 if total_questions > 0 else 0
            print(f"{label}: {count}ê°œ ({ratio:.1f}%)")
        
        # ì‹¤íŒ¨í•œ í–‰ ì •ë³´
        if self.failed_rows:
            print(f"\n=== ì‹¤íŒ¨í•œ í–‰ë“¤ ===")
            for failed in self.failed_rows[:5]:  # ì²˜ìŒ 5ê°œë§Œ ì¶œë ¥
                print(f"í–‰ {failed['row_idx']}: {failed['question_count']}ê°œ ì§ˆë¬¸ ìƒì„±")


def main():
    parser = argparse.ArgumentParser(description="Pharma-Augment V4 ì•½ì œ ì§ˆë¬¸ ìƒì„±ê¸° (Robust)")
    
    # í•„ìˆ˜ ì¸ì
    parser.add_argument("--excel", required=True, help="ì•½ì œ ì—‘ì…€ íŒŒì¼ ê²½ë¡œ")
    
    # ì„ íƒì  ì¸ì
    parser.add_argument("--sheet", default="Sheet1", help="ì‹œíŠ¸ëª…")
    parser.add_argument("--out", default="drug_questions_v4_robust.xlsx", help="ìµœì¢… ì¶œë ¥ íŒŒì¼")
    parser.add_argument("--provider", choices=["openai", "claude"], default="openai", help="LLM ì œê³µì")
    parser.add_argument("--model", default="gpt-4o-mini", help="ëª¨ë¸ëª…")
    parser.add_argument("--concurrency", type=int, default=6, help="ë™ì‹œ ì‹¤í–‰ ìˆ˜")
    parser.add_argument("--seed", type=int, default=20250903, help="ëœë¤ ì‹œë“œ")
    
    args = parser.parse_args()
    
    try:
        # ì§ˆë¬¸ ìƒì„±ê¸° ì´ˆê¸°í™”
        generator = DrugGeneratorV4Robust(
            provider=args.provider,
            model=args.model,
            concurrency=args.concurrency,
            seed=args.seed
        )
        
        print("ğŸ“‹ ì•½ì œ ë°ì´í„° ë¡œë“œ ì¤‘...")
        # ì—‘ì…€ ë°ì´í„° ë¡œë“œ
        df = generator.load_excel_data(args.excel, args.sheet)
        
        print("ğŸ”„ ë°ì´í„° ì „ì²˜ë¦¬ ì¤‘...")
        # ì „ì²˜ë¦¬
        processed_data = generator.preprocess_data(df)
        
        if not processed_data:
            logger.error("ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            sys.exit(1)
        
        print(f"ğŸ¤– V4 ì•½ì œ ì§ˆë¬¸ ìƒì„± ì‹œì‘: {len(processed_data)}ê°œ í–‰ (Robust ëª¨ë“œ)")
        print("ğŸ’¡ ê° í–‰ë§ˆë‹¤ ìµœì†Œ 5ê°œ ì§ˆë¬¸ì´ ë³´ì¥ë©ë‹ˆë‹¤!")
        # ì§ˆë¬¸ ìƒì„±
        results = asyncio.run(generator.generate_all_questions(processed_data))
        
        print("ğŸ’¾ ê²°ê³¼ ì €ì¥ ì¤‘...")
        # ê²°ê³¼ ì €ì¥
        generator.save_final_results(results, args.out)
        generator.save_audit_log()
        
        # í†µê³„ ì¶œë ¥
        generator.print_statistics(results)
        
        print("âœ… V4 ì•½ì œ ì§ˆë¬¸ ìƒì„± ì™„ë£Œ (Robust)!")
        
    except KeyboardInterrupt:
        logger.info("ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë¨")
        sys.exit(1)
    except Exception as e:
        logger.error(f"ì‹¤í–‰ ì‹¤íŒ¨: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()