#!/usr/bin/env python3
"""
Pharma-Augment V5 - í–¥ìƒëœ ì§ˆë¬¸ ìƒì„±ê¸°
V2 ìŠ¤íƒ€ì¼ì˜ í’ë¶€í•˜ê³  êµ¬ì²´ì ì¸ ì§ˆë¬¸ + V4ì˜ ëŒ€ëª…ì‚¬ ì°¨ë‹¨ ê²°í•©
"""

import argparse
import asyncio
import json
import logging
import os
import re
import sys
import random
import math
from typing import Dict, List, Optional, Tuple, Any
import pandas as pd
import aiohttp
import backoff
from rapidfuzz import fuzz
from dotenv import load_dotenv
import tiktoken
from tqdm.asyncio import tqdm
import time

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('drug_generation_v5.log', encoding='utf-8'),
        logging.StreamHandler(sys.stdout)
    ]
)
logger = logging.getLogger(__name__)

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

class DrugGeneratorV5:
    def __init__(self, provider: str = "openai", model: str = "gpt-4o-mini", 
                 concurrency: int = 6, seed: int = 20250903):
        self.provider = provider
        self.model = model
        self.concurrency = concurrency
        self.seed = seed
        random.seed(seed)
        
        # API í‚¤ ì„¤ì •
        if provider == "openai":
            self.api_key = os.getenv("OPENAI_API_KEY")
            if not self.api_key:
                raise ValueError("OPENAI_API_KEYê°€ í™˜ê²½ë³€ìˆ˜ì— ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        elif provider == "claude":
            self.api_key = os.getenv("ANTHROPIC_API_KEY")
            if not self.api_key:
                raise ValueError("ANTHROPIC_API_KEYê°€ í™˜ê²½ë³€ìˆ˜ì— ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        # ì„¸ë§ˆí¬ì–´ë¡œ ë™ì‹œì„± ì œì–´
        self.semaphore = asyncio.Semaphore(concurrency)
        
        # ëŒ€ëª…ì‚¬ ì°¨ë‹¨ ì •ê·œì‹
        self.PRONOUN_RE = re.compile(r"(ì´|ê·¸|í•´ë‹¹|ë³¸|ë™)\s?(ì•½|ì•½ì œ|ì œì œ|ì œí’ˆ)|ì´ê²ƒ|ê·¸ê²ƒ")
        
        # ë¼ë²¨ íƒ€ì…
        self.LABELS = ["POSITIVE", "NEGATIVE", "HARD_NEGATIVE"]
        
        # ê°ì‚¬ ë¡œê·¸
        self.audit_log = []
        self.progress_bar = None
    
    def load_excel_data(self, excel_path: str, sheet_name: str = "Sheet1") -> pd.DataFrame:
        """ì—‘ì…€ íŒŒì¼ ë¡œë“œ"""
        try:
            df = pd.read_excel(excel_path, sheet_name=sheet_name)
            logger.info(f"ì—‘ì…€ íŒŒì¼ ë¡œë“œ ì™„ë£Œ: {df.shape[0]}í–‰ {df.shape[1]}ì—´")
            
            # UTF-8 ë””ì½”ë”© ë¬¸ì œ í•´ê²° ì‹œë„
            for col in df.columns:
                if df[col].dtype == 'object':
                    df[col] = df[col].astype(str)
            
            # ì»¬ëŸ¼ëª… í™•ì¸ ë° ë§¤í•‘
            expected_cols = ['ì•½ì œë¶„ë¥˜ë²ˆí˜¸', 'ì•½ì œ ë¶„ë¥˜ëª…', 'êµ¬ë¶„', 'ì„¸ë¶€ì¸ì •ê¸°ì¤€ ë° ë°©ë²•']
            actual_cols = list(df.columns)
            
            logger.info(f"ì‹¤ì œ ì»¬ëŸ¼: {actual_cols}")
            
            # ì»¬ëŸ¼ ìˆœì„œëŒ€ë¡œ ë§¤í•‘ (ìˆœì„œ ê¸°ë°˜)
            if len(actual_cols) >= 4:
                column_mapping = dict(zip(actual_cols[:4], expected_cols))
                df = df.rename(columns=column_mapping)
                logger.info(f"ì»¬ëŸ¼ ë§¤í•‘ ì™„ë£Œ: {column_mapping}")
            
            return df
            
        except Exception as e:
            logger.error(f"ì—‘ì…€ íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}")
            raise
    
    def extract_name_slots(self, gubun: str) -> Tuple[str, List[str]]:
        """êµ¬ë¶„ í•„ë“œì—ì„œ main_nameê³¼ brand_names ì¶”ì¶œ"""
        # ê´„í˜¸ íŒ¨í„´ ì œê±° í›„ ì¶”ì¶œ
        clean_gubun = re.sub(r'\[.*?\]\s*', '', gubun).strip()
        
        # main_name = ê´„í˜¸ ì•ì˜ ì£¼ ì•½ì œëª…
        main_name = ""
        brand_names = []
        
        # ê´„í˜¸ ì• ë¶€ë¶„ì„ main_nameìœ¼ë¡œ
        paren_match = re.search(r'^([^(]+)', clean_gubun)
        if paren_match:
            main_name = paren_match.group(1).strip()
        
        # "í’ˆëª…:" ë’¤ì˜ í’ˆëª…ë“¤ì„ ì¶”ì¶œ
        brand_match = re.search(r'í’ˆ\s*ëª…\s*[:ï¼š]\s*([^)]+)', clean_gubun)
        if brand_match:
            brand_text = brand_match.group(1).strip()
            # 'Â·' ë˜ëŠ” '/' ê¸°ì¤€ìœ¼ë¡œ ë¶„ë¦¬
            brand_names = re.split(r'[Â·/]+', brand_text)
            brand_names = [name.strip() for name in brand_names if name.strip()]
        
        return main_name, brand_names
    
    def create_drug_prompt_v5(self, row_data: Dict) -> str:
        """V5 í”„ë¡¬í”„íŠ¸: V2 ìŠ¤íƒ€ì¼ì˜ í’ë¶€í•œ ì§ˆë¬¸ + ëŒ€ëª…ì‚¬ ì°¨ë‹¨"""
        drug_code = row_data.get('ì•½ì œë¶„ë¥˜ë²ˆí˜¸', '')
        drug_name = row_data.get('ì•½ì œ ë¶„ë¥˜ëª…', '')
        gubun = row_data.get('êµ¬ë¶„', '')
        content = row_data.get('ì„¸ë¶€ì¸ì •ê¸°ì¤€ ë° ë°©ë²•', '')
        
        main_name, brand_names = self.extract_name_slots(gubun)
        brand_names_json = json.dumps(brand_names, ensure_ascii=False)
        
        return f"""[ROLE]
ë„ˆëŠ” ì˜ë£Œ ë³´í—˜ ì‹¬ì‚¬ ë„ë©”ì¸ì˜ ì „ë¬¸ ì§ˆë¬¸ ìƒì„± ì—ì´ì „íŠ¸ë‹¤. 
V2 ìŠ¤íƒ€ì¼ì˜ í’ë¶€í•˜ê³  êµ¬ì²´ì ì¸ ì§ˆë¬¸ë“¤ì„ ìƒì„±í•˜ë˜, ëŒ€ëª…ì‚¬ëŠ” ì ˆëŒ€ ì‚¬ìš©í•˜ì§€ ì•ŠëŠ”ë‹¤.

[INPUT]
- ì•½ì œë¶„ë¥˜ë²ˆí˜¸: {drug_code}
- ì•½ì œ ë¶„ë¥˜ëª…: {drug_name}
- êµ¬ë¶„: {gubun}
- main_name: {main_name}
- brand_names: {brand_names_json}
- ì„¸ë¶€ì¸ì •ê¸°ì¤€ ë° ë°©ë²•: \"\"\"
{content}
\"\"\"

[V5 ENHANCED GENERATION RULES]
1) ì§ˆë¬¸ ìˆ˜: 8~15ê°œ (ì–‘ì§ˆ ìœ„ì£¼)
2) ì§ˆë¬¸ ê¸¸ì´: 25~80ì (V2 ìˆ˜ì¤€ìœ¼ë¡œ êµ¬ì²´ì ì´ê³  ìì„¸í•˜ê²Œ)
3) **ëŒ€ëª…ì‚¬ ì ˆëŒ€ ê¸ˆì§€**: "ì´ê²ƒ", "ê·¸ê²ƒ", "í•´ë‹¹ ì•½ì œ", "ë³¸ ì œì œ", "ë™ ì•½ë¬¼" ë“± ì¼ì²´ ì‚¬ìš© ê¸ˆì§€
4) ì§ˆë¬¸ ìœ í˜•ì„ ë‹¤ì–‘í•˜ê²Œ (V2 ìŠ¤íƒ€ì¼):
   A) ê¸°ë³¸ ì •ë³´í˜•: "{ì•½ì œëª…}ì˜ êµ¬ì²´ì ì¸ ê¸‰ì—¬ ì¸ì • ê¸°ì¤€ì€ ë¬´ì—‡ì¸ê°€ìš”?"
   B) ì¡°ê±´/ìƒí™©í˜•: "{íŠ¹ì •ìˆ˜ì¹˜/ì¡°ê±´}ì¼ ë•Œ {ì•½ì œëª…} ì‚¬ìš©ì´ ê°€ëŠ¥í•œê°€ìš”?"
   C) ë¹„êµí˜•: "{ì•½ì œëª…}ì˜ ê²½êµ¬ì œì™€ ì£¼ì‚¬ì œ ê¸‰ì—¬ ê¸°ì¤€ ì°¨ì´ì ì€?"
   D) ì ˆì°¨í˜•: "{ì•½ì œëª…} ì²˜ë°© ì‹œ í•„ìš”í•œ ì‚¬ì „ìŠ¹ì¸ ì ˆì°¨ëŠ” ì–´ë–»ê²Œ ë˜ë‚˜ìš”?"
   E) ì œí•œí˜•: "ì–´ë–¤ ê²½ìš°ì— {ì•½ì œëª…} ì‚¬ìš©ì´ ì œí•œë˜ê±°ë‚˜ ì‚­ê°ë˜ë‚˜ìš”?"

5) ì‹¤ë¬´ì  êµ¬ì²´ì„± (V2 ìˆ˜ì¤€):
   - êµ¬ì²´ì  ìˆ˜ì¹˜ í¬í•¨ (AST 60U/L, 3ê°œì›” ì´ìƒ ë“±)
   - í™˜ìêµ° ëª…ì‹œ (ì†Œì•„, ì„±ì¸, ê³ ë ¹ì ë“±)
   - ì˜ë£Œ ìš©ì–´ í™œìš© (ê°„ê¸°ëŠ¥, ì‹ ê¸°ëŠ¥, í˜ˆì¤‘ë†ë„ ë“±)
   - ì ˆì°¨ì  ì„¸ë¶€ì‚¬í•­ (ì‚¬ì „ìŠ¹ì¸, ì¦ë¹™ì„œë¥˜, ëª¨ë‹ˆí„°ë§ ë“±)

6) ì´ë¦„ ì‚¬ìš© ì „ëµ:
   - MAINë§Œ: 30-40% (ì£¼ ì•½ì œëª…ë§Œ)
   - BRANDë§Œ: 30-40% (í’ˆëª…ë§Œ)  
   - BOTH: 20-30% (ë‘˜ ë‹¤)
   - ë¸Œëœë“œ ì—†ìœ¼ë©´: MAIN 70%, BOTH 30%

[EXAMPLES - V2 ìŠ¤íƒ€ì¼ ì°¸ê³ ]
âœ… ì¢‹ì€ ì˜ˆì‹œ:
- "AST ìˆ˜ì¹˜ê°€ 60U/L ì´ìƒì¼ ë•Œ {main_name} ê¸‰ì—¬ìš”ê±´ì€ ì–´ë–»ê²Œ ì ìš©ë˜ë‚˜ìš”?" (42ì)
- "{brand_name}ì„ 3ê°œì›” ì´ìƒ ì¥ê¸° ì²˜ë°© ì‹œ í•„ìš”í•œ ëª¨ë‹ˆí„°ë§ í•­ëª©ì€?" (35ì)
- "ê°„ê¸°ëŠ¥ ì €í•˜ í™˜ìì—ì„œ {main_name} ìš©ëŸ‰ ì¡°ì ˆ ê¸°ì¤€ê³¼ ì£¼ì˜ì‚¬í•­ì€?" (37ì)
- "{brand_name}ê³¼ ìŠ¤í…Œë¡œì´ë“œ ë³‘ìš© íˆ¬ì—¬ ì‹œ ê¸‰ì—¬ ì‹¬ì‚¬ì—ì„œ ê³ ë ¤í•  ì‚¬í•­ì€?" (41ì)

âŒ í”¼í•´ì•¼ í•  ì˜ˆì‹œ:
- "ì´ ì•½ì œì˜ ì‚¬ìš© ê¸°ì¤€ì€?" (ëŒ€ëª…ì‚¬ ì‚¬ìš©)
- "{ì•½ì œëª…} ê¸°ì¤€ì€?" (ë„ˆë¬´ ë‹¨ìˆœ)
- "ì‚¬ìš©ë²•ì€?" (ë¹„êµ¬ì²´ì )

[LABELING]
- POSITIVE (70%): ì…ë ¥ ë‚´ìš©ì— ì§ì ‘ ê·¼ê±°í•œ ì§ˆë¬¸
- NEGATIVE (15%): ì™„ì „íˆ ë‹¤ë¥¸ ì•½ì œë‚˜ ìƒí™© ì§ˆë¬¸  
- HARD_NEGATIVE (15%): ë¹„ìŠ·í•˜ì§€ë§Œ í•µì‹¬ì´ ë‹¤ë¥¸ near-miss

[OUTPUT ìŠ¤í‚¤ë§ˆ]
[
  {{"ì•½ì œë¶„ë¥˜ë²ˆí˜¸":"{drug_code}","ì•½ì œ ë¶„ë¥˜ëª…":"{drug_name}","êµ¬ë¶„":"{gubun}","ì„¸ë¶€ì¸ì •ê¸°ì¤€ ë° ë°©ë²•":"{content[:100]}...","question":"êµ¬ì²´ì ì´ê³  ìƒì„¸í•œ ì§ˆë¬¸ (25-80ì)","ë¼ë²¨":"POSITIVE|NEGATIVE|HARD_NEGATIVE"}},
  ...
]

ë°˜ë“œì‹œ V2 ìˆ˜ì¤€ì˜ êµ¬ì²´ì ì´ê³  ì‹¤ë¬´ì ì¸ ì§ˆë¬¸ì„ ìƒì„±í•˜ë¼. ë‹¨ìˆœí•œ ì§ˆë¬¸ì€ ê¸ˆì§€í•œë‹¤."""

    def post_process_v5(self, questions: List[Dict], main_name: str, brand_names: List[str], content: str) -> List[Dict]:
        """V5 í›„ì²˜ë¦¬: í’ˆì§ˆ ì¤‘ì‹¬ í•„í„°ë§"""
        if not questions:
            return []
        
        processed = []
        
        for q in questions:
            text = q.get("question", "")
            label = q.get("ë¼ë²¨", "")
            
            # 1. ëŒ€ëª…ì‚¬ ê²€ì¦ (ì—„ê²©)
            if self.PRONOUN_RE.search(text):
                logger.warning(f"V5 ëŒ€ëª…ì‚¬ ê²€ì¶œ: {text}")
                continue
            
            # 2. ê¸¸ì´ ê²€ì¦ (25-80ìë¡œ ìƒí–¥)
            if not (25 <= len(text) <= 80):
                if len(text) < 25:
                    logger.warning(f"V5 ê¸¸ì´ ë¶€ì¡±: {text} ({len(text)}ì)")
                    continue
                elif len(text) > 80:
                    logger.warning(f"V5 ê¸¸ì´ ì´ˆê³¼: {text} ({len(text)}ì)")
                    continue
            
            # 3. ë¼ë²¨ ê²€ì¦
            if label not in self.LABELS:
                q["ë¼ë²¨"] = "POSITIVE"  # ê¸°ë³¸ê°’
            
            # 4. êµ¬ì²´ì„± ê²€ì¦ (ê°„ë‹¨í•œ íŒ¨í„´ ë§¤ì¹­)
            concrete_patterns = [
                r'\d+', # ìˆ«ì í¬í•¨
                r'(ê°œì›”|ì¼|íšŒ|mg|mL|U/L)', # ë‹¨ìœ„ í¬í•¨
                r'(í™˜ì|ì²˜ë°©|íˆ¬ì—¬|ì‚¬ìš©|ì ìš©)', # ì˜ë£Œ ìš©ì–´
                r'(ê¸°ì¤€|ì¡°ê±´|ì ˆì°¨|ë°©ë²•|ì‚¬í•­)', # êµ¬ì²´ì  ëª…ì‚¬
            ]
            
            has_concrete = any(re.search(pattern, text) for pattern in concrete_patterns)
            if not has_concrete:
                logger.warning(f"V5 êµ¬ì²´ì„± ë¶€ì¡±: {text}")
                continue
            
            processed.append(q)
        
        return processed
    
    @backoff.on_exception(backoff.expo, (aiohttp.ClientError, asyncio.TimeoutError), max_tries=3)
    async def call_api_v5(self, session: aiohttp.ClientSession, prompt: str, row_id: str) -> List[Dict]:
        """V5 API í˜¸ì¶œ"""
        if self.provider == "openai":
            headers = {
                "Authorization": f"Bearer {self.api_key}",
                "Content-Type": "application/json"
            }
            
            payload = {
                "model": self.model,
                "messages": [{"role": "user", "content": prompt}],
                "temperature": 0.8,  # ì°½ì˜ì„± ì¦ê°€
                "top_p": 0.95,
                "max_tokens": 3000,
                "response_format": {"type": "json_object"},
                "seed": self.seed
            }
            
            async with session.post(
                "https://api.openai.com/v1/chat/completions",
                headers=headers,
                json=payload,
                timeout=aiohttp.ClientTimeout(total=120)
            ) as response:
                if response.status == 429:
                    logger.warning(f"Rate limit for {row_id}, retrying...")
                    await asyncio.sleep(3)
                    raise aiohttp.ClientError("Rate limit")
                
                response.raise_for_status()
                result = await response.json()
                
                try:
                    content = result['choices'][0]['message']['content']
                    # JSON íŒŒì‹± ì‹œë„
                    if content.startswith('['):
                        return json.loads(content)
                    else:
                        # JSON ê°ì²´ê°€ ì˜¨ ê²½ìš° ë°°ì—´ë¡œ ê°ì‹¸ì„œ ë°˜í™˜
                        parsed = json.loads(content)
                        if isinstance(parsed, dict):
                            return [parsed]
                        return parsed
                except (json.JSONDecodeError, KeyError) as e:
                    logger.error(f"V5 JSON íŒŒì‹± ì‹¤íŒ¨ for {row_id}: {e}")
                    logger.error(f"Response content: {content[:300]}...")
                    return []
        
        return []
    
    async def generate_questions_for_drug(self, session: aiohttp.ClientSession, row_data: Dict, row_idx: int) -> List[Dict]:
        """ë‹¨ì¼ ì•½ì œì— ëŒ€í•œ V5 ì§ˆë¬¸ ìƒì„±"""
        async with self.semaphore:
            start_time = time.time()
            row_id = f"v5_row_{row_idx}"
            
            try:
                gubun = str(row_data.get('êµ¬ë¶„', ''))
                main_name, brand_names = self.extract_name_slots(gubun)
                content = str(row_data.get('ì„¸ë¶€ì¸ì •ê¸°ì¤€ ë° ë°©ë²•', ''))
                
                # V5 í”„ë¡¬í”„íŠ¸ë¡œ ìƒì„±
                prompt = self.create_drug_prompt_v5(row_data)
                raw_questions = await self.call_api_v5(session, prompt, row_id)
                
                # V5 í›„ì²˜ë¦¬
                validated_questions = self.post_process_v5(raw_questions, main_name, brand_names, content)
                
                # í’ˆì§ˆ ê¸°ì¤€: ìµœì†Œ 5ê°œ
                if len(validated_questions) < 5:
                    logger.warning(f"{row_id}: V5 í’ˆì§ˆ ê¸°ì¤€ ë¯¸ë‹¬ ({len(validated_questions)}ê°œ)")
                
                # ê°ì‚¬ ë¡œê·¸
                elapsed_ms = int((time.time() - start_time) * 1000)
                self.audit_log.append({
                    'row_id': row_id,
                    'row_idx': row_idx,
                    'main_name': main_name,
                    'brand_count': len(brand_names),
                    'questions_generated': len(validated_questions),
                    'avg_length': sum(len(q.get('question', '')) for q in validated_questions) / max(1, len(validated_questions)),
                    'elapsed_ms': elapsed_ms,
                    'provider': self.provider,
                    'model': self.model,
                    'version': 'v5'
                })
                
                # ì§„í–‰ìƒí™© ì—…ë°ì´íŠ¸
                if self.progress_bar:
                    self.progress_bar.update(1)
                
                logger.info(f"V5 ì™„ë£Œ: {row_id} - {len(validated_questions)}ê°œ ì§ˆë¬¸ (í‰ê·  {int(sum(len(q.get('question', '')) for q in validated_questions) / max(1, len(validated_questions)))}ì)")
                return validated_questions
                
            except Exception as e:
                logger.error(f"V5 ì§ˆë¬¸ ìƒì„± ì‹¤íŒ¨ {row_id}: {e}")
                if self.progress_bar:
                    self.progress_bar.update(1)
                return []
    
    def preprocess_data(self, df: pd.DataFrame) -> List[Dict]:
        """ë°ì´í„° ì „ì²˜ë¦¬"""
        processed_data = []
        
        for idx, row in df.iterrows():
            try:
                # NaN ê°’ ì²˜ë¦¬
                row_dict = {}
                for col in ['ì•½ì œë¶„ë¥˜ë²ˆí˜¸', 'ì•½ì œ ë¶„ë¥˜ëª…', 'êµ¬ë¶„', 'ì„¸ë¶€ì¸ì •ê¸°ì¤€ ë° ë°©ë²•']:
                    if col in row:
                        val = row[col]
                        if pd.isna(val):
                            row_dict[col] = ""
                        else:
                            row_dict[col] = str(val).strip()
                    else:
                        row_dict[col] = ""
                
                # í•„ìˆ˜ í•„ë“œ ê²€ì¦
                if not row_dict.get('êµ¬ë¶„') or not row_dict.get('ì„¸ë¶€ì¸ì •ê¸°ì¤€ ë° ë°©ë²•'):
                    logger.warning(f"í–‰ {idx}: í•„ìˆ˜ í•„ë“œ ëˆ„ë½")
                    continue
                
                processed_data.append(row_dict)
                
            except Exception as e:
                logger.warning(f"í–‰ {idx} ì „ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
                continue
        
        logger.info(f"V5 ì „ì²˜ë¦¬ ì™„ë£Œ: {len(processed_data)}ê°œ í•­ëª©")
        return processed_data
    
    async def generate_all_questions(self, processed_data: List[Dict]) -> List[Dict]:
        """ëª¨ë“  ì•½ì œì— ëŒ€í•œ V5 ì§ˆë¬¸ ìƒì„±"""
        # ì§„í–‰ìƒí™© ë°” ì´ˆê¸°í™”
        self.progress_bar = tqdm(total=len(processed_data), desc="V5 ì§ˆë¬¸ ìƒì„±", unit="ì•½ì œ")
        
        async with aiohttp.ClientSession() as session:
            tasks = [
                self.generate_questions_for_drug(session, item, idx)
                for idx, item in enumerate(processed_data)
            ]
            
            results = await asyncio.gather(*tasks, return_exceptions=True)
            
            # ì§„í–‰ìƒí™© ë°” ì¢…ë£Œ
            if self.progress_bar:
                self.progress_bar.close()
                self.progress_bar = None
            
            # ê²°ê³¼ ì •ë¦¬
            all_questions = []
            for idx, result in enumerate(results):
                if isinstance(result, Exception):
                    logger.error(f"í–‰ {idx} ì‹¤íŒ¨: {result}")
                elif isinstance(result, list):
                    all_questions.extend(result)
            
            return all_questions
    
    def save_final_results(self, questions: List[Dict], output_path: str):
        """ìµœì¢… í˜•ì‹ìœ¼ë¡œ ê²°ê³¼ ì €ì¥"""
        try:
            # ì—‘ì…€ í˜•ì‹ìœ¼ë¡œ ì €ì¥ (ê³ ì • ì»¬ëŸ¼)
            df = pd.DataFrame(questions)
            
            # ì»¬ëŸ¼ ìˆœì„œ ê³ ì •
            final_columns = ['ì•½ì œë¶„ë¥˜ë²ˆí˜¸', 'ì•½ì œ ë¶„ë¥˜ëª…', 'êµ¬ë¶„', 'ì„¸ë¶€ì¸ì •ê¸°ì¤€ ë° ë°©ë²•', 'question', 'ë¼ë²¨']
            for col in final_columns:
                if col not in df.columns:
                    df[col] = ""
            
            df = df[final_columns]
            df.to_excel(output_path, index=False, engine='openpyxl')
            
            logger.info(f"V5 ê²°ê³¼ ì €ì¥: {output_path} ({len(questions)}ê°œ ì§ˆë¬¸)")
            
        except Exception as e:
            logger.error(f"V5 ê²°ê³¼ ì €ì¥ ì‹¤íŒ¨: {e}")
            raise
    
    def save_audit_log(self, output_dir: str = "."):
        """ê°ì‚¬ ë¡œê·¸ ì €ì¥"""
        try:
            audit_path = os.path.join(output_dir, "audit_log_drug_v5.csv")
            df = pd.DataFrame(self.audit_log)
            df.to_csv(audit_path, index=False, encoding='utf-8-sig')
            logger.info(f"V5 ê°ì‚¬ ë¡œê·¸ ì €ì¥: {audit_path}")
        except Exception as e:
            logger.error(f"V5 ê°ì‚¬ ë¡œê·¸ ì €ì¥ ì‹¤íŒ¨: {e}")
    
    def print_statistics(self, questions: List[Dict]):
        """V5 í†µê³„ ì¶œë ¥"""
        if not questions:
            print("V5 ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        total_questions = len(questions)
        
        # ê¸¸ì´ í†µê³„
        lengths = [len(q.get('question', '')) for q in questions]
        avg_length = sum(lengths) / len(lengths) if lengths else 0
        min_length = min(lengths) if lengths else 0
        max_length = max(lengths) if lengths else 0
        
        # ë¼ë²¨ ë¶„í¬
        label_counts = {}
        for q in questions:
            label = q.get('ë¼ë²¨', 'UNKNOWN')
            label_counts[label] = label_counts.get(label, 0) + 1
        
        # V5 í†µê³„ ì¶œë ¥
        print(f"\n=== V5 ì•½ì œ ì§ˆë¬¸ ìƒì„± í†µê³„ ===")
        print(f"ì´ ì§ˆë¬¸ ìˆ˜: {total_questions}")
        print(f"í‰ê·  ê¸¸ì´: {avg_length:.1f}ì")
        print(f"ê¸¸ì´ ë²”ìœ„: {min_length}-{max_length}ì")
        
        print(f"\n=== ë¼ë²¨ ë¶„í¬ ===")
        for label, count in label_counts.items():
            ratio = count / total_questions * 100 if total_questions > 0 else 0
            print(f"{label}: {count}ê°œ ({ratio:.1f}%)")
        
        # V2ì™€ ë¹„êµ ì •ë³´
        print(f"\n=== V2ì™€ ë¹„êµ ===")
        print(f"V2 í‰ê·  ê¸¸ì´: 36.2ì")
        print(f"V5 í‰ê·  ê¸¸ì´: {avg_length:.1f}ì")
        if avg_length >= 30:
            print("âœ… V5ê°€ V2 ìˆ˜ì¤€ì˜ êµ¬ì²´ì„± ë‹¬ì„±!")
        else:
            print("âš ï¸  V5 ê¸¸ì´ê°€ V2ë³´ë‹¤ ì§§ìŒ - êµ¬ì²´ì„± ê°œì„  í•„ìš”")


def main():
    parser = argparse.ArgumentParser(description="Pharma-Augment V5 ì•½ì œ ì§ˆë¬¸ ìƒì„±ê¸°")
    
    # í•„ìˆ˜ ì¸ì
    parser.add_argument("--excel", required=True, help="ì•½ì œ ì—‘ì…€ íŒŒì¼ ê²½ë¡œ")
    
    # ì„ íƒì  ì¸ì
    parser.add_argument("--sheet", default="Sheet1", help="ì‹œíŠ¸ëª…")
    parser.add_argument("--out", default="drug_questions_v5.xlsx", help="ìµœì¢… ì¶œë ¥ íŒŒì¼")
    parser.add_argument("--provider", choices=["openai", "claude"], default="openai", help="LLM ì œê³µì")
    parser.add_argument("--model", default="gpt-4o-mini", help="ëª¨ë¸ëª…")
    parser.add_argument("--concurrency", type=int, default=6, help="ë™ì‹œ ì‹¤í–‰ ìˆ˜")
    parser.add_argument("--seed", type=int, default=20250903, help="ëœë¤ ì‹œë“œ")
    
    args = parser.parse_args()
    
    try:
        # ì§ˆë¬¸ ìƒì„±ê¸° ì´ˆê¸°í™”
        generator = DrugGeneratorV5(
            provider=args.provider,
            model=args.model,
            concurrency=args.concurrency,
            seed=args.seed
        )
        
        print("ğŸ“‹ V5 ì•½ì œ ë°ì´í„° ë¡œë“œ ì¤‘...")
        # ì—‘ì…€ ë°ì´í„° ë¡œë“œ
        df = generator.load_excel_data(args.excel, args.sheet)
        
        print("ğŸ”„ V5 ë°ì´í„° ì „ì²˜ë¦¬ ì¤‘...")
        # ì „ì²˜ë¦¬
        processed_data = generator.preprocess_data(df)
        
        if not processed_data:
            logger.error("ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            sys.exit(1)
        
        print(f"ğŸ¤– V5 ì•½ì œ ì§ˆë¬¸ ìƒì„± ì‹œì‘: {len(processed_data)}ê°œ í–‰")
        print("ğŸ¯ V2 ìˆ˜ì¤€ì˜ êµ¬ì²´ì ì´ê³  í’ë¶€í•œ ì§ˆë¬¸ì„ ìƒì„±í•©ë‹ˆë‹¤!")
        # ì§ˆë¬¸ ìƒì„±
        results = asyncio.run(generator.generate_all_questions(processed_data))
        
        print("ğŸ’¾ V5 ê²°ê³¼ ì €ì¥ ì¤‘...")
        # ê²°ê³¼ ì €ì¥
        generator.save_final_results(results, args.out)
        generator.save_audit_log()
        
        # í†µê³„ ì¶œë ¥
        generator.print_statistics(results)
        
        print("âœ… V5 ì•½ì œ ì§ˆë¬¸ ìƒì„± ì™„ë£Œ!")
        
    except KeyboardInterrupt:
        logger.info("ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë¨")
        sys.exit(1)
    except Exception as e:
        logger.error(f"V5 ì‹¤í–‰ ì‹¤íŒ¨: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()