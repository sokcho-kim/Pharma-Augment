"""
V7 ì˜ë£Œ ë³´í—˜ ì§ˆë¬¸ ìƒì„±ê¸° - ReasonIR ê¸°ë°˜ ë©€í‹°ë°´ë“œ ê°œì„ 
í•µì‹¬ ë³€í™”: SR/MR/LR ê¸¸ì´ ë°´ë“œ (60%/25%/15%) + ë©€í‹°í„´ ìƒì„± + ì•µì»¤íŒ© ìˆ˜ì§‘
"""

import pandas as pd
import re
import random
import json
import time
import math
import uuid
from pathlib import Path
from typing import List, Dict, Tuple, Optional, Any
from dataclasses import dataclass
from rapidfuzz import fuzz
import logging
import traceback
from datetime import datetime
import openai
import os
from dotenv import load_dotenv
from enum import Enum

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# ë¡œê¹… ì„¤ì • (ë°±ì—… í¬í•¨)
log_file = f'drug_generation_v7_{datetime.now().strftime("%Y%m%d_%H%M%S")}.log'
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler(log_file, encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# OpenAI API í‚¤ ì„¤ì •
openai.api_key = os.getenv('OPENAI_API_KEY')

class LengthBand(Enum):
    """ê¸¸ì´ ë°´ë“œ ì •ì˜"""
    SR = "SR"  # Short Range: 25-80 chars
    MR = "MR"  # Medium Range: 80-160 chars  
    LR = "LR"  # Long Range: 200-600 chars (scenario-based)

@dataclass
class BandConfig:
    """ë°´ë“œë³„ ì„¤ì •"""
    name: LengthBand
    min_chars: int
    max_chars: int
    ratio: float  # ì „ì²´ ëŒ€ë¹„ ë¹„ìœ¨
    allow_pronouns_in_scenario: bool = False  # ì‹œë‚˜ë¦¬ì˜¤ ë¶€ë¶„ì—ì„œ ëŒ€ëª…ì‚¬ í—ˆìš© ì—¬ë¶€

@dataclass 
class GenerationConfig:
    """ìƒì„± ì„¤ì •"""
    # ë¼ë²¨ ë¹„ìœ¨ (í–‰ ë‹¨ìœ„)
    pos_ratio: float = 6.0
    hn_ratio: float = 3.0
    en_ratio: float = 0.0  # ê¸°ë³¸ 0, ì‹¤í—˜ì‹œì—ë§Œ ì‚¬ìš©
    
    # ë°´ë“œ ì„¤ì •
    bands: Dict[LengthBand, BandConfig] = None
    
    # ê¸°íƒ€ ì„¤ì •
    slice_length: int = 2500
    max_retries: int = 3
    temperature: float = 0.7
    model: str = "gpt-4o-mini"
    
    def __post_init__(self):
        if self.bands is None:
            self.bands = {
                LengthBand.SR: BandConfig(LengthBand.SR, 25, 80, 0.6),
                LengthBand.MR: BandConfig(LengthBand.MR, 80, 160, 0.25), 
                LengthBand.LR: BandConfig(LengthBand.LR, 200, 600, 0.15, allow_pronouns_in_scenario=True)
            }

@dataclass
class Question:
    """ìƒì„±ëœ ì§ˆë¬¸"""
    text: str
    label: str  # POSITIVE, HARD_NEGATIVE, EASY_NEGATIVE
    band: LengthBand
    anchor_id: str  # ì•µì»¤íŒ© ID
    doc_slice_id: str
    metadata: Dict[str, Any]

class V7QuestionGenerator:
    """V7 ì§ˆë¬¸ ìƒì„±ê¸° - ë©€í‹°ë°´ë“œ ReasonIR ë°©ì‹"""
    
    def __init__(self, config: GenerationConfig = None):
        self.config = config or GenerationConfig()
        
        # ëŒ€ëª…ì‚¬ íŒ¨í„´ (ë°´ë“œë³„ ì°¨ë“± ì ìš©)
        self.strict_pronoun_pattern = re.compile(
            r'(ì´ê²ƒ|ê·¸ê²ƒ|í•´ë‹¹|ë³¸|ë™)\s*(ì•½|ì œì œ|ì œí’ˆ|ê³ ì‹œ|ì¡°í•­|ë‚´ìš©|í•­)|\b(ì´ê²ƒ|ê·¸ê²ƒ)\b'
        )
        
        # êµ¬ì²´ì„± ê²€ì¦ íŒ¨í„´  
        self.specificity_pattern = re.compile(
            r'\d|mg|ã|U/L|%|íšŒ|ê°œì›”|ì¼|ì£¼|ê¸‰ì—¬|ë¹„ê¸‰ì—¬|ë³¸ì¸ë¶€ë‹´|ì‚¬ì „ìŠ¹ì¸|ìˆ˜ê°€|ì½”ë“œ|ê¸°ê°„|íšŸìˆ˜|ì‹œí–‰ì¼|ê°œì •'
        )
        
        # ë¬¸ë‘ ë‹¤ì–‘ì„± ì²´í¬
        self.opening_words = ['ë¬´ì—‡', 'ì–´ë–»ê²Œ', 'ì–¸ì œ', 'ì™œ', 'ì–´ë–¤', 'ì–´ë””ì„œ', 'ì–´ëŠ', 'ëˆ„ê°€']
        
        # ì •ì±… í‚¤ì›Œë“œ
        self.policy_keywords = [
            'ê¸‰ì—¬', 'ë¹„ê¸‰ì—¬', 'ë³¸ì¸ë¶€ë‹´', 'ì‚¬ì „ìŠ¹ì¸', 'ìˆ˜ê°€', 'ì½”ë“œ', 
            'ê¸°ê°„', 'íšŸìˆ˜', 'ì‹œí–‰ì¼', 'ê°œì •', 'ì œì¶œ', 'ì´ì˜ì‹ ì²­'
        ]
        
    def load_and_preprocess_data(self, file_path: str) -> pd.DataFrame:
        """ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬"""
        logger.info(f"ë°ì´í„° ë¡œë“œ ì¤‘: {file_path}")
        
        # ì—‘ì…€ íŒŒì¼ ì½ê¸°
        df = pd.read_excel(file_path)
        logger.info(f"ì›ë³¸ ë°ì´í„°: {len(df)}í–‰, ì»¬ëŸ¼: {list(df.columns)}")
        
        # ì»¬ëŸ¼ ë§¤í•‘ (ì‹¤ì œ ë°ì´í„°ì— ë§ê²Œ ìˆ˜ì •)
        column_mapping = {
            'ì•½ì œë¶„ë¥˜ë²ˆí˜¸': 'code',
            'ì•½ì œë¶„ë¥˜ëª…': 'code_name',  # 'ì•½ì œ ë¶„ë¥˜ëª…' â†’ 'ì•½ì œë¶„ë¥˜ëª…' 
            'êµ¬ë¶„': 'title',
            'ì„¸ë¶€ì¸ì •ê¸°ì¤€ ë° ë°©ë²•': 'text'
        }
        
        # ë¶€ë¶„ ì¼ì¹˜ë¡œ ì»¬ëŸ¼ ë§¤í•‘
        mapped_columns = {}
        for col in df.columns:
            for ko_name, en_name in column_mapping.items():
                if ko_name in str(col):
                    mapped_columns[col] = en_name
                    break
        
        df = df.rename(columns=mapped_columns)
        
        # í•„ìˆ˜ ì»¬ëŸ¼ í™•ì¸
        required_cols = ['code', 'code_name', 'title', 'text']
        missing_cols = [col for col in required_cols if col not in df.columns]
        if missing_cols:
            raise ValueError(f"í•„ìˆ˜ ì»¬ëŸ¼ ëˆ„ë½: {missing_cols}")
            
        # í•µì‹¬ ì»¬ëŸ¼ë§Œ ê²°ì¸¡ì¹˜ í™•ì¸ (ì•½ì œë¶„ë¥˜ë²ˆí˜¸, ë¶„ë¥˜ëª…ì€ í—ˆìš©)
        essential_cols = ['title', 'text']  # êµ¬ë¶„, ì„¸ë¶€ì¸ì •ê¸°ì¤€ë§Œ í•„ìˆ˜
        initial_len = len(df)
        df = df.dropna(subset=essential_cols)
        logger.info(f"í•„ìˆ˜ ë°ì´í„° í™•ì¸ í›„: {len(df)}í–‰ (ì œê±°: {initial_len - len(df)}í–‰)")
        
        # ì•½ì œë¶„ë¥˜ë²ˆí˜¸, ë¶„ë¥˜ëª…ì´ ë¹„ì–´ìˆëŠ” ê²½ìš° ê¸°ë³¸ê°’ ì„¤ì •
        df['code'] = df['code'].fillna('Unknown')
        df['code_name'] = df['code_name'].fillna('ë¯¸ë¶„ë¥˜')
        
        return df
        
    def slice_text(self, text: str) -> List[str]:
        """í…ìŠ¤íŠ¸ë¥¼ ì ì ˆí•œ í¬ê¸°ë¡œ ìŠ¬ë¼ì´ì‹± (ë¬¸ì¥ ê²½ê³„ ë³´ì¡´)"""
        if len(text) <= self.config.slice_length:
            return [text]
        
        slices = []
        current_pos = 0
        
        while current_pos < len(text):
            end_pos = min(current_pos + self.config.slice_length, len(text))
            
            # ë¬¸ì¥ ê²½ê³„ì—ì„œ ìë¥´ê¸°
            if end_pos < len(text):
                # ë§ˆì§€ë§‰ ë¬¸ì¥ ëì„ ì°¾ê¸°
                last_sentence_end = max(
                    text.rfind('.', current_pos, end_pos),
                    text.rfind('ë‹¤.', current_pos, end_pos),
                    text.rfind('í•¨.', current_pos, end_pos)
                )
                
                if last_sentence_end > current_pos:
                    end_pos = last_sentence_end + 1
            
            slice_text = text[current_pos:end_pos].strip()
            if slice_text:
                slices.append(slice_text)
                
            current_pos = end_pos
            
        return slices
        
    def parse_drug_info(self, title: str) -> Dict[str, Any]:
        """ì•½ì œ ì •ë³´ íŒŒì‹±"""
        result = {
            'main_name': '',
            'brand_names': [],
            'raw_title': title
        }
        
        # ê´„í˜¸ ì• ì£¼ ì•½ì œëª… ì¶”ì¶œ
        if '(' in title:
            result['main_name'] = title.split('(')[0].strip()
        else:
            result['main_name'] = title.strip()
            
        # í’ˆëª… ì¶”ì¶œ (í’ˆëª…: ë’¤ì˜ ë‚´ìš©ì„ Â· ë˜ëŠ” // ë¡œ ë¶„ë¦¬)
        if 'í’ˆëª…:' in title:
            brand_part = title.split('í’ˆëª…:')[1].strip()
            # Â· ë˜ëŠ” // ë¡œ ë¶„ë¦¬
            separators = ['Â·', '//', ',']
            brands = [brand_part]
            
            for sep in separators:
                new_brands = []
                for brand in brands:
                    new_brands.extend([b.strip() for b in brand.split(sep) if b.strip()])
                brands = new_brands
                
            result['brand_names'] = [b for b in brands if b and b != result['main_name']]
            
        return result
        
    def generate_questions_by_band(self, doc_slice: str, band: LengthBand, 
                                 drug_info: Dict[str, Any]) -> List[str]:
        """ë°´ë“œë³„ ì§ˆë¬¸ ìƒì„±"""
        band_config = self.config.bands[band]
        
        # ë°´ë“œë³„ í”„ë¡¬í”„íŠ¸
        if band == LengthBand.SR:
            prompt = self._get_sr_prompt(doc_slice)
        elif band == LengthBand.MR:
            prompt = self._get_mr_prompt(doc_slice)
        else:  # LR
            prompt = self._get_lr_prompt(doc_slice)
            
        logger.info(f"{band.value} ë°´ë“œ ì§ˆë¬¸ ìƒì„± ì¤‘...")
        
        try:
            from openai import OpenAI
            client = OpenAI(api_key=openai.api_key)
            
            response = client.chat.completions.create(
                model=self.config.model,
                messages=[{"role": "user", "content": prompt}],
                temperature=self.config.temperature,
                max_tokens=1000
            )
            
            content = response.choices[0].message.content.strip()
            
            if band == LengthBand.LR:
                # LRì˜ ê²½ìš° ì‹œë‚˜ë¦¬ì˜¤ì—ì„œ ì§ˆë¬¸ ì¶”ì¶œ
                questions = self._extract_lr_questions(content)
            else:
                # SR/MRì˜ ê²½ìš° ê° ì¤„ì´ ì§ˆë¬¸
                questions = [line.strip() for line in content.split('\n') 
                           if line.strip() and line.strip().endswith('?')]
                           
            logger.info(f"{band.value} ë°´ë“œ: {len(questions)}ê°œ ì§ˆë¬¸ ìƒì„±")
            return questions
            
        except Exception as e:
            logger.error(f"{band.value} ë°´ë“œ ìƒì„± ì‹¤íŒ¨: {e}")
            return []
    
    def _get_sr_prompt(self, doc_slice: str) -> str:
        """SR ë°´ë“œ í”„ë¡¬í”„íŠ¸"""
        return f"""You generate Korean questions for an insurance review embedding model.
Return many lines, each a single Korean question strictly based on the document below.
Constraints: 25â€“80 characters; end with '?'; include at least one number/unit/policy term;
no pronouns like 'ì´ê²ƒ/ê·¸ê²ƒ/í•´ë‹¹/ë³¸/ë™ + ì•½Â·ì œì œÂ·ì œí’ˆ'; one issue per line; vary openings; no JSON.

Document:
<<<DOC
{doc_slice}
DOC
>>>"""

    def _get_mr_prompt(self, doc_slice: str) -> str:
        """MR ë°´ë“œ í”„ë¡¬í”„íŠ¸"""  
        return f"""ë¬¸ì„œë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•œêµ­ì–´ ì§ˆë¬¸ì„ ì—¬ëŸ¬ ê°œ ìƒì„±í•˜ì„¸ìš”. ê° ì¤„ë§ˆë‹¤ í•˜ë‚˜ì”© ì‘ì„±í•˜ì„¸ìš”.

ìš”êµ¬ì‚¬í•­:
- ê¸¸ì´: 80-160ì (ê³µë°± í¬í•¨)
- ë°˜ë“œì‹œ '?'ë¡œ ëë‚˜ëŠ” ì§ˆë¬¸
- ìˆ«ì/ë‹¨ìœ„/ì •ì±… ìš©ì–´ 1ê°œ ì´ìƒ í¬í•¨  
- ëŒ€ëª…ì‚¬(ì´ê²ƒ/ê·¸ê²ƒ/í•´ë‹¹/ë³¸/ë™ ë“±) ì™„ì „ ê¸ˆì§€
- í•œ ì¤„ë‹¹ í•˜ë‚˜ì˜ ì£¼ì œë§Œ
- ì§ˆë¬¸ ì‹œì‘ ë°©ì‹ ë‹¤ì–‘í™”
- JSON í˜•ì‹ ì‚¬ìš© ê¸ˆì§€

ì°¸ê³  ë¬¸ì„œ:
<<<DOC
{doc_slice}
DOC
>>>"""

    def _get_lr_prompt(self, doc_slice: str) -> str:
        """LR ë°´ë“œ í”„ë¡¬í”„íŠ¸ (ë©€í‹°í„´ ì‹œë‚˜ë¦¬ì˜¤â†’ì§ˆë¬¸)"""
        return f"""í•œêµ­ì–´ë¡œ ìì„¸í•œ ì„ìƒ ì‹œë‚˜ë¦¬ì˜¤ë¥¼ ì‘ì„±í•˜ì„¸ìš”. ê° ì‹œë‚˜ë¦¬ì˜¤ëŠ” í™˜ì ìƒí™©ì„ êµ¬ì²´ì ìœ¼ë¡œ ê¸°ìˆ í•œ í›„ ë§ˆì§€ë§‰ì— ë³´í—˜ ê¸‰ì—¬ ê´€ë ¨ ì§ˆë¬¸ìœ¼ë¡œ ëë‚˜ì•¼ í•©ë‹ˆë‹¤.

í•„ìˆ˜ ìš”êµ¬ì‚¬í•­:
- ì „ì²´ ê¸¸ì´: ìµœì†Œ 200ì ì´ìƒ (300-500ì ê¶Œì¥, ê³µë°± í¬í•¨)
- í™˜ì ì •ë³´: ë‚˜ì´, ì„±ë³„, ê¸°ì €ì§ˆí™˜, ì¹˜ë£Œê²½ê³¼ ë“± êµ¬ì²´ì ìœ¼ë¡œ ê¸°ìˆ 
- ìƒí™© ì „ê°œ: í˜„ì¬ ìƒí™©, ë¬¸ì œì , ê³ ë ¤ì‚¬í•­ ë“±ì„ ìƒì„¸íˆ ì„œìˆ   
- ë§ˆì§€ë§‰ ë¬¸ì¥: ë°˜ë“œì‹œ '?'ë¡œ ëë‚˜ëŠ” ê¸‰ì—¬ê¸°ì¤€ ê´€ë ¨ ì§ˆë¬¸
- ì˜ë£Œ ìš©ì–´/ìˆ«ì/ë‹¨ìœ„ í¬í•¨ (ìš©ëŸ‰, ê¸°ê°„, ê¸°ì¤€ ë“±)
- ëŒ€ëª…ì‚¬(ì´ê²ƒ/ê·¸ê²ƒ/í•´ë‹¹/ë³¸/ë™) ì‚¬ìš© ê¸ˆì§€
- ê° ì‹œë‚˜ë¦¬ì˜¤ëŠ” ë¹ˆ ì¤„ë¡œ êµ¬ë¶„

ì°¸ê³  ë¬¸ì„œ:
<<<DOC
{doc_slice}
DOC
>>>

ì˜ˆì‹œ í˜•ì‹:
65ì„¸ ë‚¨ì„± í™˜ìê°€ [ì§ˆí™˜ëª…]ìœ¼ë¡œ ì§„ë‹¨ë°›ì•˜ë‹¤. [ê¸°ì¡´ ì¹˜ë£Œ ë‚´ìš©ê³¼ ê²°ê³¼]. [í˜„ì¬ ìƒí™©ê³¼ ë¬¸ì œì ]. [ì¶”ê°€ì ì¸ ì„ìƒ ì •ë³´]. ì´ëŸ¬í•œ ìƒí™©ì—ì„œ [ì•½ì œëª…] ê¸‰ì—¬ ì¸ì • ê¸°ì¤€ì„ ë§Œì¡±í•˜ëŠ”ê°€?"""

    def _extract_lr_questions(self, content: str) -> List[str]:
        """LR ì‹œë‚˜ë¦¬ì˜¤ì—ì„œ ì§ˆë¬¸ ì¶”ì¶œ"""
        questions = []
        cases = content.strip().split('\n\n')
        
        for case in cases:
            case = case.strip()
            if not case:
                continue
                
            # ì „ì²´ ì‹œë‚˜ë¦¬ì˜¤ ê¸¸ì´ í™•ì¸ (200-600ì)
            if not (200 <= len(case) <= 600):
                continue
                
            # ? ê¸°í˜¸ë¡œ ëë‚˜ëŠ” ë¬¸ì¥ ì°¾ê¸° (ì˜ë£Œìš©ì–´ ê³ ë ¤)
            lines = case.split('\n')
            for line in reversed(lines):
                line = line.strip()
                if line.endswith('?'):
                    questions.append(case)  # ì „ì²´ ì‹œë‚˜ë¦¬ì˜¤ ë°˜í™˜
                    break
                    
        return questions
        
    def validate_question(self, question: str, band: LengthBand) -> bool:
        """ì§ˆë¬¸ ìœ íš¨ì„± ê²€ì¦"""
        band_config = self.config.bands[band]
        
        # ê¸¸ì´ ì²´í¬
        if not (band_config.min_chars <= len(question) <= band_config.max_chars):
            return False
            
        # ë¬¼ìŒí‘œ ì²´í¬
        if not question.endswith('?'):
            return False
            
        # ëŒ€ëª…ì‚¬ ì²´í¬ (ë°´ë“œë³„ ì°¨ë“±)
        if band in [LengthBand.SR, LengthBand.MR]:
            # SR/MRì€ ì—„ê²©í•œ ëŒ€ëª…ì‚¬ ê¸ˆì§€
            if self.strict_pronoun_pattern.search(question):
                return False
        else:  # LR
            # LRì€ ì§ˆë¬¸ ë¶€ë¶„ë§Œ ëŒ€ëª…ì‚¬ ê¸ˆì§€ (ì‹œë‚˜ë¦¬ì˜¤ ë¶€ë¶„ì€ í—ˆìš©)
            if self.strict_pronoun_pattern.search(question):
                return False
        
        # êµ¬ì²´ì„± ì²´í¬ (ìˆ«ì/ë‹¨ìœ„/ì •ì±…ì–´ í¬í•¨)
        if not self.specificity_pattern.search(question):
            return False
            
        # ë‹¨ì¼ ë…¼ì  ì²´í¬ (ë³µí•© ì§ˆë¬¸ ë°©ì§€)
        complex_markers = [',', ' ë° ', '/']
        complex_count = sum(question.count(marker) for marker in complex_markers)
        if complex_count >= 2:
            return False
            
        return True
        
    def generate_hard_negatives(self, positive_questions: List[Question]) -> List[Question]:
        """Hard Negative ìƒì„± (ì•µì»¤ ê¸°ë°˜ ë³€í˜•) - ì‹¤íŒ¨ ë°©ì§€ ê°•í™”"""
        hard_negatives = []
        
        if not positive_questions:
            logger.warning("POS ì§ˆë¬¸ì´ ì—†ì–´ HN ìƒì„± ë¶ˆê°€")
            return hard_negatives
            
        # ìƒìœ„ POS ì§ˆë¬¸ë“¤ì„ ì•µì»¤ë¡œ ì„ íƒ
        anchors = positive_questions[:min(5, len(positive_questions))]
        max_attempts = 20  # ìµœëŒ€ ì‹œë„ íšŸìˆ˜
        attempt = 0
        
        while len(hard_negatives) < len(positive_questions) // 2 and attempt < max_attempts:
            for anchor in anchors:
                if len(hard_negatives) >= len(positive_questions) // 2:
                    break
                    
                try:
                    # facet ë³€í˜• (1ê°œë§Œ)
                    mutated_questions = self._mutate_facet(anchor)
                    
                    for mutated in mutated_questions:
                        # LLMìœ¼ë¡œ ë¦¬ë¼ì´íŠ¸
                        rewritten = self._rewrite_question(mutated)
                        if rewritten and self.validate_question(rewritten, anchor.band):
                            hn_question = Question(
                                text=rewritten,
                                label="HARD_NEGATIVE", 
                                band=anchor.band,
                                anchor_id=anchor.anchor_id,
                                doc_slice_id=anchor.doc_slice_id,
                                metadata={**anchor.metadata, 'mutation_type': mutated.get('mutation_type')}
                            )
                            hard_negatives.append(hn_question)
                            break  # ì•µì»¤ë‹¹ 1ê°œì”©ë§Œ
                except Exception as e:
                    logger.warning(f"HN ìƒì„± ì‹¤íŒ¨ (ì•µì»¤: {anchor.text[:30]}): {e}")
                    continue
                    
            attempt += 1
            
        # ìµœì†Œí•œì˜ HN ë³´ì¥ (fallback)
        if len(hard_negatives) == 0:
            logger.warning("HN ìƒì„± ì™„ì „ ì‹¤íŒ¨, ê°„ë‹¨í•œ fallback HN ìƒì„±")
            hard_negatives = self._create_fallback_hn(positive_questions)
            
        logger.info(f"HN ìƒì„± ì™„ë£Œ: {len(hard_negatives)}ê°œ")
        return hard_negatives
        
    def _create_fallback_hn(self, positive_questions: List[Question]) -> List[Question]:
        """ê°„ë‹¨í•œ fallback HN ìƒì„± (í™•ì‹¤í•œ ë³´ì¥)"""
        fallback_hn = []
        
        for pos_q in positive_questions[:5]:  # ìµœëŒ€ 5ê°œê¹Œì§€ ì‹œë„
            try:
                original_text = pos_q.text
                modified_text = None
                
                # ë°©ë²• 1: ìˆ«ì ë³€ê²½
                import re
                numbers = re.findall(r'\d+', original_text)
                if numbers:
                    original_num = numbers[0]
                    try:
                        new_num = str(int(original_num) + 10) if int(original_num) < 90 else str(int(original_num) - 10)
                        modified_text = original_text.replace(original_num, new_num, 1)
                    except:
                        pass
                
                # ë°©ë²• 2: í‚¤ì›Œë“œ ë³€ê²½ (ìˆ«ì ì‹¤íŒ¨ì‹œ)
                if not modified_text:
                    if 'ê¸‰ì—¬' in original_text:
                        modified_text = original_text.replace('ê¸‰ì—¬', 'ë¹„ê¸‰ì—¬', 1)
                    elif 'ì¸ì •' in original_text:
                        modified_text = original_text.replace('ì¸ì •', 'ì œì™¸', 1)
                    elif 'í•„ìš”' in original_text:
                        modified_text = original_text.replace('í•„ìš”', 'ë¶ˆí•„ìš”', 1)
                
                # ë°©ë²• 3: ë‹¨ìˆœ ì ‘ë¯¸ì‚¬ ì¶”ê°€ (ëª¨ë‘ ì‹¤íŒ¨ì‹œ)
                if not modified_text:
                    modified_text = original_text.replace('?', ' (ì˜ˆì™¸ì¡°ê±´)?')
                    
                if modified_text and modified_text != original_text:
                    hn_question = Question(
                        text=modified_text,
                        label="HARD_NEGATIVE",
                        band=pos_q.band,
                        anchor_id=pos_q.anchor_id,
                        doc_slice_id=pos_q.doc_slice_id,
                        metadata={**pos_q.metadata, 'mutation_type': 'fallback_simple'}
                    )
                    fallback_hn.append(hn_question)
                    logger.info(f"Fallback HN ìƒì„±: '{modified_text[:30]}...'")
                    
                    # ëª©í‘œ ë‹¬ì„±ì‹œ ì¤‘ë‹¨
                    if len(fallback_hn) >= len(positive_questions) // 3:
                        break
                    
            except Exception as e:
                logger.warning(f"Fallback HN ìƒì„± ì‹¤íŒ¨: {e}")
                continue
                
        logger.info(f"Fallback HN ìµœì¢… ìƒì„±: {len(fallback_hn)}ê°œ")
        return fallback_hn
        
    def _mutate_facet(self, anchor: Question) -> List[Dict[str, Any]]:
        """ë‹¨ì¼ facet ë³€í˜•"""
        mutations = []
        
        # ë³€í˜• íƒ€ì…ë“¤
        mutation_types = [
            'dosage_boundary',  # ìš©ëŸ‰ ê²½ê³„
            'duration_change',  # ê¸°ê°„ ë³€ê²½
            'route_change',     # íˆ¬ì—¬ê²½ë¡œ ë³€ê²½
            'indication_shift', # ì ì‘ì¦ ì´ë™
            'age_boundary',     # ì—°ë ¹ ê²½ê³„
            'coverage_flip',    # ê¸‰ì—¬â†”ë¹„ê¸‰ì—¬
        ]
        
        for mutation_type in mutation_types[:2]:  # ìµœëŒ€ 2ê°œ ë³€í˜•
            mutated_text = self._apply_mutation(anchor.text, mutation_type)
            if mutated_text and mutated_text != anchor.text:
                mutations.append({
                    'text': mutated_text,
                    'mutation_type': mutation_type
                })
                
        return mutations
        
    def _apply_mutation(self, text: str, mutation_type: str) -> Optional[str]:
        """êµ¬ì²´ì ì¸ ë³€í˜• ì ìš©"""
        if mutation_type == 'dosage_boundary':
            # ìˆ«ì ê²½ê³„ ë³€í˜• (ì˜ˆ: 10mg â†’ 5mg)
            import re
            numbers = re.findall(r'\d+', text)
            if numbers:
                original = numbers[0]
                modified = str(int(int(original) * 0.5))  # ì ˆë°˜ìœ¼ë¡œ
                return text.replace(original, modified, 1)
                
        elif mutation_type == 'coverage_flip':
            # ê¸‰ì—¬â†”ë¹„ê¸‰ì—¬ ë’¤ë°”ê¾¸ê¸°
            if 'ê¸‰ì—¬' in text:
                return text.replace('ê¸‰ì—¬', 'ë¹„ê¸‰ì—¬', 1)
            elif 'ë¹„ê¸‰ì—¬' in text:
                return text.replace('ë¹„ê¸‰ì—¬', 'ê¸‰ì—¬', 1)
                
        # ë‹¤ë¥¸ ë³€í˜•ë“¤ë„ êµ¬í˜„...
        return None
        
    def _rewrite_question(self, mutated_data: Dict[str, Any]) -> Optional[str]:
        """ë³€í˜•ëœ í…ìŠ¤íŠ¸ë¥¼ ìì—°ìŠ¤ëŸ¬ìš´ ì§ˆë¬¸ìœ¼ë¡œ ë¦¬ë¼ì´íŠ¸"""
        prompt = f"""Rewrite the given Korean sentence into a natural Korean question.
Constraints: 25â€“80 characters; end with '?'; keep numbers/units/policy terms; no pronouns.
Return exactly one line. No JSON.

Original:
{mutated_data['text']}"""

        try:
            from openai import OpenAI
            client = OpenAI(api_key=openai.api_key)
            
            response = client.chat.completions.create(
                model=self.config.model,
                messages=[{"role": "user", "content": prompt}],
                temperature=0.3,  # ë‚®ì€ temperatureë¡œ ì¼ê´€ì„± í™•ë³´
                max_tokens=100
            )
            
            rewritten = response.choices[0].message.content.strip()
            return rewritten if rewritten.endswith('?') else None
            
        except Exception as e:
            logger.error(f"ë¦¬ë¼ì´íŠ¸ ì‹¤íŒ¨: {e}")
            return None
    
    def balance_labels_per_band(self, questions: List[Question], 
                              target_total: int) -> List[Question]:
        """ë°´ë“œë³„ ë¼ë²¨ ë¹„ìœ¨ ì •ê·œí™”"""
        # ë°´ë“œë³„ ê·¸ë£¹í™”
        band_groups = {}
        for q in questions:
            if q.band not in band_groups:
                band_groups[q.band] = []
            band_groups[q.band].append(q)
        
        balanced_questions = []
        
        for band, band_questions in band_groups.items():
            band_config = self.config.bands[band]
            band_target = int(target_total * band_config.ratio)
            
            # ë°´ë“œ ë‚´ì—ì„œ ë¼ë²¨ ë¹„ìœ¨ ì ìš© (ë¹„ìœ¨ ë¬´ê²°ì„± ë³´ì¥)
            total_ratio = self.config.pos_ratio + self.config.hn_ratio + self.config.en_ratio
            pos_target = int(band_target * self.config.pos_ratio / total_ratio)
            hn_target = int(band_target * self.config.hn_ratio / total_ratio)  
            en_target = int(band_target * self.config.en_ratio / total_ratio)
            
            # ë¼ë²¨ë³„ ë¶„ë¥˜
            pos_questions = [q for q in band_questions if q.label == "POSITIVE"]
            hn_questions = [q for q in band_questions if q.label == "HARD_NEGATIVE"]
            en_questions = [q for q in band_questions if q.label == "EASY_NEGATIVE"]
            
            logger.info(f"{band.value} ë°´ë“œ ë¶„ë¥˜ ì „ ì§ˆë¬¸: {len(band_questions)}ê°œ")
            logger.info(f"  ë¼ë²¨ ë¶„í¬: POS={len(pos_questions)}, HN={len(hn_questions)}, EN={len(en_questions)}")
            
            # ë¶€ì¡±ë¶„ ê²½ê³  ë° ëŒ€ì‘
            if len(pos_questions) < pos_target:
                logger.warning(f"{band.value} ë°´ë“œ POS ë¶€ì¡±: {len(pos_questions)}/{pos_target}")
            if len(hn_questions) < hn_target:
                logger.warning(f"{band.value} ë°´ë“œ HN ë¶€ì¡±: {len(hn_questions)}/{hn_target}")
                # HN ë¶€ì¡±ì‹œ POSë¡œ ì¼ë¶€ ëŒ€ì²´ (ì„ì‹œ ì¡°ì¹˜)
                if len(pos_questions) > pos_target:
                    extra_pos = len(pos_questions) - pos_target
                    hn_deficit = hn_target - len(hn_questions)
                    compensation = min(extra_pos, hn_deficit)
                    pos_target += compensation
                    hn_target = len(hn_questions)  # ì‹¤ì œ ê°€ëŠ¥í•œ ìˆ˜ë¡œ ì¡°ì •
                    logger.info(f"{band.value} ë°´ë“œ: HN ë¶€ì¡±ë¶„ì„ POSë¡œ {compensation}ê°œ ë³´ìƒ")
            
            # ìƒ˜í”Œë§
            selected_pos = random.sample(pos_questions, min(pos_target, len(pos_questions)))
            selected_hn = random.sample(hn_questions, min(hn_target, len(hn_questions)))
            selected_en = random.sample(en_questions, min(en_target, len(en_questions)))
            
            balanced_questions.extend(selected_pos + selected_hn + selected_en)
            
            # ë¹„ìœ¨ ê²€ì¦ ë¡œê·¸
            actual_total = len(selected_pos) + len(selected_hn) + len(selected_en)
            if actual_total > 0:
                pos_ratio = len(selected_pos) / actual_total * 100
                hn_ratio = len(selected_hn) / actual_total * 100
                logger.info(f"{band.value} ë°´ë“œ ìµœì¢…: POS {len(selected_pos)}({pos_ratio:.1f}%), "
                          f"HN {len(selected_hn)}({hn_ratio:.1f}%), EN {len(selected_en)}")
                
                # ì¹˜ëª…ì  ë¶ˆê· í˜• ê°ì§€
                if len(selected_hn) == 0 and hn_target > 0:
                    logger.error(f"âš ï¸ {band.value} ë°´ë“œì—ì„œ HNì´ 0ê°œ! ì„¸íŠ¸ ë¬´ê²°ì„± ìœ„í—˜!")
        
        return balanced_questions
        
    def remove_duplicates(self, questions: List[Question]) -> List[Question]:
        """ì¤‘ë³µ ì œê±° (ë¼ë²¨ë³„ ë¶„ë¦¬ ì²˜ë¦¬)"""
        unique_questions = []
        
        for q in questions:
            is_duplicate = False
            for existing in unique_questions:
                # ê°™ì€ ë¼ë²¨ë¼ë¦¬ë§Œ ì¤‘ë³µ ë¹„êµ (POS, HN, EN ë³„ë„ ì²˜ë¦¬)
                if q.label == existing.label:
                    # í† í°ì…‹ ìœ ì‚¬ë„ ì²´í¬
                    similarity = fuzz.token_set_ratio(q.text, existing.text)
                    if similarity >= 82:
                        is_duplicate = True
                        logger.debug(f"{q.label} ì¤‘ë³µ ì œê±°: '{q.text[:20]}...' vs '{existing.text[:20]}...' ({similarity}%)")
                        break
                    
            if not is_duplicate:
                unique_questions.append(q)
                
        # ë¼ë²¨ë³„ ì œê±° í˜„í™©
        label_before = {}
        label_after = {}
        for q in questions:
            label_before[q.label] = label_before.get(q.label, 0) + 1
        for q in unique_questions:
            label_after[q.label] = label_after.get(q.label, 0) + 1
            
        logger.info(f"ì¤‘ë³µ ì œê±°: {len(questions)} â†’ {len(unique_questions)}")
        logger.info(f"ë¼ë²¨ë³„ ë³€í™”: {label_before} â†’ {label_after}")
        return unique_questions
        
    def check_opening_diversity(self, questions: List[Question]) -> bool:
        """ë¬¸ë‘ ë‹¤ì–‘ì„± ì²´í¬"""
        opening_counts = {}
        total = len(questions)
        
        for q in questions:
            for opening in self.opening_words:
                if q.text.startswith(opening):
                    opening_counts[opening] = opening_counts.get(opening, 0) + 1
                    break
                    
        # 30% ì´ˆê³¼í•˜ëŠ” ë¬¸ë‘ê°€ ìˆëŠ”ì§€ ì²´í¬
        for opening, count in opening_counts.items():
            if count / total > 0.3:
                logger.warning(f"ë¬¸ë‘ '{opening}' ê³¼ë‹¤ ì‚¬ìš©: {count}/{total} ({count/total*100:.1f}%)")
                return False
                
        return True
        
    def validate_final_dataset(self, all_questions: List[Question]):
        """ì „ì²´ ë°ì´í„°ì…‹ ë¬´ê²°ì„± ê²€ì¦"""
        if not all_questions:
            logger.error("âš ï¸ ì¹˜ëª…ì  ì˜¤ë¥˜: ìƒì„±ëœ ì§ˆë¬¸ì´ 0ê°œ!")
            return
            
        # ì „ì²´ ë¼ë²¨ ë¶„í¬
        label_counts = {}
        band_counts = {}
        
        for q in all_questions:
            label_counts[q.label] = label_counts.get(q.label, 0) + 1
            band_counts[q.band.value] = band_counts.get(q.band.value, 0) + 1
        
        total = len(all_questions)
        pos_count = label_counts.get("POSITIVE", 0)
        hn_count = label_counts.get("HARD_NEGATIVE", 0)
        
        logger.info("="*50)
        logger.info("ğŸ“Š ìµœì¢… ë°ì´í„°ì…‹ ê²€ì¦")
        logger.info(f"ì „ì²´ ì§ˆë¬¸ ìˆ˜: {total}ê°œ")
        logger.info(f"ë¼ë²¨ ë¶„í¬: {label_counts}")
        logger.info(f"ë°´ë“œ ë¶„í¬: {band_counts}")
        
        if total > 0:
            pos_ratio = pos_count / total * 100
            hn_ratio = hn_count / total * 100
            logger.info(f"POS ë¹„ìœ¨: {pos_ratio:.1f}%")
            logger.info(f"HN ë¹„ìœ¨: {hn_ratio:.1f}%")
            
            # ì¹˜ëª…ì  ë¬¸ì œ ê°ì§€
            if hn_count == 0:
                logger.error("ğŸš¨ ì¹˜ëª…ì  ì˜¤ë¥˜: HARD_NEGATIVEê°€ 0ê°œ! V5ì™€ ë™ì¼í•œ ë¬¸ì œ ë°œìƒ!")
                logger.error("ì„¸íŠ¸ ë¬´ê²°ì„±ì´ ê¹¨ì¡ŒìŠµë‹ˆë‹¤. ì‹¤í–‰ì„ ì¤‘ë‹¨í•˜ê±°ë‚˜ HN ìƒì„± ë¡œì§ì„ ìˆ˜ì •í•˜ì„¸ìš”.")
            elif hn_ratio < 20:  # ì „ì²´ì˜ 20% ë¯¸ë§Œ
                logger.warning(f"âš ï¸ ê²½ê³ : HN ë¹„ìœ¨ì´ {hn_ratio:.1f}%ë¡œ ë‚®ìŠµë‹ˆë‹¤. ëª©í‘œ: 33.3%")
            else:
                logger.info("âœ… ë¼ë²¨ ë¹„ìœ¨ ê²€ì¦ í†µê³¼")
        
        logger.info("="*50)
        
    def generate_questions_for_row(self, row: pd.Series, target_count: int) -> List[Question]:
        """í•œ í–‰ì— ëŒ€í•œ ì „ì²´ ì§ˆë¬¸ ìƒì„± íŒŒì´í”„ë¼ì¸"""
        # ê¸°ë³¸ ì •ë³´ ì¶”ì¶œ
        drug_info = self.parse_drug_info(row['title'])
        text_slices = self.slice_text(row['text'])
        
        all_questions = []
        
        for slice_idx, doc_slice in enumerate(text_slices):
            anchor_id = str(uuid.uuid4())
            slice_id = f"{row['code']}_{slice_idx}"
            
            # ê° ë°´ë“œë³„ POS ì§ˆë¬¸ ìƒì„±
            for band in [LengthBand.SR, LengthBand.MR, LengthBand.LR]:
                questions_text = self.generate_questions_by_band(doc_slice, band, drug_info)
                
                for q_text in questions_text:
                    if self.validate_question(q_text, band):
                        question = Question(
                            text=q_text,
                            label="POSITIVE",
                            band=band,
                            anchor_id=anchor_id,
                            doc_slice_id=slice_id,
                            metadata={
                                'code': row.get('code', ''),
                                'code_name': row.get('code_name', ''),
                                'title': row.get('title', ''),
                                'text': row.get('text', ''),
                                'drug_info': drug_info
                            }
                        )
                        all_questions.append(question)
        
        # Hard Negative ìƒì„±
        pos_questions = [q for q in all_questions if q.label == "POSITIVE"]
        if pos_questions:
            hn_questions = self.generate_hard_negatives(pos_questions)
            logger.info(f"ìƒì„±ëœ HN ìƒì„¸:")
            for i, hn in enumerate(hn_questions):
                logger.info(f"  HN {i+1}: band={hn.band.value}, label={hn.label}, text={hn.text[:30]}...")
            all_questions.extend(hn_questions)
        
        # ì¤‘ë³µ ì œê±°
        all_questions = self.remove_duplicates(all_questions)
        
        # ë¼ë²¨ ë¹„ìœ¨ ì •ê·œí™”
        balanced_questions = self.balance_labels_per_band(all_questions, target_count)
        
        logger.info(f"í–‰ {row['code']}: ì´ {len(balanced_questions)}ê°œ ì§ˆë¬¸ ìƒì„±")
        
        return balanced_questions
        
    def save_results(self, all_questions: List[Question], original_df: pd.DataFrame, 
                    output_file: str):
        """ê²°ê³¼ ì €ì¥ (ë°±ì—… ë° ì•ˆì „ ì €ì¥ í¬í•¨)"""
        from pathlib import Path
        import shutil
        
        # ê¸°ì¡´ íŒŒì¼ ë°±ì—…
        if Path(output_file).exists():
            backup_file = output_file.replace('.xlsx', f'_backup_{datetime.now().strftime("%Y%m%d_%H%M%S")}.xlsx')
            shutil.copy2(output_file, backup_file)
            logger.info(f"ê¸°ì¡´ íŒŒì¼ ë°±ì—…: {backup_file}")
        
        # ì—‘ì…€ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        results = []
        
        for q in all_questions:
            row_data = {
                'ì•½ì œë¶„ë¥˜ë²ˆí˜¸': q.metadata.get('code', ''),
                'ì•½ì œë¶„ë¥˜ëª…': q.metadata.get('code_name', ''), 
                'êµ¬ë¶„': q.metadata.get('title', ''),
                'ì„¸ë¶€ì¸ì •ê¸°ì¤€ ë° ë°©ë²•': q.metadata.get('text', ''),
                'question': q.text,
                'ë¼ë²¨': q.label
            }
            results.append(row_data)
            
        result_df = pd.DataFrame(results)
        
        # ğŸ” ì¶œë ¥ ë°ì´í„° ê²€ì¦
        required_columns = ['ì•½ì œë¶„ë¥˜ë²ˆí˜¸', 'ì•½ì œë¶„ë¥˜ëª…', 'êµ¬ë¶„', 'ì„¸ë¶€ì¸ì •ê¸°ì¤€ ë° ë°©ë²•', 'question', 'ë¼ë²¨']
        missing_columns = [col for col in required_columns if col not in result_df.columns]
        if missing_columns:
            raise ValueError(f"âŒ í•„ìˆ˜ ì»¬ëŸ¼ ëˆ„ë½: {missing_columns}")
        
        # ë°ì´í„° ë¬´ê²°ì„± ì²´í¬
        empty_critical_columns = []
        for col in ['êµ¬ë¶„', 'ì„¸ë¶€ì¸ì •ê¸°ì¤€ ë° ë°©ë²•']:
            if result_df[col].isnull().all() or (result_df[col] == '').all():
                empty_critical_columns.append(col)
        
        if empty_critical_columns:
            logger.warning(f"âš ï¸ ë¹ˆ ë°ì´í„° ì»¬ëŸ¼: {empty_critical_columns}")
            # ìƒ˜í”Œ í™•ì¸
            logger.info("ì²« 3í–‰ ìƒ˜í”Œ:")
            logger.info(result_df[['êµ¬ë¶„', 'ì„¸ë¶€ì¸ì •ê¸°ì¤€ ë° ë°©ë²•']].head(3).to_string())
        
        logger.info(f"âœ… ì¶œë ¥ ê²€ì¦ ì™„ë£Œ - ì´ {len(result_df)}í–‰, {len(result_df.columns)}ê°œ ì»¬ëŸ¼")
        
        # ì„ì‹œ íŒŒì¼ë¡œ ë¨¼ì € ì €ì¥ (ì•ˆì „í•œ ì €ì¥)
        temp_file = output_file.replace('.xlsx', '_temp.xlsx')
        try:
            result_df.to_excel(temp_file, index=False, engine='openpyxl')
            # ì„±ê³µí•˜ë©´ ì›ë³¸ íŒŒì¼ë¡œ ì´ë™
            shutil.move(temp_file, output_file)
            logger.info(f"ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {output_file}")
        except Exception as e:
            logger.error(f"ì €ì¥ ì‹¤íŒ¨: {e}")
            if Path(temp_file).exists():
                Path(temp_file).unlink()  # ì‹¤íŒ¨ì‹œ ì„ì‹œíŒŒì¼ ì‚­ì œ
            raise e
        
        logger.info(f"ì´ {len(results)}ê°œ ì§ˆë¬¸")
        
        # í†µê³„ ì¶œë ¥
        label_counts = result_df['ë¼ë²¨'].value_counts()
        band_counts = pd.Series([q.band.value for q in all_questions]).value_counts()
        
        logger.info("ë¼ë²¨ ë¶„í¬:")
        for label, count in label_counts.items():
            logger.info(f"  {label}: {count}")
            
        logger.info("ë°´ë“œ ë¶„í¬:")
        for band, count in band_counts.items():
            logger.info(f"  {band}: {count}")
            
        # ì•µì»¤íŒ© JSONL ì €ì¥ (ì„ íƒì‚¬í•­)
        jsonl_file = output_file.replace('.xlsx', '_anchorpack.jsonl')
        with open(jsonl_file, 'w', encoding='utf-8') as f:
            for q in all_questions:
                anchor_data = {
                    'anchor_id': q.anchor_id,
                    'band': q.band.value,
                    'question': q.text,
                    'doc_slice_id': q.doc_slice_id,
                    'label': q.label
                }
                f.write(json.dumps(anchor_data, ensure_ascii=False) + '\n')
                
        logger.info(f"ì•µì»¤íŒ© ì €ì¥ ì™„ë£Œ: {jsonl_file}")

    def generate_dataset(self, file_path: str, output_file: str, max_rows: int = None):
        """ì „ì²´ ë°ì´í„°ì…‹ ìƒì„± í•¨ìˆ˜ - í…ŒìŠ¤íŠ¸ìš© max_rows ì§€ì›"""
        try:
            # ë°ì´í„° ë¡œë“œ
            df = self.load_and_preprocess_data(file_path)
            
            # í…ŒìŠ¤íŠ¸ìš© í–‰ ì œí•œ
            if max_rows:
                df = df.head(max_rows)
                logger.info(f"í…ŒìŠ¤íŠ¸ ëª¨ë“œ: {max_rows}í–‰ìœ¼ë¡œ ì œí•œ")
            
            # ì „ì²´ ì§ˆë¬¸ ìƒì„±
            all_questions = []
            target_per_row = 15  # í–‰ë‹¹ ëª©í‘œ ì§ˆë¬¸ ìˆ˜
            
            for idx, row in df.iterrows():
                logger.info(f"ì²˜ë¦¬ ì¤‘: {idx+1}/{len(df)} - {row.get('code', 'Unknown')}")
                questions = self.generate_questions_for_row(row, target_per_row)
                all_questions.extend(questions)
                
                # ì§„í–‰ìƒí™© ì²´í¬ ë° ì¤‘ê°„ ì €ì¥ (50í–‰ë§ˆë‹¤)
                if (idx + 1) % 50 == 0 and not max_rows:  # í…ŒìŠ¤íŠ¸ ëª¨ë“œì—ì„œëŠ” ì¤‘ê°„ ì €ì¥ ì•ˆí•¨
                    checkpoint_file = output_file.replace('.xlsx', f'_checkpoint_{idx+1}.xlsx')
                    self.save_results(all_questions, df, checkpoint_file)
                    logger.info(f"ì¤‘ê°„ ì €ì¥ ì™„ë£Œ: {checkpoint_file}")
            
            # ìµœì¢… ê²°ê³¼ ì €ì¥
            self.save_results(all_questions, df, output_file)
            logger.info(f"ğŸ‰ ìµœì¢… ì™„ë£Œ! ìƒì„±ëœ ì§ˆë¬¸ ìˆ˜: {len(all_questions)}")
            
            return all_questions
            
        except Exception as e:
            logger.error(f"âŒ ë°ì´í„°ì…‹ ìƒì„± ì‹¤íŒ¨: {e}")
            raise e

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    # ì„¤ì •
    config = GenerationConfig()
    generator = V7QuestionGenerator(config)
    
    # ê³ ì • ë°ì´í„° ê²½ë¡œ
    data_file = "C:/Jimin/Pharma-Augment/data/ìš”ì–‘ì‹¬ì‚¬ì•½ì œ_í›„ì²˜ë¦¬_v2.xlsx"
    output_file = "C:/Jimin/Pharma-Augment/versions/v7/drug_questions_v7.xlsx"
    
    try:
        logger.info("="*60)
        logger.info("V7 ì§ˆë¬¸ ìƒì„±ê¸° ì‹¤í–‰ ì‹œì‘")
        logger.info(f"ì‹œì‘ ì‹œê°„: {datetime.now()}")
        logger.info(f"ë¡œê·¸ íŒŒì¼: {log_file}")
        logger.info(f"ì¶œë ¥ íŒŒì¼: {output_file}")
        logger.info("="*60)
        
        # ë°ì´í„° ë¡œë“œ
        df = generator.load_and_preprocess_data(data_file)
        
        # ì „ì²´ ì§ˆë¬¸ ìƒì„±
        all_questions = []
        target_per_row = 15  # í–‰ë‹¹ ëª©í‘œ ì§ˆë¬¸ ìˆ˜
        
        for idx, row in df.iterrows():
            logger.info(f"ì²˜ë¦¬ ì¤‘: {idx+1}/{len(df)} - {row['code']}")
            questions = generator.generate_questions_for_row(row, target_per_row)
            all_questions.extend(questions)
            
            # ì§„í–‰ìƒí™© ì²´í¬ ë° ì¤‘ê°„ ì €ì¥
            if (idx + 1) % 50 == 0:  # 50í–‰ë§ˆë‹¤ ì¤‘ê°„ ì €ì¥
                checkpoint_file = output_file.replace('.xlsx', f'_checkpoint_{idx+1}.xlsx')
                temp_questions = generator.remove_duplicates(all_questions.copy())
                generator.save_results(temp_questions, df, checkpoint_file)
                logger.info(f"ì¤‘ê°„ ì €ì¥ ì™„ë£Œ: {checkpoint_file} ({len(temp_questions)}ê°œ ì§ˆë¬¸)")
                
            if (idx + 1) % 10 == 0:
                logger.info(f"ì§„í–‰ìƒí™©: {idx+1}/{len(df)} ({(idx+1)/len(df)*100:.1f}%)")
        
        # ìµœì¢… ì •ë¦¬ ë° ì €ì¥
        all_questions = generator.remove_duplicates(all_questions)
        
        # ì „ì²´ ë°ì´í„°ì…‹ ë¬´ê²°ì„± ê²€ì¦
        generator.validate_final_dataset(all_questions)
        
        generator.save_results(all_questions, df, output_file)
        
        logger.info("V7 ì§ˆë¬¸ ìƒì„± ì™„ë£Œ!")
        
    except Exception as e:
        logger.error(f"ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}")
        logger.error(traceback.format_exc())

if __name__ == "__main__":
    main()